{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e258e2d-b1cd-4657-9cd5-f1c4ba7b38eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'metadata': {'pdf:PDFVersion': '1.7', 'pdf:docinfo:title': 'Mel Spectrogram-based advanced deep temporal clustering model with unsupervised data for fault diagnosis', 'xmp:CreatorTool': 'Elsevier', 'pdf:hasXFA': 'false', 'access_permission:can_print_degraded': 'true', 'X-TIKA:Parsed-By-Full-Set': ['org.apache.tika.parser.DefaultParser', 'org.apache.tika.parser.pdf.PDFParser'], 'X-TIKA:content_handler': 'ToTextContentHandler', 'pdf:num3DAnnotations': '0', 'dc:format': 'application/pdf; version=1.7', 'pdf:docinfo:custom:robots': 'noindex', 'pdf:docinfo:creator_tool': 'Elsevier', 'access_permission:fill_in_form': 'true', 'pdf:docinfo:custom:CreationDate--Text': '7th February 2023', 'pdf:hasCollection': 'false', 'pdf:encrypted': 'false', 'dc:title': 'Mel Spectrogram-based advanced deep temporal clustering model with unsupervised data for fault diagnosis', 'pdf:containsNonEmbeddedFont': 'false', 'pdf:docinfo:custom:CrossMarkDomains[1]': 'elsevier.com', 'robots': 'noindex', 'pdf:docinfo:subject': 'Expert Systems With Applications, 217 (2023) 119551. doi:10.1016/j.eswa.2023.119551', 'pdf:hasMarkedContent': 'true', 'pdf:docinfo:creator': 'Geonkyo Hong', 'pdf:docinfo:custom:CrossmarkMajorVersionDate': '2010-04-23', 'access_permission:extract_for_accessibility': 'true', 'resourceName': \"b'Mel-Spectrogram-based-advanced-deep-temporal-clusterin_2023_Expert-Systems-w.pdf'\", 'pdf:docinfo:custom:CrossMarkDomains[2]': 'sciencedirect.com', 'X-TIKA:Parsed-By': ['org.apache.tika.parser.DefaultParser', 'org.apache.tika.parser.pdf.PDFParser'], 'ElsevierWebPDFSpecifications': '7.0', 'pdf:docinfo:custom:doi': '10.1016/j.eswa.2023.119551', 'pdf:docinfo:custom:CrossmarkDomainExclusive': 'true', 'X-TIKA:embedded_depth': '0', 'CrossmarkDomainExclusive': 'true', 'pdf:annotationTypes': 'null', 'pdf:docinfo:producer': 'Acrobat Distiller 8.1.0 (Windows)', 'pdf:annotationSubtypes': 'Link', 'CreationDate--Text': '7th February 2023', 'doi': '10.1016/j.eswa.2023.119551', 'pdf:containsDamagedFont': 'false', 'pdf:unmappedUnicodeCharsPerPage': ['0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0'], 'access_permission:modify_annotations': 'true', 'dc:creator': 'Geonkyo Hong', 'dcterms:created': '2023-02-07T18:16:11Z', 'dcterms:modified': '2023-02-07T18:19:55Z', 'CrossMarkDomains[1]': 'elsevier.com', 'pdf:overallPercentageUnmappedUnicodeChars': '0.0', 'pdf:docinfo:keywords': 'Anomaly detection,Data augmentation,Fault diagnosis,Mel spectrogram,Time series,Unsupervised learning', 'pdf:docinfo:modified': '2023-02-07T18:19:55Z', 'Content-Length': '7956340', 'Content-Type': 'application/pdf', 'dc:language': 'en', 'pdf:producer': 'Acrobat Distiller 8.1.0 (Windows)', 'dc:subject': ['Anomaly detection,Data augmentation,Fault diagnosis,Mel spectrogram,Time series,Unsupervised learning', 'Expert Systems With Applications, 217 (2023) 119551. doi:10.1016/j.eswa.2023.119551'], 'X-TIKA:EXCEPTION:warn': 'org.xml.sax.SAXParseException; lineNumber: 82; columnNumber: 11; The content of elements must consist of well-formed character data or markup.\\n\\tat org.apache.xerces.parsers.DOMParser.parse(Unknown Source)\\n\\tat org.apache.xerces.jaxp.DocumentBuilderImpl.parse(Unknown Source)\\n\\tat java.xml/javax.xml.parsers.DocumentBuilder.parse(DocumentBuilder.java:122)\\n\\tat org.apache.tika.utils.XMLReaderUtils.buildDOM(XMLReaderUtils.java:396)\\n\\tat org.apache.tika.parser.pdf.PDMetadataExtractor.loadDOM(PDMetadataExtractor.java:472)\\n\\tat org.apache.tika.parser.pdf.PDMetadataExtractor.extract(PDMetadataExtractor.java:69)\\n\\tat org.apache.tika.parser.pdf.PDFParser.extractMetadata(PDFParser.java:423)\\n\\tat org.apache.tika.parser.pdf.PDFParser.parse(PDFParser.java:181)\\n\\tat org.apache.tika.parser.CompositeParser.parse(CompositeParser.java:298)\\n\\tat org.apache.tika.parser.CompositeParser.parse(CompositeParser.java:298)\\n\\tat org.apache.tika.parser.AutoDetectParser.parse(AutoDetectParser.java:175)\\n\\tat org.apache.tika.parser.RecursiveParserWrapper.parse(RecursiveParserWrapper.java:163)\\n\\tat org.apache.tika.server.core.resource.TikaResource.parse(TikaResource.java:352)\\n\\tat org.apache.tika.server.core.resource.RecursiveMetadataResource.parseMetadata(RecursiveMetadataResource.java:78)\\n\\tat org.apache.tika.server.core.resource.RecursiveMetadataResource.parseMetadataToMetadataList(RecursiveMetadataResource.java:190)\\n\\tat org.apache.tika.server.core.resource.RecursiveMetadataResource.getMetadata(RecursiveMetadataResource.java:179)\\n\\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\\n\\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\\n\\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\\n\\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)\\n\\tat org.apache.cxf.service.invoker.AbstractInvoker.performInvocation(AbstractInvoker.java:179)\\n\\tat org.apache.cxf.service.invoker.AbstractInvoker.invoke(AbstractInvoker.java:96)\\n\\tat org.apache.cxf.jaxrs.JAXRSInvoker.invoke(JAXRSInvoker.java:201)\\n\\tat org.apache.cxf.jaxrs.JAXRSInvoker.invoke(JAXRSInvoker.java:104)\\n\\tat org.apache.cxf.interceptor.ServiceInvokerInterceptor$1.run(ServiceInvokerInterceptor.java:59)\\n\\tat org.apache.cxf.interceptor.ServiceInvokerInterceptor.handleMessage(ServiceInvokerInterceptor.java:96)\\n\\tat org.apache.cxf.phase.PhaseInterceptorChain.doIntercept(PhaseInterceptorChain.java:307)\\n\\tat org.apache.cxf.transport.ChainInitiationObserver.onMessage(ChainInitiationObserver.java:121)\\n\\tat org.apache.cxf.transport.http.AbstractHTTPDestination.invoke(AbstractHTTPDestination.java:265)\\n\\tat org.apache.cxf.transport.http_jetty.JettyHTTPDestination.doService(JettyHTTPDestination.java:247)\\n\\tat org.apache.cxf.transport.http_jetty.JettyHTTPHandler.handle(JettyHTTPHandler.java:79)\\n\\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)\\n\\tat org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)\\n\\tat org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1440)\\n\\tat org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:190)\\n\\tat org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1355)\\n\\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)\\n\\tat org.eclipse.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:191)\\n\\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)\\n\\tat org.eclipse.jetty.server.Server.handle(Server.java:516)\\n\\tat org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:487)\\n\\tat org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:732)\\n\\tat org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:479)\\n\\tat org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)\\n\\tat org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)\\n\\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)\\n\\tat org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)\\n\\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)\\n\\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)\\n\\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)\\n\\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)\\n\\tat org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)\\n\\tat org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)\\n\\tat org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)\\n\\tat java.base/java.lang.Thread.run(Thread.java:840)\\n', 'pdf:docinfo:custom:ElsevierWebPDFSpecifications': '7.0', 'pdf:totalUnmappedUnicodeChars': '0', 'access_permission:assemble_document': 'true', 'xmpTPg:NPages': '16', 'pdf:hasXMP': 'true', 'pdf:charsPerPage': ['5080', '8647', '7249', '349', '6806', '5847', '4697', '8242', '340', '5601', '331', '2701', '876', '3591', '9060', '8038'], 'access_permission:extract_content': 'true', 'access_permission:can_print': 'true', 'CrossMarkDomains[2]': 'sciencedirect.com', 'X-TIKA:parse_time_millis': '264', 'access_permission:can_modify': 'true', 'pdf:docinfo:created': '2023-02-07T18:16:11Z', 'CrossmarkMajorVersionDate': '2010-04-23'}, 'content': '\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nMel Spectrogram-based advanced deep temporal clustering model with unsupervised data for fault diagnosis\\n\\n\\nExpert Systems With Applications 217 (2023) 119551\\n\\nAvailable online 13 January 2023\\n0957-4174/© 2023 The Authors. Published by Elsevier Ltd. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-\\nnc-nd/4.0/).\\n\\nMel Spectrogram-based advanced deep temporal clustering model with \\nunsupervised data for fault diagnosis \\n\\nGeonkyo Hong , Dongjun Suh * \\n\\nDepartment of Convergence & Fusion System Engineering, Kyungpook National University, Sangju 37224, South Korea   \\n\\nA R T I C L E  I N F O   \\n\\nKeywords: \\nAnomaly detection \\nData augmentation \\nFault diagnosis \\nMel spectrogram \\nTime series \\nUnsupervised learning \\n\\nA B S T R A C T   \\n\\nFault diagnosis of mechanical equipment using data-driven machine learning methods has been developed \\nrecently as a promising technique for improving the reliability of industrial systems. However, these methods \\nsuffer from data sparsity due to the difficulty in data collection, which limits the feature extraction of anomalies. \\nTo solve this problem, we propose the mel spectrogram-based advanced deep temporal clustering (ADTC) model, \\nwhich can extract and verify the features of unlabeled data through an unsupervised learning based autoencoder \\nand the K-means. In addition, the ADTC model uses the proposed centroid based learning to obtain calibrated \\nunsupervised learning data by minimizing the data point and target centroid distances for misclustered encoder \\noutput features in ensemble-based unsupervised learning. The classifier of the ADTC model uses a supervised \\nlearning based deep support vector machine network model, which is robust to nonlinear data, to diagnose the \\nfaults of the mechanical equipment. The proposed ADTC model was validated using mechanical equipment \\ndataset with data augmentation to address the imbalanced dataset problem. During experiments, the mel \\nspectrogram-based ADTC model exhibited the best performance in the various industrial environment with a \\nprediction accuracy as high as 98.06%, outperforming other compared algorithms.   \\n\\n1. Introduction \\n\\nThe use of industrial systems to control mechanical equipment has \\nincreased manifold and has resulted in fresh complexities and un-\\ncertainties in the industrial environment. Consequently, the accurate \\ndiagnosis and prediction of faults in mechanical equipment is essential \\nfor performing effective maintenance and repairs to improve their reli-\\nability and productivity as well as reduce overall maintenance costs (Liu \\n& Liu, 2003; Tung & Yang, 2009). \\n\\nWith recent advancements in artificial intelligence and big data in \\nthe field of fault diagnosis for efficient system utilization, interest in \\nintelligent data-driven machine learning technology with high accuracy \\nand easy access is increasing (Chalapathy & Chawla, 2019; Pang, Shen, \\nCao, Hengel, & Den., 2021). However, despite the promising perfor-\\nmance reported in previous studies, the major shortcoming of data- \\ndriven fault diagnoses lies in the limitation of learning using a large \\namount of data (Shyu, Chen, & Iyengar, 2020). In industrial sites, only a \\nlimited amount of machine data can be collected, and abnormal datasets \\n\\nwith defects are more challenging to collect than normal datasets (Fahim \\n& Sillitti, 2019). Because of imbalanced data, the feature extraction of \\nanomalies is also limited. \\n\\nTherefore, several studies have considered the sparseness of data in \\nreal environments by performing unsupervised learning-based failure \\ndiagnosis classification. (Wu, Zhang, Cheng, & Peng, 2021) performed \\nmachine turbine diagnostics with autoencoder (AE) models using a \\nsoftmax classifier that reduces the reliance on unlabeled data. (Yang, \\nKarimi, & Sun, 2021) implemented a wide kernel-based convolutional \\nAE to learn features from raw signals important for diagnosing me-\\nchanical faults. (Liu et al., 2018) diagnosed faults by training the latent \\ncoding space on bearing training data using a categorical adversarial AE \\nbased on unsupervised learning. (Tao, Wang, Chen, Stojanovic, & Yang, \\n2020) generated spurious short time Fourier transform data from a \\nCatGAN model and clustered the machine dataset for fault diagnosis. \\nAlthough this study applied unsupervised learning to overcome the \\nlimitations of supervised learning when data are sparse, the accuracy \\nwas reduced when the model was applied to other domains. To date, \\n\\nPeer review under responsibility of Submissions with the production note ‘Please add the Reproducibility Badge for this item’ the Badge and the following footnote \\nto be added:The code (and data) in this article has been certified as Reproducible by the CodeOcean: https://codeocean.com. More information on the Reproduc-\\nibility Badge Initiative is available at https://www.elsevier.com/physicalsciencesandengineering/computerscience/journals. \\n\\n* Corresponding author. \\nE-mail addresses: gun2399@knu.ac.kr (G. Hong), dongjunsuh@knu.ac.kr (D. Suh).  \\n\\nContents lists available at ScienceDirect \\n\\nExpert Systems With Applications \\n\\njournal homepage: www.elsevier.com/locate/eswa \\n\\nhttps://doi.org/10.1016/j.eswa.2023.119551 \\nReceived 20 August 2022; Received in revised form 17 December 2022; Accepted 11 January 2023   \\n\\nmailto:gun2399@knu.ac.kr\\nmailto:dongjunsuh@knu.ac.kr\\nwww.sciencedirect.com/science/journal/09574174\\nhttps://www.elsevier.com/locate/eswa\\nhttps://doi.org/10.1016/j.eswa.2023.119551\\nhttps://doi.org/10.1016/j.eswa.2023.119551\\nhttps://doi.org/10.1016/j.eswa.2023.119551\\nhttp://crossmark.crossref.org/dialog/?doi=10.1016/j.eswa.2023.119551&domain=pdf\\nhttp://creativecommons.org/licenses/by-nc-nd/4.0/\\nhttp://creativecommons.org/licenses/by-nc-nd/4.0/\\n\\n\\nExpert Systems With Applications 217 (2023) 119551\\n\\n2\\n\\nexisting studies have not considered multiple environmental conditions \\nfor mechanical equipment fault diagnosis and have focused on only one \\nor two types of datasets corresponding to the mechanical equipment \\nused for verification, limiting the adaptation of the results to other do-\\nmains. When a data-driven model performs fault diagnosis, imbalance in \\nthe data can have a high impact on the performance of the model. \\nVarious studies have been conducted to analyze and solve the problems \\nassociated with imbalanced data (Johnson & Khoshgoftaar, 2019). \\n(Shorten & Khoshgoftaar, 2019) reported that overfitting occurs during \\nnetwork training when the model learns a function with a very large \\nvariance because deep neural networks (DNNs) are strongly dependent \\non the data. Hence, deep learning frameworks that use data augmen-\\ntation are required to improve the size and quality of the datasets. Chen \\nand Jin (Chen & Jin, 2019) increased the performance accuracy of a \\nmodel via data augmentation for highly imbalanced data. (Mikołajczyk \\n& Grochowski, 2018) maximized model efficiency by applying various \\ndata augmentation methods to solve the imbalance issue. (Li, Li, Qu, & \\nHe, 2020) diagnosed gear defects using a deep sparse AE model with \\ndata augmentation. (Li, Li, & Ma, 2020) conducted a diagnostic study \\nusing data augmentation and unsupervised data exploration to reduce \\nthe effects of imbalanced data and sparsity on the generalization per-\\nformance of an intelligent diagnostic model. \\n\\nTo overcome the data sparsity problem in this study, data augmen-\\ntation is performed on a time-series-based vibration dataset, and unla-\\nbeled datasets are explored by combining the unsupervised learning- \\nbased autoencoder (AE) model and the K-means algorithm. In the un-\\nsupervised learning process, K-means is used to evaluate data features \\nextracted from the encoder of the AE model. The K-means clustering \\nmakes it possible to know in advance how the data points extracted from \\nthe encoder of AE model affect the performance. By extracting data \\nfeatures through unsupervised learning, experiments can be performed \\nthat consider the real industrial environment, which has sparse data. \\nThis approach can use mel spectrogram image based unsupervised data \\nto identify the characteristics of the fundamental structure of insufficient \\ndata, contributing to machine learning-based fault diagnosis using a \\nmechanical equipment dataset. It also solves the domain adaptability \\nproblem by extracting unsupervised learning-based data that do not \\ndepend on a single target value from the sparse mechanical equipment \\ndataset. Data points that are not included in the target centroid derived \\nthrough K-means are weighted by training the proposed deep neural \\nnetwork (DNN) model using centroid-based learning so that they are \\nmoved closer to the target centroid. This method contributes to the \\nperformance of the final classifier model by obtaining high-quality \\nfeatures of the dataset. In the deep support vector machine network \\n(DSVMN) classifier model, the output data of the encoder with added \\nweights, which are not included in the target cluster, and the encoder \\noutput data, which are included in the target centroid obtained by K- \\nmeans, are combined and used as the input value. On the basis of this \\nalgorithm, we propose the mel spectrogram image-based advanced deep \\ntemporal clustering (ADTC) model that can perform fault diagnosis \\nusing a class for each type of nonlinear-based mechanical equipment. \\nThe mel spectrogram-based image is used as the input value of the model \\nto overcome the problem of combining a long length of data and com-\\nplex frequency according to the sampling rate of the existing signal- \\nbased data in machine learning-based prediction. The image visualiza-\\ntion method using the mel spectrogram, obtained by pre-processing the \\nraw signals, performs signal processing on high-dimensional and com-\\nplex raw audio signals, thereby scaling high and low frequencies to \\nenable a representation of the datasets in the frequency domain. In \\naddition, this method is widely used to improve performance in machine \\nlearning-based models for sound recognition through sound feature \\nextraction (Tran & Lundgren, 2020; Arias-Vergara et al., 2021; Wang, \\nXue, Culhane, Diao, Ding, & Tarokh, 2020). Therefore, in this study, \\nnormal and abnormal data were identified using a representation in the \\nfrequency domain with the mel spectrogram-based mechanical equip-\\nment dataset. In validation experiments, the mel spectrogram image- \\n\\nbased model reflected various conditions of the industrial environ-\\nment and diagnosed defects better than the raw signal-based model. The \\nexperimental results indicate that the proposed method provides supe-\\nrior performance in environments with various loads, noise signals, and \\nlengths, thus indicating its application potential for industrial purposes. \\nThe contributions of this study are as follows.  \\n\\n• By verifying the unsupervised data extracted using the autoencoder \\nthrough clustering, a high performance accuracy can be achieved for \\nsparse mechanical equipment data.  \\n\\n• The proposed method can solve data sparsity and data imbalance \\nproblems using the DNN model to calibrate feature values for me-\\nchanical equipment that are not extracted well in unsupervised \\nlearning.  \\n\\n• The proposed method exhibits superior performance and shows a \\ngeneralization of fault diagnosis for various mechanical equipment \\nby overcoming data sparsity.  \\n\\n• To overcome the problems of data sparsity and imbalance in the \\nlimited datasets obtained in actual industrial sites, it is possible to \\nincrease the performance of the proposed ADTC model by aug-\\nmenting the mechanical equipment dataset.  \\n\\n• The proposed approach solves the domain adaptability problem by \\nextracting the features of the fundamental structure of the sparse \\nmechanical equipment dataset using time–frequency based mel \\nspectrogram image through unsupervised learning in advance and \\nuses supervised learning to improve the performance of fault \\ndiagnosis. \\n\\n• The robustness of the model was verified by demonstrating the su-\\nperior performance of the proposed ADTC model through experi-\\nments varying the length, load, and levels of noise of various \\nmechanical equipment datasets obtained in an industrial \\nenvironment. \\n\\nThe remainder of this paper is organized as follows: Section 2 pro-\\nvides a detailed review of existing work, Section 3 presents and describes \\nthe proposed ADTC model. Section 4 outlines the experiments con-\\nducted and analyzes the results obtained. Finally, Section 5 summarizes \\nour conclusions and suggests directions for future studies in this field. \\n\\n2. Related work \\n\\nNumerous studies have been conducted to assess and ensure the \\nreliability and safety of data-driven fault diagnosis of mechanical \\nequipment. (Rauber, da Silva Loca, & de Boldt, 2021) compared and \\nanalyzed the diagnostic performance of K-nearest neighbor, one- \\ndimensional (1D) convolutional neural network (CNN), support vector \\nmachine (SVM), and random forest models using bearing data. (Brito, \\nSusto, Brito, & Duarte, 2022) performed feature importance analysis \\nthrough unsupervised learning-based machine fault diagnosis and \\nShapley additive explanations (SHAP) using frequency-based datasets to \\nprovide insight for each module. (Yang et al., 2021) performed feature \\nextraction using an unsupervised learning-based deep belief network to \\ndiagnose faults in gearboxes and bearings, and partial least squares was \\nused to optimize the supervised learning process to improve classifica-\\ntion. (Saufi et al., 2020) diagnosed faults using a time–frequency based \\nSSAE model with a limited number of samples to detect gearbox faults. \\n(Varga, 2017) detected defects using a Large Memory Storage Retrieval \\nmodel (LAMSTAR) based on signal processing-based short time fourier \\ntransform (STFT) data to detect the health status of bearings. (Sun, Yan, \\n& Wen, 2018) applied nonlinear projection by compressing the data to \\nidentify defects in rotating machines. These data were used to perform \\nfault diagnosis through the autoencoder. (Li, Zhang, & Ding, 2019) \\nemployed an attention mechanism to find information data segments \\nand extract the identification function of the input to diagnose the defect \\nof a rolling bearing. (Sohaib, Kim, & Kim, 2017) used a sparse stacked \\nautoencoder (SAE)-based hybrid method to effectively diagnose bearing \\n\\nG. Hong and D. Suh                                                                                                                                                                                                                            \\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119551\\n\\n3\\n\\nfaults of different severities. Although the above study performed data- \\nbased mechanical fault diagnosis, it did not consider various environ-\\nments, and it has limitations because it did not test the adaptability of \\nthe method to other conditions such as noise and various loads in the \\nactual industrial environment. \\n\\nMany other studies have considered domain adaptability. (Xiao \\net al., 2021) diagnosed mechanical faults using the proposed the noisy \\ndomain adaptive marginal stacking denoising AE(NDAmsDA) model for \\nnoise domain adaptation. (Qian, Qin, Wang, & Liu, 2021) overcome a \\nnoisy environment with a convolutional AE, called CAE-DLTN, which \\nuses Correlation Alignment (CORRE) to integrate domains. These \\nstudies addressed adaptability by performing fault diagnosis on noise, \\nbut there is a possibility of overfitting in a specific domain. (Li, Zhang, \\nDing, & Sun, 2019) minimized the multi-kernel maximum mean (MMD) \\nof multiple layers for the learned representation in supervised learning \\nto perform domain adaptability for bearing data. (Li, Hu, Zheng, Li, & \\nMa, 2021) evaluated the performance of domain adaptability for \\nbearing data through central moment mismatching using a convolu-\\ntional neural network-based model. (Chen, Zhao, He, Wei, & Yang, \\n2022) proposed a method for unsupervised learning-based bearing \\ndomain adaptability using the join sliced Wasserstein distance approach, \\nwhich considers conditional probabilities. To overcome the limitations \\nof previous studies, we consider the domain adaptation of industrial \\nsystems through fault diagnosis using mel spectrogram images reflecting \\nvarious lengths, loads, and levels of noise of bearing and industrial \\nmachines. \\n\\n3. Proposed method \\n\\nFig. 1 shows the proposed method for fault diagnosis of mechanical \\nequipment. In this study, augmented mel spectrogram image-based \\nlearning data were used to overcome the data sparsity and data imbal-\\nance problems found in industry and machine learning-based methods. \\nIn addition, data sparseness can be overcome by extracting the features \\nof the fundamental structure of the data in advance through unsuper-\\nvised learning using these data. Diagnostic performance can further be \\nimproved by correcting the features of datasets that include inaccurate \\nfeatures using supervised learning. \\n\\n3.1. Dataset formulation \\n\\nEq. (1) for the augmented mel spectrogram image-based input data \\nDusk=1 of the feature extractor model based on the first unsupervised \\nlearning model (k = 1) is defined as n data samples as follows. More-\\nover, these input data xusk=1\\n\\ni in Eq. (2) can be expressed using Nusk=1 di-\\nmensions as follows. \\n\\nDusk=1 = {xusk=1\\ni }\\n\\nn\\ni=1 (1)  \\n\\nxusk=1\\ni ∈ RNusk=1\\n\\n(2) \\n\\nThe input data Dusk=2 of the second unsupervised learning-based \\nmodel (k = 2) for feature verification is defined as n data samples as \\nfollows in Eq. (3), where these data xusk=2\\n\\ni in Eq. (4) can be expressed \\nusing Nusk=2 dimensions. \\n\\nDusk=2 = {xusk=2\\ni }\\n\\nn\\ni=1 (3)  \\n\\nxusk=2\\ni ∈ RNusk=2\\n\\n(4) \\n\\nThe input data Dsk=1 of the first supervised learning-based model (k =\\n\\n1), which uses centroid learning in Eq. (5), is defined as n, where the \\ninput data in xsk=1\\n\\ni can be expressed as Nsk=1 in Eq. (6). \\n\\nDsk=1 = {xsk=1\\ni }\\n\\nn\\ni=1 (5)  \\n\\nxsk=1\\ni ∈ RNsk=1\\n\\n(6) \\n\\nThe second supervised learning model (k = 2) takes input data Dsk=2 \\n\\nin Eq. (7), which consists of features extracted by the ensemble model, is \\nrepresented by n data samples and ysk=2\\n\\ni represents the label corre-\\nsponding to xsk=2\\n\\ni . The input data xsk=2\\ni in Eq. (8) of the supervised \\n\\nlearning-based DSVMN classifier model can be represented using Nsk=2 \\n\\ndimensions. \\n\\nDsk=2 = {xsk=2\\ni , ysk=2\\n\\ni }\\nn\\ni=1 (7)  \\n\\nxsk=2\\ni ∈ RNsk=2\\n\\n(8) \\n\\nIn the experiment, a 4D image-based input is output in 2D through \\nthe encoder and used as input for the K-means based feature validator, \\nDNN-based centroid based learning, and DSVMN classifier model. In \\naddition, because the dimensions of the input of the unsupervised \\nlearning-based feature validator are the same as the dimensions of the \\noutput, the dimensions of the input of the supervised learning-based \\ncentroid learning model and classifier correspond. Therefore, the input \\ndimensions of each model can be defined as Eq. (9). The same conditions \\nfor the training data and validation data of all mechanical equipment \\ndatasets were used for all data spaces Dusk=1 , Dusk=2 , Dsk=1 , and Dsk=2 . \\n\\nNusk=1 > Nusk=2 = Nsk=1 = Nsk=2 (9)  \\n\\n3.2. Proposed method overview \\n\\nIn this section, we propose an ADTC model and mel spectrogram \\nimage-based algorithm that overcomes the problem of data sparsity and \\nachieves the best performance on mechanical equipment datasets with \\nvarious loads, noise signals, and time/length conditions. The detailed \\nmethod of the proposed fault diagnosis is illustrated in Fig. 1 and Al-\\ngorithm 1. The data were augmented to solve the imbalanced data \\nproblem in the time-series-based Case Western Reserve University \\n(CWRU) bearing dataset and Malfunctioning Industrial Machine Inves-\\ntigation and Inspection (MIMII) dataset. The augmented datasets were \\nconverted into mel spectrogram images. Mel spectrogram image based \\nunsupervised learning can solve the problem of data sparsity by \\nextracting the features of the underlying structure, even with a small \\namount of data. It also helps address domain adaptability problems and \\nimproves performance by diagnosing faults using a data-driven ma-\\nchine-learning approach. \\n\\nThe mel spectrogram based proposed model can extract features \\nfrom unsupervised data using the AE and K-means algorithm to over-\\ncome the data sparsity problem in real industry. In addition, we can \\ngenerate high-quality data as feature vectors using several unsupervised \\nlearning models (Rajoub, 2020; Stevenson, Mues, & Bravo, 2021; \\nTavakoli & Heydarian, 2022; Zhang et al., 2022). \\n\\nThe encoder and decoder of the AE model are composed of 2D CNN \\nand long short-term memory (LSTM) layers. In a 2D CNN, we extract \\nvisual patterns from mel spectrogram images and use LSTM to learn time \\nseries-based features. The AE is trained using normal data, and abnormal \\ndata values are predicted after learning the difference between the input \\nvalue of the encoder and the reconstructed output value. Using this \\nmethod, it is possible to solve the “curse of dimensionality” problem \\nfrequently encountered in deep learning by mapping input values into a \\nlow-dimensional space and learn the features of mechanical equipment \\ndata in an unsupervised manner. The low-dimensional points predicted \\nby the learned encoder are used as input for the K-means algorithm, \\nDNN, and DSVMN. \\n\\nThe K-means algorithm is used to validate unsupervised data using \\nthe output value of the encoder. Using the existing K-means algorithm to \\npredict a mechanical equipment dataset with many classes and high \\nlevels of noise yields results with low accuracy. In this model, mis-\\nclustered feature data reduce the performance. Therefore, the output \\nvalue of the encoder corresponding to misclustered feature data is used \\nas the input value of the DNN. \\n\\nThe DNN model with four fully connected layers based on the pro-\\n\\nG. Hong and D. Suh                                                                                                                                                                                                                            \\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119551\\n\\n4\\n\\nFig. 1. Proposed method for mechanical equipment fault diagnosis.  \\n\\nG. Hong and D. Suh                                                                                                                                                                                                                            \\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119551\\n\\n5\\n\\nposed Euclidean distance loss of the target centroid coordinate values is \\nused to assign weights for each class to the machine equipment data \\npoints not included in the target cluster. By making the number of DNN \\nmodels equal to the number of machine equipment classes, the target \\ncentroid distances are learned well.  \\n\\nAlgorithm. 1. Proposed Method \\n\\nStep 1: Input Value \\nNumber of mel spectrogram image datasets with data augmentation \\nDusk=1 = {xusk=1\\n\\ni }\\nn\\ni=1 x\\n\\nusk=1\\ni ∈ RNusk=1 \\n\\nStep 2: Unsupervised learning based on the feature extractor \\nInput image {xusk=1\\n\\ni }\\nn\\ni=1 to the AE to extract the latent variable vector \\n\\nDusk=2 = {xusk=2\\ni }\\n\\nn\\ni=1, xusk=2\\n\\ni ∈ RNusk=2 \\nof the encoder. \\n\\nfor epoch = 1,2,3,…, k do \\nUpdate θe, θde using Equations (12)–(17) and the data {xusk=1\\n\\ni }\\nn\\ni=1 \\n\\nend for \\nOutput: Predicted value Dusk=2 = {xusk=2\\n\\ni }\\nn\\ni=1, xusk=2\\n\\ni ∈ RNusk=2 \\nusing the {xusk=1\\n\\ni }\\nn\\ni=1 \\n\\ndataset \\nStep 3: Unsupervised learning based on the feature validator \\nExtract the feature value ED(i,j) of the distance between the centroid μj and \\n{xusk=2\\n\\ni }\\nn\\ni=1 as the input for the K-means algorithm. \\n\\nInitialize: centroids μj, number of data samples allocated to the center μNassignment\\nj , \\n\\nnumber of samples by class Nclass,  \\nWhile True do: \\nfor t = 1,2,3,…, n do \\n\\nS(t)\\ni = {xusk=2\\n\\ni :\\n\\n⃒\\n⃒\\n⃒xusk=2\\n\\ni − μ(t)\\ni\\n\\n⃒\\n⃒\\n⃒\\n2\\n≤\\n\\n⃒\\n⃒\\n⃒xusk=2\\n\\ni − μ(t)\\nj\\n\\n⃒\\n⃒\\n⃒\\n2\\n∀j,1 ≤ j ≤ k} using Equation (18) \\n\\nμ(t+1)\\nj =\\n\\n1\\n⃒\\n⃒\\n⃒S(t)\\n\\ni\\n\\n⃒\\n⃒\\n⃒\\n\\n∑\\n\\nxusk=2\\ni ∈S(t)\\n\\ni\\n\\nxusk=2\\ni if μ(t)\\n\\nj = μ(t+1)\\nj do \\n\\nuntil Convergence \\nend for \\nif μNassignment\\n\\nj <= Nclass*0.5 then \\nContinue \\nelse \\nBreak \\nend for \\nOutput: Dsk=1 = {xsk=1\\n\\ni }\\nn\\ni=1← Misclustered(Dusk=2 = {xusk=2\\n\\ni }\\nn\\ni=1), \\n\\nClustered(Dusk=2 = {xusk=2\\ni }\\n\\nn\\ni=1)\\n\\nStep 4: Centroid based learning \\nIn the DNN, the fault diagnosis of mechanical equipment is performed using the \\nlearned the mapping target centroid μj and the extracted feature Dsk=1 = {xsk=1\\n\\ni }\\nn\\ni=1 ← \\n\\nMisclustered(Dusk=2 = {xusk=2\\ni }\\n\\nn\\ni=1), x\\n\\nsk=1\\ni ∈ RNsk=1 \\n\\nfor epoch = 1,2,3,…, k do \\nUpdate θC using Equation (20)-(22) \\nend for \\nOutput: Predicted θC*Misclustered(Dusk=2 = {xusk=2\\n\\ni }\\nn\\ni=1)\\n\\nStep 5: Classifier for fault diagnosis \\nIn the DSVMN, the fault of mechanical equipment with j = m classes is diagnosed \\nusing the extracted feature θC*Misclustered(Dusk=2 = {xusk=2\\n\\ni }\\nn\\ni=1), \\n\\nClustered(Dusk=2 = {xusk=2\\ni }\\n\\nn\\ni=1)\\n\\nfor epoch = 1,2,3,…, k do \\nUpdate θs using Equations (23)–(25) \\nend for \\nOutput: Predicted {{ysk=2\\n\\ni }\\nn\\ni=1}\\n\\n′\\n\\nIn this method, it is possible to obtain data in which weights have been \\nadded to feature points using the fault clustering results of the encoder \\noutput. The proposed method can solve data sparsity and data imbal-\\nance problems by correcting the feature values for mechanical equip-\\nment that are not extracted well in unsupervised learning using DNN \\nmodels. It is possible to achieve generalization and robustness in in-\\ndustrial environments. \\n\\nThe weighted encoder output data not included in the target centroid \\nand the encoder output data of the target centroid, are combined and \\ninput to the DSVMN classifier. A radial basis function (RBF) kernel- \\nbased SVM, which can classify multiple nonlinear feature spaces, has \\nbeen widely used for detecting anomalies in mechanical equipment \\n(Han, Zhang, Yin, & Tan, 2021; Miao, Zhang, Lin, Zhao, Liu, Liu, & Li, \\n2022; Wang, Yao, Chen, & Ding, 2021; Yao, Fang, Xiao, Hou, & Fu, \\n2021). The proposed DSVMN converts the existing SVM into a neural \\nnetwork. The input layer of this model is an RBF kernel layer that can \\n\\ntransform a nonlinear feature space into a linear classification space and \\nmaps the mechanical equipment feature data extracted from unsuper-\\nvised learning to a Gaussian space. The feature values obtained through \\nthese layers pass through the second layer, a fully connected layer, the \\nthird layer, a dropout layer to prevent overfitting, and the last layer, \\nwith is a fully connected layer that classifies normal data and abnormal \\ndata. In the DSVMN model, normal data and abnormal data are classi-\\nfied according to the labels in the data using the features learned by the \\nensemble feature extractor. In addition, K-fold cross-validation is per-\\nformed to prevent overfitting of the DSVMN model. In this way, a su-\\npervised learning method based on unsupervised data can solve the \\nproblem of domain adaptability for mechanical equipment data. \\n\\n3.3. Feature extractor for unsupervised data \\n\\nThe proposed 2D CNN-LSTM-based AE model is trained on data \\n{xusk=1\\n\\ni }\\nn\\ni=1 to extract features in order to obtain a low-dimensional, high- \\n\\nlevel data space. {xusk=1\\ni }\\n\\nn\\ni=1 comprises normal and abnormal data for the \\n\\nfault diagnosis of mechanical equipment. In an AE, features are extrac-\\nted from the input using an encoder network. The compressed feature \\nvector is restored to the size of the input vector through the decoder and \\na high-dimensional value is output. The input value is defined as \\n{xusk=1\\n\\ni }\\nn\\ni=1, the feature value extracted from the encoder is z({xusk=1\\n\\ni }\\nn\\ni=1)\\n\\nvalue in Eq. (10), the encoder parameter is θe, the decoder output value \\nx′ can be expressed as Eq. (11) and the decoder parameter is θde. The \\ndecoder output x′ is the output of the AE. The AE can be used to solve \\ndata sparsity problems by extracting unsupervised data features that \\nreflect the underlying structure of the data. In addition, it can improve \\nthe adaptability of the model to mechanical equipment data with \\nvarious characteristics. \\n\\nz({xusk=1\\ni }\\n\\nn\\ni=1) ={xusk=2\\n\\ni }\\nn\\ni=1 (10)  \\n\\nx\\n′\\n\\n= h(z\\n(\\n{xusk=1\\n\\ni }\\nn\\ni=1\\n\\n))\\n(11) \\n\\nIn this study, the auto encoder extracts features of the time series- \\nbased mechanical equipment datasets using 2D CNNs and LSTMs. In \\nthe encoder, there are convolutional layers with 128, 64, and 32 filters, \\nmaxpooling layers, and an LSTM layer. The decoder has a structure \\nsymmetrical to that of the encoder, where an upsampling layer is used \\ninstead of the maxpooling layer. We optimize the loss function of AE LAE \\n\\nto obtain the output, which is sent to the K-means, DNN, and DSVMN in \\nthe fully connected layer, where the bottleneck between the encoder and \\ndecoder occurs. In Eq. (12) and Eq. (13) for optimizing the auto-encoder \\nloss function LAE and parameters θe, and θde are as follows. \\n\\nLAE =\\n1\\nn\\n\\n∑n\\n\\ni=1\\n(xus1\\n\\ni − x′\\n\\ni)\\n2 (12)  \\n\\nθ\\n′\\n\\ne, θ\\n′\\n\\nde = argmin\\nθ′e ,θ\\n\\n′\\n\\nde\\n\\nLAE(θe, θde) (13) \\n\\nAdadelta gradient descent was used to learn the unsupervised data \\nby optimizing the parameters of the AE feature extractor. \\n\\nG(t)←γG(t − 1)+ (1 − γ)(\\n∂LAE\\n\\n∂(θe, θde)\\n)\\n\\n2 (14)  \\n\\nΔ(θe, θde)←\\n̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅\\nΔS(t − 1)+\\n\\n√\\n∊\\n\\n̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅\\nG(t) + ∊\\n\\n√ *\\n∂LAE\\n\\n∂(θe, θde)\\n(15)  \\n\\nS(t)← γS(t − 1)+ (1 − γ)Δ(θe, θde)\\n2 (16)  \\n\\nθe, θde ← θe, θde − Δ(θe, θde) (17) \\n\\nHere, G(t) is the exponential mean function and γ represents the step \\nsize in Eq. (14). To adjust the learning rate of Adadelta gradient descent, \\nwe use Δ(θe, θde) and S(t) in Eq. (15) and Eq. (16), which decrease the \\n\\nG. Hong and D. Suh                                                                                                                                                                                                                            \\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119551\\n\\n6\\n\\nlearning rate according to the change in weight Eq. (17). Adadelta can \\nbe used to obtain high-level feature vectors z({xusk=1\\n\\ni }\\nn\\ni=1). \\n\\n3.4. Feature validator for unsupervised data \\n\\nWe propose a K-means clustering method to validate the features of \\nthe unsupervised data. Distance measurement learning using the K- \\nmeans clustering approach is used to validate the feature extraction. In \\nthis study, the feature extracted by the encoder is used as the input of the \\nK-means model. This method contributes to the domain adaptability by \\nevaluating sparse data. We use the low-dimensional, high-quality \\ndataset Dusk=2 obtained from the encoder to learn the Euclidean distance \\nbetween the data and cluster centroids in Eq. (18). The cluster centroids \\nare expressed as {μi}\\n\\ni=Nc\\ni=1 clusters, where Nc is the number clusters. In \\n\\naddition, the Nc of the high-quality feature vector is equal to the number \\nof classes in the dataset. In this step, for verification, an iterative opti-\\nmization method is proposed to evaluate the quality of the data by \\nobtaining Misclustered(Dusk=2 = {xusk=2\\n\\ni }\\nn\\ni=1), which are the data that do \\n\\nnot belong to the target centroid according to the unsupervised data \\npoints, and Clustered(Dusk=2 = {xusk=2\\n\\ni }\\nn\\ni=1), which have been clustered \\n\\ninto the target centroid in Eq. (19). Unsupervised data with poor clus-\\ntering, i.e., Misclustered(Dusk=2 = {xusk=2\\n\\ni }\\nn\\ni=1), is used as the input value \\n\\nfor centroid based learning. The clustering results on unsupervised data \\nperformed well because the features were extracted from the encoder \\nusing the mel spectrogram images. In addition, we initialized the k- \\nmeans to cluster when the number of data samples allocated to the \\ncentroid of the k-means is less than 50 % of the number of samples \\ncorresponding to the class to ensure the stability of the model. \\n\\nED(i,j) =\\n∑Nc\\n\\nj=1\\n\\n∑n\\n\\ni=1\\n‖xusk=2\\n\\ni − μj‖\\n2 (18)   \\n\\n3.5. Centroid based learning using unsupervised data \\n\\nThe Misclustered(Dusk=2 = {xusk=2\\ni }\\n\\nn\\ni=1) data points that are not clus-\\n\\ntered into the target centroid were obtained through the K-means al-\\ngorithm. These data points have unclear characteristics and can \\nadversely affect the supervised learning-based fault diagnosis perfor-\\nmance. Therefore, we propose a DNN algorithm that uses the Euclidean \\ndistance loss function to map the misclustered data points to the co-\\nordinates of the target centroid through weights. The proposed DNN \\nconsists of five fully connected layers, and each layer consists of 128, 64, \\n32, 16, and 300 nodes. The Eq. (20), Eq. (21), and Eq. (22) for the loss \\nfunction and weight parameter θC for mapping the data point to the \\ncoordinates of the optimized target centroid are as follows. \\n\\nLED(i,j) =\\n∑Nc\\n\\nj=1\\n\\n∑n\\n\\ni=1\\n‖xusk=1\\n\\ni − μj‖\\n2 (20)  \\n\\nθ\\n′\\n\\nC = argmin\\nθ′C\\n\\nLAE(θC) (21)  \\n\\nθC ← θC − δ\\n∂LED(i,j)\\n\\n∂θC\\n(22)  \\n\\n3.6. Classification for fault diagnosis using unsupervised data \\n\\nClassification is performed by the proposed supervised learning- \\nbased model using the misclustered dataset obtained from the centroid \\nbased learning DNN, the encoder’s output values, and the clustered \\nvalues. In the DSVMN model, mechanical equipment data are mapped in \\nGaussian space through the RBF kernel-based layer. It has the advantage \\nof improving the accuracy of the mechanical equipment fault diagnosis \\nclassification with the features previously extracted through spatial \\ntransformation. Parameter γ of the RBF kernel is responsible for regu-\\nlating the hyperparameters. In Eq. (23), γ as the nearest neighbor kernel, \\ncan adjust the distance between xsk=2\\n\\ni and xsk=2\\nj . In this experiment, γ is set \\n\\nto 0.001. The RBF kernel equation is as follows. \\n\\nRBF = exp(− γ‖xsk=2\\ni − xsk=2\\n\\nj ‖)\\n2 (23) \\n\\nIn Eq. (24), sj is the score of the incorrect mechanical equipment \\nlabel, sysk=2\\n\\ni \\nis the score of the true mechanical equipment label, and 1 is \\n\\nthe value of the hinge loss function Lsvm. Lsvm is used to regularize soft \\nmargin SVM for fault diagnosis. The Eq. (25) of parameter θc uses the \\nhinge loss Lsvm for optimized DSVMN mechanical equipment fault \\ndiagnosis classification, and it is expressed follows. \\n\\nLsvm =\\n∑\\n\\nj∕=yi\\n\\nmax(0, sj − sysk=2\\ni\\n\\n+ 1) (24)  \\n\\nθc←θc − δ\\n∂Lsvm\\n\\n∂θc\\n(25) \\n\\nThe number of nodes of the last fully connected layer is equal to the \\nnumber of classes, and the classes in the multi-class mechanical equip-\\n\\nment dataset are the predicted {{{ysk=2\\ni }\\n\\nn\\ni=1}\\n\\nj=m\\nj=1 }\\n\\n′\\n\\n. \\n\\n4. Experimental study \\n\\nIn this study, data augmentation was performed on the mechanical \\nequipment dataset to overcome the problems of data imbalance and data \\nsparsity. In addition, experiments were performed using mel spectro-\\ngram images, which yield better performance than the raw vibration \\ndataset. To consider the various environments of real industrial sites in \\nthe input values of the proposed ADTC model, five experiments were \\nconducted. The proposed ADTC model achieved the best performance in \\nvarious environments, proving its robustness. \\n\\n4.1. Data description and algorithm setup \\n\\nThis section describes the CWRU bearing dataset, the MIMII dataset, \\nand the Paderborn University bearing dataset used in the proposed \\nmethod for the fault diagnosis of mechanical equipment. \\n\\n4.1.1. CWRU bearing dataset \\nThe data in the CWRU bearing dataset were collected using an \\n\\naccelerometer on faults in the drive and fan ends of the motor bearing: \\ndefects were present in the rolling elements, inner race, and outer race of \\nthe bearings. In this dataset, each load was configured using 0, 1, 2, or 3 \\nhp at sampling frequencies of 12 or 48 kHz. In this experiment, only the \\nhigh frequency 48 kHz sampling data were used to conduct the effect- \\n\\nDsk=1 = {xsk=1\\ni }\\n\\nn\\ni=1←Misclustered(Dusk=2 = {xusk=2\\n\\ni }\\nn\\ni=1),Clustered(Dusk=2 = {xusk=2\\n\\ni }\\nn\\ni=1) (19)   \\n\\nG. Hong and D. Suh                                                                                                                                                                                                                            \\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119551\\n\\n7\\n\\ndefect diagnosis study. Furthermore, the 1, 2, and 3 hp datasets were \\nused in the experiment because there were missing values in the 0 hp \\ndataset. \\n\\n4.1.2. MIMII dataset \\nThe MIMII dataset consists of industrial machine data for valves, \\n\\npumps, fans, and slide rails. This dataset contains both normal and \\nabnormal data with a time period of 10 s. The abnormal data contain \\ncontamination leakage, rotational imbalance, and rail damage infor-\\nmation. All the sounds were recorded at 6, 0, or − 6 dB noise at a 16 kHz \\nsampling rate using a 16-bit microphone. \\n\\n4.1.3. Paderborn University bearing dataset \\nThe Paderborn University bearing dataset consists of normal data, \\n\\ndata for inner race faults, and data for outer race faults. This dataset \\nconsists of 1500 RPM and 900 RPM data (Kimotho, Lessmeier, Sextro, & \\nZimmer, 2016). Table 1 shows the abnormal data for the outer race \\nfatigue, which includes pitting and plastic deform indentations, and the \\ninner race fatigue, which includes pitting. In addition, the data for the \\nnormal state, as listed in Table 2, presents various run-in period, radial \\nload, and speed values. All vibration datasets were recorded at a 64 kHz \\nsampling rate. \\n\\n4.2. Data preprocessing \\n\\nThis section describes the sliding window augmentation method, \\naudio data augmentation method, and SSIM image data augmentation \\nverification method for overcoming the data sparsity of mechanical \\nequipment datasets. In addition, the mel spectrogram images used in the \\nfault diagnosis of mechanical equipment are explained. \\n\\n4.2.1. Data augmentation \\nData augmentation was applied to the CWRU, MIMII and Paderborn \\n\\nUniversity datasets in different ways to solve the data imbalance issue. \\nThe amount of data contained in the CWRU bearing dataset and \\nPaderborn University bearing dataset were not suitable for training the \\nmodels. To overcome the issue of overfitting that occurs owing to \\ninsufficient data, data augmentation was performed by applying a \\nsliding window technique in which a window length of 4096 and a step \\nsize of 64 were used to capture two bearing faults (Shenfield & Howarth, \\n2020). The number of samples in the original data was augmented by \\nvarying length and step, which improved the performance of the ma-\\nchine learning. In addition, this augmentation of the number of samples \\nimproved the adaptability to domains by enabling the model to learn \\nvarious features. Fig. 2 shows the sliding window method. In all the \\nexperiments, the overlapping parts of the windows were used for the \\ntraining dataset and the non-overlapping parts were used for the test \\ndataset. Table 3 lists the number of bearing datasets used in the exper-\\niments. In the MIMII dataset, the fault diagnosis performance of the \\nADTC model significantly decreased because of the data imbalance. \\nTherefore, audio augmentation (increasing the time, moving the time, \\nadding noise, and reducing the volume) was applied to the abnormal \\ndata of the MIMII dataset. Shifting, where the data start at a new point as \\na way to roll through the data, stretching, a method that increases data \\nlength, and adding noise, which adjusts the signal-to-noise ratio of the \\noriginal data, and a volume reduction method, in which the amplitude of \\nthe data is reduced, were applied to the industrial machine dataset. This \\n\\nTable 2 \\nPaderborn University bearing abnormal data.  \\n\\nBearing code Damage (main mode and symptom) Element type Combination of damage Arrangement Extent of damage Characteristic of damage No. Samples \\n\\nKA04 Fatigue: pitting Outer Race Single no repetition 1 Single 3969 \\nKA15 Plastic deform Indentations Outer Race Single no repetition 1 Single 3969 \\nKA16 Fatigue: pitting Outer Race Repetitive random 2 Single 3969 \\nKI04 Fatigue: pitting Inner Race Multiple no repetition 1 Single 3969 \\nKI14 Fatigue: pitting Inner Race Multiple no repetition 1 Single 3969 \\nKI16 Fatigue: pitting Inner Race Single no repetition 3 Single 3969 \\nKI18 Fatigue: pitting Inner Race Single no repetition 2 Single 3969  \\n\\nFig. 2. Sliding window method for data augmentation.  \\n\\nTable 3 \\nCWRU Bearing dataset.  \\n\\nFault type Inch No. of samples \\n\\nNormal N/A 11,426 \\n\\nBall Fault \\n0.007 \\n\\n11,426 0.014 \\n0.021 \\n\\nInner Race Fault \\n0.007 \\n\\n11,426 0.014 \\n0.021 \\n\\nOuter Race Fault \\n0.007 \\n\\n11,426 0.014 \\n0.021  \\n\\nTable 1 \\nPaderborn University bearing normal data.  \\n\\nBearing Code Run-in Period Radial Load [N] Speed [min] No. Samples \\n\\nK001 >50 1000–3000 1500–2000 3969 \\nK002 19 3000 2900 3969 \\nK003 1 3000 3000 3969  \\n\\nG. Hong and D. Suh                                                                                                                                                                                                                            \\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119551\\n\\n8\\n\\nindustrial machine vibration dataset can be used in various experiments \\nto creating datasets reflecting various environments. In the experiment, \\nthe augmented data and original data were used as the training dataset, \\nand the experiment was conducted using a part of the original data as \\nthe test set. \\n\\n4.2.2. Mel spectrogram \\nThe time–frequency-based mel spectrogram image method is widely \\n\\nused in the field of data-driven fault diagnosis in the case of noisy \\ndatasets because models using mel spectrogram images have shown \\nbetter performances as compared to the case in which raw signals were \\nused (Hong & Suh, 2021; Hossain, 2019). Therefore, the augmented raw \\nsignals of the bearing dataset and the industrial machine dataset were \\nconverted into a mel spectrogram image in this experiment. The hyper- \\nparameters used for this conversion were the sampling rate, mel band, \\nframe length, and frame stride. Mel bands of 80 and 40 were used for the \\nbearing dataset with a 48 kHz sampling rate and an industrial machine \\ndataset with a 16 kHz sampling rate. Additionally, frame lengths and \\nframe strides of 0.025 and 0.010 s, respectively, were used. The raw \\nsignal and converted mel spectrogram images are depicted in Fig. 3. In \\nthe mel spectrogram images, the x-axis indicates time and the y-axis \\nindicates the frequency. To express the raw signal as a mel spectrogram \\nimage, a fast Fourier transform is performed, and the window segment is \\nmapped from the time to the frequency domain through the parameters. \\nThe amplitude of the raw signal is converted into decibels and mapped \\nto the mel scale. The y-axis of the mel spectrogram represents the mel \\ndomain from 0 to 8192, and the x-axis represents the time of the data to \\nexpress the characteristics of the raw signal data as an image. By rep-\\nresenting it as an image, it is possible to extract easily recognizable \\nfeatures of data via machine learning. \\n\\n4.2.3. SSIM \\nThe structural similarity index method (SSIM) is used to measure the \\n\\nsimilarity to the original image with respect to the distortions caused by \\ncompression and transformation. This method was used in this study to \\ncompare the industrial machine image data to which audio augmenta-\\ntion was applied to the original images. The Eq. (26) used in this method \\ncan be expressed as follows (Channappayya, Bovik, & Heath, 2008): \\n\\nSSIM(x, y) =\\n(2μxμy + c1 )(2σxy + c2)\\n\\n(2μ2\\nx + μ2\\n\\ny + c1)(σ2\\nx + σ2\\n\\ny + c2)\\n(26)  \\n\\nwhere μx, μy, σ2\\nx , σ2\\n\\ny , and σxy represent the mean, variance, and covari-\\nance of x and y, respectively, and c1 and c2 are the normalization con-\\nstant and the contrast term. Based on the comparison of the original and \\naugmented image data using the SSIM method, only the dataset with an \\nSSIM of 90 % or higher was used as the input value of the DNN model. \\nTable 4 lists the number of augmented industrial machine dataset \\nsamples. \\n\\n4.3. Numerical experiment \\n\\nIn order to evaluate the ADTC model based on mel spectrogram \\nimage inputs, experiments were performed to evaluate the mel spec-\\ntrogram images, domain adaptability, bearing and industrial machine \\ndatasets, bearing analysis for different rotational speeds, and damage \\nanalysis. Various noise levels, lengths, loads, and RPM values were \\napplied to the mechanical equipment dataset in the experiments. The \\nresults show that the proposed ADTC model achieved the best perfor-\\nmance in the various cases. \\n\\n4.3.1. Performance analysis of mel spectrogram images \\nMany studies have revealed that the accuracy of deep learning can be \\n\\nimproved through data feature extraction in the time–frequency domain \\nby transforming the raw signals into mel spectrogram images (Oh, 2020; \\nPandey, Shekhawat, & Prasanna, 2019). Accordingly, a comparative \\n\\nanalysis according to data type was performed in this experiment using \\nthe ADTC model to establish that the fault diagnosis-based mel spec-\\ntrogram images exhibited a better performance than those based on a \\nfast Fourier transform (FFT) and raw signals. The raw signal, FFT, and \\nmel spectrogram image datasets were obtained under the same condi-\\ntions. The bearing dataset for the comparative analysis consisted of 1, 2, \\nand 3 hp and the industrial machine dataset was used with − 6, 0, and 6 \\ndB noise. The ADTC model in the experiment was used as a 1D con-\\nvolutional layer of AE according to the FFT and raw signal dimension \\nand as a 2D layer for the mel spectrogram image. The accuracy ac-\\ncording to data type is presented in Table 5. Evidently, the raw data had \\na mean accuracy of 81 %, whereas the mel spectrogram image data \\nshowed a mean accuracy of 98 %. The two types of datasets show similar \\ntrends corresponding to the respective conditions; the bearing data show \\nsimilar results for loads and the performance accuracy of the industrial \\nmachine data generally tends to decrease when a high volume of noise \\ndata is present. Overall, the results establish that the mel spectrogram \\nimage data are superior to the raw data. Therefore, these experimental \\nresults prove the superiority and necessity of diagnosing mechanical \\nequipment faults using the mel spectrogram image. Moreover, the pro-\\nposed mel spectrogram image-based fault diagnosis method surpasses \\nthe existing raw signal and FFT-based method and shows high potential. \\nClearly, fault diagnosis using time and frequency-based mel spectrogram \\nimages of bearing and industrial machine datasets can improve model \\naccuracy. \\n\\n4.3.2. Domain adaptation performance analysis \\nIn this experiment, the domain adaptation of the proposed mel \\n\\nspectrogram image-based ADTC model was evaluated with different \\nbearing loads. A single load sample was used as shown in Table 1, and an \\nexperiment was performed to compare and analyze domain adaptation \\ntests of other models. Table 6 shows the performance of the proposed \\nADTC model, SVM (Konar & Chattopadhyay, 2011), CNN-SVM (Xu, Ma, \\nZhang, Yang, Li, & Liu, 2019), denoising AE (DAE) (Li et al., 2019), deep \\nrepresentation clustering (DRC) (Li et al., 2020), and the models based \\non the results of the comparative analysis. The models, including the \\nSVM, exhibited a good overall performance. Additionally, each model \\nexhibited the robust adaptability to other loads when a 2 hp load is \\nlearned. When transfer learning was performed with each other, good \\nresults were obtained, whereas those for 1 and 3 hp showed poor results. \\nIn the prediction of each class in transfer learning, the remaining classes \\nshowed excellent predictions except for Ball 0.014 Fault and Ball 0.021 \\nFault. These results indicate that the Ball 0.014 Fault and Ball 0.021 \\nFault classes can become a factor in the performance degradation of \\nfault diagnosis when predicted through transfer learning using different \\nloads. Compared with the other models, the proposed ADTC model \\nexhibited the best results when transfer learning for each load was \\nperformed. Fig. 4 shows the confusion matrices for the transfer learning \\nof the proposed model. The confusion matrix shows the prediction ac-\\ncuracy of the model by comparing the predicted label and the actual \\nlabel for transfer learning according to the load of each bearing. It shows \\nthe best performance of the transfer learning experiment from 2 hp to 1 \\nhp, and shows the degraded performance of the model from 3 hp to 1 hp. \\nAs mentioned above, the predictions of Ball 0.014 Fault and Ball 0.021 \\nFault affect the accuracy. \\n\\n4.3.3. Bearing dataset analysis considering different noise levels \\nData obtained from real-life industrial locations using sensors are \\n\\ngenerally contaminated with noise, which reduces the accuracy of the \\ndata-driven fault diagnosis model (Tagawa, Maskeliūnas, & Dam-\\naševičius, 2021). Hence, a robustness test of the proposed mel spectro-\\ngram image-based model was conducted for various noise \\nenvironments. The bearing dataset for the robustness test was con-\\nstructed by applying noise to the original data corresponding to the \\nfollowing signal-to-noise ratios (SNRs): − 8, − 6, − 4, − 2, 0, 2, 4, 6, and 8 \\ndB. The Eq. (27) for the SNR signal is as follows: \\n\\nG. Hong and D. Suh                                                                                                                                                                                                                            \\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119551\\n\\n9\\n\\nFig. 3. Original raw signals and mel spectrogram images.  \\n\\nG. Hong and D. Suh                                                                                                                                                                                                                            \\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119551\\n\\n10\\n\\nSNRdB = 10log10(\\nPsignal\\n\\nPnoise\\n) (27)  \\n\\nwhere Psignal represents the average signal power and Pnoise represents the \\naverage noise power. We added white Gaussian noise according to the \\nSNR for each dataset to increase the noise levels of all of the samples for \\neach load. The performance evaluation of the proposed and comparative \\nmodels is shown in Table 7. Generally, the accuracy of the model \\ndecreased as the noise-power ratio increased to − 8 dB. Conversely, as \\nthe signal-power ratio became higher than the noise-power ratio and \\n\\napproached 8 dB, the accuracy of the model tended to increase. In \\nconclusion, bearing data containing noise can interfere with the diag-\\nnosis of inner and outer race defects of the bearing. However, through \\ncomparison with other models, it was proven that the proposed ADTC \\nmodel is robust and less susceptible to noise in real-life industrial \\nenvironments. \\n\\n4.3.4. Industrial machine dataset analysis considering different noise \\nAn experiment was performed to consider the effect of noise in a \\n\\ntime-series dataset of industrial machines. A large number of data \\nsamples tested previously produced significantly reduced accuracy of \\nthe model because of the imbalance in the data. Therefore, in this study, \\nthe fault diagnosis of an industrial machine was performed using the \\naugmented dataset presented in Table 4. The proposed mel spectrogram \\nimage-based model was evaluated using precision, recall, and F1 scores \\nwhile taking four comparative models and two data augmentation \\nmethods into consideration: the corresponding results are listed in \\nTable 8. Two data augmentation methods, as presented in Table 4, were \\napplied: Case 1, where only the abnormal data were augmented to \\nresolve the data imbalance, and Case 2, where both the normal and \\nabnormal data were augmented, but the data imbalance could not be \\nresolved. Both normal and abnormal data construct the number of \\nsamples, for which the data were augmented by applying five multiples \\nof the original number of samples. Each of the models in which the \\nnoise-power ratio was increased showed poor results, similar to that in \\nthe case of bearing. Depending on the data augmentation method, the \\ntwo methods show similar results, or the data augmentation method for \\nsolving the imbalance problem showed a higher classification perfor-\\nmance. Therefore, for the industrial machine dataset, the balanced data \\naugmentation method is recommended for both normal and abnormal \\ndatasets because the balanced dataset exhibits better performance. \\nOverall, the proposed model as well as the supervised learning-based \\nSVM model produced desirable results. Additionally, the industrial \\nmachine dataset exhibited differences based on type; the smallest dif-\\nference was observed in the valve dataset, whereas the fan data were \\nfound to be vulnerable to noise. In conclusion, the proposed ADTC \\nmodel utilizing the data preprocessing method proved to be the most \\nrobust for noise reduction and exhibited the highest accuracy. Fig. 5 \\nindicates the classification performance corresponding to Case 1 of the \\nproposed model with the best results. The AUC value, i.e., the area under \\nthe ROC curve, corresponding to the ROC area signifies classification \\nperformance. The ROC curve shows the performance of the classification \\nmodel at various thresholds through the metrics of true positive rate \\n(TPR) and false positive rate (FPR). The range of AUC values is between \\n0 and 1, and when the prediction is 100 % correct, the AUC is 1.0, and an \\nAUC of a model with 100 % incorrect predictions is 0. The proposed \\nmodel has an AUC of 1.0, indicating excellent prediction accuracy for \\nindustrial machines. \\n\\n4.3.5. Bearing dataset analysis considering different rotational speeds and \\ndamage \\n\\nAn experiment was performed to consider the effect of rotational \\nspeed and load on the time series bearing dataset. Existing bearing \\ndatasets are small in size. Therefore, in this study, bearing faults were \\ndiagnosed using an augmented dataset obtained using the sliding \\n\\nTable 4 \\nMIMII dataset.  \\n\\nData \\ntype \\n\\nSNR \\n(dB) \\n\\nFault \\ntype \\n\\nNo. of datasets No. of augmented datasets \\n\\nValve 6 Normal 3691 – \\nAbnormal 479 2395 \\n\\n0 Normal 3691 – \\nAbnormal 479 2395 \\n\\n− 6 Normal 2699 – \\nAbnormal 479 2395 \\n\\nPump 6 Normal 3749 – \\nAbnormal 456 2280 \\n\\n0 Normal 3749 – \\nAbnormal 456 2280 \\n\\n− 6 Normal 3749 – \\nAbnormal 456 2280 \\n\\nFan 6 Normal 4075 – \\nAbnormal 1475 4075 \\n\\n0 Normal 4075 – \\nAbnormal 1475 4075 \\n\\n− 6 Normal 4075 – \\nAbnormal 1475 4075 \\n\\nSlide Rails 6 Normal 3204 – \\nAbnormal 890 3204 \\n\\n0 Normal 3204 – \\nAbnormal 890 3204 \\n\\n− 6 Normal 3204 – \\nAbnormal 890 3204  \\n\\nTable 5 \\nAccuracy (%) obtained using raw signals, FFT, and mel spectrogram images.  \\n\\nData type Pump \\n\\nSNR − 6 dB 0 dB 6 dB \\n\\nSignal 81 82 86 \\nFFT 97 98 98 \\nImage 98 97 99  \\n\\nData type Fan \\n\\nSNR − 6 dB 0 dB 6 dB \\n\\nSignal 73 79 83 \\nFFT 98 99 99 \\nImage 100 99 100  \\n\\nData type Slide Rails \\n\\nSNR − 6 dB 0 dB 6 dB \\n\\nSignal 68 90 87 \\nFFT 98 99 99 \\nImage 99 99 99  \\n\\nData type Valve \\n\\nSNR − 6 dB 0 dB 6 dB \\n\\nSignal 82 85 80 \\nFFT 96 98 98 \\nImage 99 99 99  \\n\\nData type Bearing \\n\\nLoad 1 hp 2 hp 3 hp \\n\\nSignal 89 89 85 \\nFFT 98 98 99 \\nImage 99 99 98  \\n\\nTable 6 \\nModel accuracy (%) results obtained using different loads.  \\n\\nMethod 1 hp to \\n2 hp \\n\\n1 hp to \\n3 hp \\n\\n2 hp to \\n1 hp \\n\\n2 hp to \\n3 hp \\n\\n3 hp to \\n1 hp \\n\\n3 hp to \\n2 hp \\n\\nSVM 94 76 95 93 83 96 \\nCNN-SVM 95 66 95 94 72 83 \\nDAE 91 72 72 75 73 71 \\nDRC 84 76 80 83 65 80 \\nProposed Model 96 97 98 97 95 97  \\n\\nG. Hong and D. Suh                                                                                                                                                                                                                            \\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119551\\n\\n11\\n\\nFig. 4. Confusion matrices of different loads.  \\n\\nG. Hong and D. Suh                                                                                                                                                                                                                            \\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119551\\n\\n12\\n\\nTable 8 \\nModel accuracy (%) based on noisy the industrial machine dataset.  \\n\\nDataset Valve dataset \\n\\nSNR − 6 dB 0 dB 6 dB \\nMethod P R F1 P R F1 P R F1 \\nSVM 0.92 0.92 0.92 0.90 0.90 0.90 0.96 0.96 0.96 \\nCNN-SVM 0.91 0.92 0.91 0.92 0.92 0.92 0.99 0.99 0.99 \\nDAE 0.86 0.86 0.86 0.85 0.85 0.85 0.92 0.94 0.92 \\nDRC 0.89 0.89 0.89 0.88 0.89 0.88 0.92 0.92 0.92 \\nADTC Model Case 1 1.00 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 \\n\\nCase 2 0.95 0.95 0.95 0.95 0.94 0.95 0.96 0.96 0.96  \\n\\nDataset Fan dataset \\n\\nSNR − 6 dB 0 dB 6 dB \\nMethod P R F1 P R F1 P R F1 \\nSVM 0.90 0.90 0.90 0.94 0.94 0.94 0.98 0.98 0.98 \\nCNN-SVM 0.94 0.94 0.94 0.93 0.94 0.93 0.98 0.98 0.98 \\nDAE 0.85 0.86 0.85 0.83 0.85 0.83 0.84 0.90 0.86 \\nDRC 0.88 0.88 0.88 0.88 0.88 0.88 0.96 0.96 0.96 \\nADTC Model Case 1 1.00 1.00 1.00 0.99 0.98 0.98 1.00 0.99  0.99 \\n\\nCase 2 0.95 0.95 0.95 0.96 0.95 0.95 0.95 0.96  0.95  \\n\\nDataset Slide rails dataset \\n\\nSNR − 6 dB 0 dB 6 dB \\nMethod P R F1 P R F1 P R F1 \\nSVM 0.86 0.86 0.86 0.88 0.88 0.94 0.95 0.94 0.94 \\nCNN-SVM 0.83 0.84 0.83 0.91 0.91 0.91 0.90 0.92 0.90 \\nDAE 0.83 0.85 0.83 0.80 0.84 0.81 0.89 0.92 0.90 \\nDRC 0.93 0.93 0.93 0.92 0.92 0.92 0.93 0.94 0.93 \\nADTC Model Case 1 0.99 0.99 0.99 1.00 0.99 0.99 0.99 0.99  0.99 \\n\\nCase 2 0.96 0.96 0.96 0.95 0.95 0.95 0.98 0.98  0.98  \\n\\nDataset Pump dataset \\n\\nSNR − 6 dB 0 dB 6 dB \\nMethod P R F1 P R F1 P R F1 \\nSVM 0.84 0.86 0.85 0.93 0.93 0.93 0.95 0.95 0.95 \\nCNN-SVM 0.82 0.84 0.82 0.94 0.94 0.94 0.97 0.97 0.97 \\nDAE 0.82 0.83 0.0.82 0.84 0.86 0.84 0.88 0.88 0.88 \\nDRC 0.86 0.86 0.86 0.90 0.90 0.90 0.93 0.92 0.92 \\nADTC Model Case 1 0.98 0.98 0.98 0.98 0.97 0.97 0.99 0.99  0.99 \\n\\nCase 2 0.96 0.96 0.96 0.98 0.99 0.98 0.99 0.99  0.99  \\n\\nTable 7 \\nModel accuracy (%) based on the noisy bearing dataset.  \\n\\nDataset 1 hp Bearing \\n\\nSNR − 8 dB − 6 dB − 4 dB − 2 dB 0 dB 2 dB 4 dB 6 dB 8 dB \\n\\nSVM 90 91 92 90 94 96 96 96 97 \\nCNN \\n\\nSVM \\n90 91 90 92 95 98 97 96 98 \\n\\nDAE 75 72 76 75 78 78 92 90 90 \\nDRC 72 73 73 72 74 83 82 86 87 \\nADTC Model 97 97 97 96 99 99 99 99 99  \\n\\nDataset 2 hp Bearing \\n\\nSNR − 8 dB − 6 dB − 4 dB − 2 dB 0 dB 2 dB 4 dB 6 dB 8 dB \\n\\nSVM 92 91 92 90 94 96 96 96 96 \\nCNN \\n\\nSVM \\n88 93 93 93 95 97 98 98 98 \\n\\nDAE 75 73 74 75 90 90 90 91 92 \\nDRC 72 74 74 72 72 74 80 83 84 \\nADTC Model 96 95 96 97 98 99 99 99 99  \\n\\nDataset 3 hp Bearing \\n\\nSNR − 8 dB − 6 dB − 4 dB − 2 dB 0 dB 2 dB 4 dB 6 dB 8 dB \\n\\nSVM 86 92 92 90 94 96 96 96 96 \\nCNN \\n\\nSVM \\n93 94 93 92 93 92 96 98 98 \\n\\nDAE 72 73 73 80 80 83 82 84 90 \\nDRC 72 73 73 80 80 80 80 83 84 \\nADTC Model 98 97 98 99 99 99 99 99 99  \\n\\nG. Hong and D. Suh                                                                                                                                                                                                                            \\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119551\\n\\n13\\n\\nFig. 5. ROC curve of the proposed model based on the industrial machine dataset.  \\n\\nTable 9 \\nModel performance for the RPM of bearing dataset.  \\n\\nDataset Bearing dataset \\n\\nRPM 1500 RPM to 900 RPM 900 RPM to 1500 RPM 1500 RPM 900 RPM \\n\\nMethod P R F1 P R F1 P R F1 P R F1 \\n\\nSVM 0.99 0.99 0.99 0.99 0.98 0.99 0.98 0.99 0.99 0.99 0.99 0.99 \\nCNN-SVM 0.95 0.96 0.95 0.95 0.95 0.96 0.95 0.95 0.95 1.00 1.00 1.00 \\nDAE 0.93 0.94 0.93 0.94 0.95 0.95 0.95 0.95 0.95 0.98 0.98 0.98 \\nDRC 0.97 0.97 0.97 0.97 0.97 0.97 0.98 0.98 0.98 0.98 0.98 0.98 \\nADTC model 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00  \\n\\nG. Hong and D. Suh                                                                                                                                                                                                                            \\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119551\\n\\n14\\n\\nwindow technique. These datasets are described in Table 1 and Table 2. \\nThe proposed mel spectrogram image-based model was evaluated using \\nthe four comparative metrics of precision, recall, and F1 score. The re-\\nsults are presented in Table 9. Experiments were carried out under the \\nfollowing four conditions: 1500 RPM to 900 RPM, 900 RPM to 1500 \\nRPM, 900 RPM, and 1500 RPM. In addition, the dataset includes three \\nsets of normal data with different run-in periods, radial loads, and \\nspeeds; IR(Inner Race) defect data with different extents of damage and \\ndamage combinations; and OR (Outer Race) defect data with different \\nextents of damage, damage types, and damage combinations, yielding a \\ntotal of 10 classes. The experiment was performed using this 10-class \\ndataset. The results of the experiment reveal that the F1 score of the \\nproposed ADTC model is the highest. In addition, the ROC curve of the \\nADTC model in Fig. 6 shows that it is possible to solve the problem of \\ndomain adaptability for various bearing conditions by obtaining a high \\nAUC. Through experiments considering the rotational speed and dam-\\nage of these bearings, the ADTC model is shown to have robustness, even \\non datasets with various types of normal state. Moreover, it shows its \\nsuperiority in domain adaptability to other bearing types. Overall, the \\ntransfer learning for different RPMs and model predictions for a single \\nRPM are consistent with the real labels. In addition, the proposed model \\nshows high performance, even though there are several normal states. \\n\\n4.3.6. Discussion \\nIn this case study, five major cases were considered in the \\n\\nexperiments. In the first case, the performance of the proposed model \\nwas compared and analyzed using a time-series-based raw signal dataset \\nfor mechanical equipment, an FFT dataset, and a time–frequency-based \\nmel spectrogram dataset, which were obtained by converting the raw \\nsignal. The analysis results indicate that the proposed mel spectrogram \\nimage-based fault diagnosis surpasses the existing raw signal and FFT \\nmethods and therefore shows promise. Clearly, fault diagnosis using \\ntime/frequency-based mel spectrogram images for bearing and indus-\\ntrial machine datasets can improve model accuracy. Moreover, because \\nthe model trained on the augmented dataset performs better, a data \\naugmentation method for fault diagnosis is recommended. \\n\\nIn the second case, the domain adaptation of the proposed model was \\nevaluated through a domain adaptation test for each load of the bearing. \\nThe best results were obtained when the bearing loads at 2 hp were \\nlearned. Experimental results indicate that the Ball 0.014 Fault and Ball \\n0.021 Fault classes can degrade fault diagnosis when predictions are \\nmade through transfer learning using different loads. In addition, the \\nexperimental results show that the proposed model has adaptability to \\nseveral domains. \\n\\nIn the third case, we conducted a study on the robustness of the \\nproposed model in a real industrial environment using the bearing \\ndataset. As the noise-to-power ratio increased to − 8 dB, the accuracy of \\nthe model decreased, and a comparison with other models revealed that \\nthe proposed ADTC model is robust and less sensitive to noise in real \\nindustrial environments. \\n\\nFig. 6. ROC curve of the proposed model based on the bearing dataset.  \\n\\nG. Hong and D. Suh                                                                                                                                                                                                                            \\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119551\\n\\n15\\n\\nIn the fourth case, the robustness of the proposed model was eval-\\nuated by considering a real industrial environment using the industrial \\nmachine dataset. It was observed that the fault diagnosis performance of \\nthe mechanical equipment dataset is affected by the noise levels and the \\nmodel based on an SVM exhibited a higher accuracy. For the industrial \\nmachine dataset, a balanced data augmentation method is recom-\\nmended for both the normal and abnormal datasets because the \\nbalanced dataset leads to better performance. \\n\\nIn the fifth case, bearing data consisting of 10 classes (e.g., normal \\ndata with different run-in periods, radial loads, and speeds; IR defect \\ndata with different damage combinations, extents of damage, types of \\ndamage; and OR defect data with different damage combinations) were \\nused in the experiments. Through experiments on rotational speed and \\nbearing damage, it was shown that the ADTC model is robust even in \\ndatasets with various types of normal state and shows superiority in \\nbearing-type domain adaptability to other methods. \\n\\n5. Conclusion \\n\\nIn this paper, a mel spectrogram-based ADTC model that can \\nimprove system productivity and reliability by diagnosing abnormalities \\nin an industrial environment was proposed. The main contributions of \\nthe proposed method are as follows. Data augmentation was performed \\nto overcome the problem associated with the imbalanced time-series \\ndataset of mechanical equipment. The limited ability to extract fea-\\ntures from mechanical equipment data with sparsity was addressed by \\nexploring feature extraction using an unsupervised learning-based \\nmodel. Moreover, fault diagnosis was performed by including the \\nextracted feature values of the unsupervised data in the supervised \\nlearning model. \\n\\nUsing the proposed method, the domain adaptive performances of \\nthe mechanical equipment and robustness under the influence of in-\\ndustrial noise were evaluated. The results indicate that the high pre-\\ndictive accuracy of the proposed fault- diagnosis model makes it a robust \\nmodel for noisy environments and exhibits the adaptive performance of \\ndomains in datasets with various time lengths. Thus, it was demon-\\nstrated that the mel spectrogram-based ADTC model is an effective fault \\ndiagnosis approach and the balanced dataset has better fault-diagnosis \\nperformance. However, the K-means method has a limitation in that \\nthe number of clusters must be defined in advance. \\n\\nIn future study, we will use K-means to automatically designate the \\nnumber of clusters. Domain adaptation experiments considering various \\nenvironmental conditions and equipment types can also be conducted, \\nin addition to diagnosis prediction studies for overcoming high data \\nsparsity. \\n\\nCRediT authorship contribution statement \\n\\nGeonkyo Hong: Conceptualization, Methodology, Software, Vali-\\ndation, Formal analysis, Investigation, Resources, Data curation, \\nWriting – original draft, Writing – review & editing, Visualization. \\nDongjun Suh: Conceptualization, Methodology, Software, Validation, \\nFormal analysis, Investigation, Resources, Data curation, Writing – \\noriginal draft, Writing – review & editing, Visualization, Supervision, \\nProject administration, Funding acquisition. \\n\\nDeclaration of Competing Interest \\n\\nThe authors declare the following financial interests/personal re-\\nlationships which may be considered as potential competing interests: \\n\\nDongjun Suh reports article publishing charges was provided by \\nNational Research Foundation of Korea. Dongjun Suh reports article \\npublishing charges was provided by Korea Institute of Energy Technol-\\nogy Evaluation and Planning and the Ministry of Trade, Industry & \\nEnergy of the Republic of Korea. \\n\\nThe remaining authors declare that they have no known competing \\n\\nfinancial interests or personal relationships that could have appeared to \\ninfluence the work reported in this paper. \\n\\nData availability \\n\\nThe authors do not have permission to share data. \\n\\nAcknowledgements \\n\\nThis work was supported by a National Research Foundation of \\nKorea (NRF) grant funded by the Korean government (MSIT) (No. NRF- \\n2021R1A5A8033165), (No. NRF-2021R1I1A3049503); the Korea Insti-\\ntute of Energy Technology Evaluation and Planning (KETEP) and the \\nMinistry of Trade, Industry & Energy (MOTIE) of the Republic of Korea \\n(No. 20224000000150). \\n\\nReferences \\n\\nArias-Vergara, T., Klumpp, P., Vasquez-Correa, J. C., Nöth, E., Orozco-Arroyave, J. R., & \\nSchuster, M. (2021). Multi-channel spectrograms for speech processing applications \\nusing deep learning methods. Pattern Analysis and Applications, 24(2), 423–431. \\nhttps://doi.org/10.1007/s10044-020-00921-5 \\n\\nBrito, L. C., Susto, G. A., Brito, J. N., & Duarte, M. A. V. (2022). An explainable artificial \\nintelligence approach for unsupervised fault detection and diagnosis in rotating \\nmachinery. Mechanical Systems and Signal Processing, 163(June 2021), 108105. \\nhttps://doi.org/10.1016/j.ymssp.2021.108105 \\n\\nChalapathy, R., & Chawla, S. (2019). Deep Learning for Anomaly Detection: A Survey. 1–50. \\nChannappayya, S. S., Bovik, A. C., & Heath, R. W. (2008). Rate bounds on SSIM index of \\n\\nquantized images. IEEE Transactions on Image Processing, 17(9), 1624–1639. https:// \\ndoi.org/10.1109/TIP.2008.2001400 \\n\\nChen, P., Zhao, R., He, T., Wei, K., & Yang, Q. (2022). Unsupervised domain adaptation \\nof bearing fault diagnosis based on Join Sliced Wasserstein Distance. ISA \\nTransactions, 129, 504–519. https://doi.org/10.1016/j.isatra.2021.12.037 \\n\\nChen, Y., & Jin, H. (2019). Rare sound event detection using deep learning and data \\naugmentation. Proceedings of the Annual Conference of the International Speech \\nCommunication Association, INTERSPEECH, 2019-Septe, 619–623. https://doi.org/ \\n10.21437/Interspeech.2019-1985. \\n\\nFahim, M., & Sillitti, A. (2019). Anomaly detection, analysis and prediction techniques in \\nIoT environment: A systematic literature review. IEEE Access, 7, 81664–81681. \\nhttps://doi.org/10.1109/ACCESS.2019.2921912 \\n\\nHan, T., Zhang, L., Yin, Z., & Tan, A. C. C. (2021). Rolling bearing fault diagnosis with \\ncombined convolutional neural networks and support vector machine. Measurement: \\nJournal of the International Measurement Confederation, 177(February), Article \\n109022. https://doi.org/10.1016/j.measurement.2021.109022 \\n\\nHong, G., & Suh, D. (2021). Supervised-learning-based intelligent fault diagnosis for \\nmechanical equipment. IEEE Access, 9, 116147–116162. https://doi.org/10.1109/ \\naccess.2021.3104189 \\n\\nHossain, M. S., & Muhammad, G. (2019). Emotion recognition using deep learning \\napproach from audio–visual emotional big data. Information Fusion, 49(August \\n2018), 69–78. https://doi.org/10.1016/j.inffus.2018.09.008 \\n\\nJohnson, J. M., & Khoshgoftaar, T. M. (2019). Survey on deep learning with class \\nimbalance. Journal of Big Data, 6(1). https://doi.org/10.1186/s40537-019-0192-5 \\n\\nKimotho, J. K., Lessmeier, C., Sextro, W., & Zimmer, D. (2016). Condition monitoring of \\nbearing damage in electromechanical drive systems by using motor current signals of \\nelectric motors: a benchmark dataset for data-driven classification. Third European \\nConference of the Prognostics and Health Management Society 2016, Cm, 152–156. http \\n://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.1088.9087&rep=rep \\n1&type=pdf. \\n\\nKonar, P., & Chattopadhyay, P. (2011). Bearing fault detection of induction motor using \\nwavelet and Support Vector Machines (SVMs). Applied Soft Computing Journal, 11(6), \\n4203–4211. https://doi.org/10.1016/j.asoc.2011.03.014 \\n\\nLi, F., Liu, M., Zhao, Y., Kong, L., Dong, L., Liu, X., & Hui, M. (2019). Feature extraction \\nand classification of heart sound using 1D convolutional neural networks. EURASIP \\nJournal on Advances in Signal Processing, 2019(1). https://doi.org/10.1186/s13634- \\n019-0651-3 \\n\\nLi, X., Li, J., Qu, Y., & He, D. (2020). Semi-supervised gear fault diagnosis using raw \\nvibration signal based on deep learning. Chinese Journal of Aeronautics, 33(2), \\n418–426. https://doi.org/10.1016/j.cja.2019.04.018 \\n\\nLi, X., Li, X., & Ma, H. (2020). Deep representation clustering-based fault diagnosis \\nmethod with unsupervised data applied to rotating machinery. Mechanical Systems \\nand Signal Processing, 143. https://doi.org/10.1016/j.ymssp.2020.106825 \\n\\nLi, X., Zhang, W., & Ding, Q. (2019). Understanding and improving deep learning-based \\nrolling bearing fault diagnosis with attention mechanism. Signal Processing, 161, \\n136–154. https://doi.org/10.1016/j.sigpro.2019.03.019 \\n\\nLi, X., Zhang, W., Ding, Q., & Sun, J. Q. (2019). Multi-Layer domain adaptation method \\nfor rolling bearing fault diagnosis. Signal Processing, 157, 180–197. https://doi.org/ \\n10.1016/j.sigpro.2018.12.005 \\n\\nLi, X., Hu, Y., Zheng, J., Li, M., & Ma, W. (2021). Central moment discrepancy based \\ndomain adaptation for intelligent bearing fault diagnosis. Neurocomputing, 429, \\n12–24. https://doi.org/10.1016/j.neucom.2020.11.063 \\n\\nG. Hong and D. Suh                                                                                                                                                                                                                            \\n\\nhttps://doi.org/10.1007/s10044-020-00921-5\\nhttps://doi.org/10.1016/j.ymssp.2021.108105\\nhttps://doi.org/10.1109/TIP.2008.2001400\\nhttps://doi.org/10.1109/TIP.2008.2001400\\nhttps://doi.org/10.1016/j.isatra.2021.12.037\\nhttps://doi.org/10.1109/ACCESS.2019.2921912\\nhttps://doi.org/10.1016/j.measurement.2021.109022\\nhttps://doi.org/10.1109/access.2021.3104189\\nhttps://doi.org/10.1109/access.2021.3104189\\nhttps://doi.org/10.1016/j.inffus.2018.09.008\\nhttps://doi.org/10.1186/s40537-019-0192-5\\nhttp://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.1088.9087%26rep=rep1%26type=pdf\\nhttp://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.1088.9087%26rep=rep1%26type=pdf\\nhttp://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.1088.9087%26rep=rep1%26type=pdf\\nhttps://doi.org/10.1016/j.asoc.2011.03.014\\nhttps://doi.org/10.1186/s13634-019-0651-3\\nhttps://doi.org/10.1186/s13634-019-0651-3\\nhttps://doi.org/10.1016/j.cja.2019.04.018\\nhttps://doi.org/10.1016/j.ymssp.2020.106825\\nhttps://doi.org/10.1016/j.sigpro.2019.03.019\\nhttps://doi.org/10.1016/j.sigpro.2018.12.005\\nhttps://doi.org/10.1016/j.sigpro.2018.12.005\\nhttps://doi.org/10.1016/j.neucom.2020.11.063\\n\\n\\nExpert Systems With Applications 217 (2023) 119551\\n\\n16\\n\\nLiu, H., Zhou, J., Xu, Y., Zheng, Y., Peng, X., & Jiang, W. (2018). Unsupervised fault \\ndiagnosis of rolling bearings using a deep neural network based on generative \\nadversarial networks. Neurocomputing, 315, 412–424. https://doi.org/10.1016/j. \\nneucom.2018.07.034 \\n\\nLiu, S. C., & Liu, S. Y. (2003). An efficient expert system for machine fault diagnosis. \\nInternational Journal of Advanced Manufacturing Technology, 21(9), 691–698. https:// \\ndoi.org/10.1007/s00170-002-1389-9 \\n\\nMiao, Y., Zhang, B., Lin, J., Zhao, M., Liu, H., Liu, Z., & Li, H. (2022). A review on the \\napplication of blind deconvolution in machinery fault diagnosis. Mechanical Systems \\nand Signal Processing, 163(June 2021), 108202. https://doi.org/10.1016/j. \\nymssp.2021.108202 \\n\\nMikołajczyk, A., & Grochowski, M. (2018). Data augmentation for improving deep \\nlearning in image classification problem. 2018 International Interdisciplinary PhD \\nWorkshop, IIPhDW 2018, 117–122. https://doi.org/10.1109/ \\nIIPHDW.2018.8388338. \\n\\nOh, W. (2020). Comparison of environmental sound classification performance of \\nconvolutional neural networks according to audio preprocessing methods. Journal of \\nthe Acoustical Society of Korea, 39(3), 143–149. https://doi.org/10.7776/ \\nASK.2020.39.3.143 \\n\\nPandey, S. K., Shekhawat, H. S., & Prasanna, S. R. M. (2019). Deep learning techniques \\nfor speech emotion recognition: A review. In 2019 29Th International Conference \\nRadioelektronika, RADIOELEKTRONIKA 2019 - Microwave and Radio Electronics Week. \\nhttps://doi.org/10.1109/RADIOELEK.2019.8733432 \\n\\nPang, G., Shen, C., Cao, L., & Hengel, A. V. D. (2021). Deep learning for anomaly \\ndetection: A review. ACM Computing Surveys, 54(2). https://doi.org/10.1145/ \\n3439950 \\n\\nQian, Q., Qin, Y., Wang, Y., & Liu, F. (2021). A new deep transfer learning network based \\non convolutional auto-encoder for mechanical fault diagnosis. Measurement: Journal \\nof the International Measurement Confederation, 178(March), Article 109352. https:// \\ndoi.org/10.1016/j.measurement.2021.109352 \\n\\nRajoub, B. (2020). Supervised and unsupervised learning. Biomedical Signal Processing \\nand Artificial Intelligence in Healthcare, January, 51–89. https://doi.org/10.1016/ \\nb978-0-12-818946-7.00003-2. \\n\\nRauber, T. W., da Silva Loca, A. L., Boldt, F. de A., Rodrigues, A. L., & Varejão, F. M. \\n(2021). An experimental methodology to evaluate machine learning methods for \\nfault diagnosis based on vibration signals. Expert Systems with Applications, 167 \\n(September 2020). 10.1016/j.eswa.2020.114022. \\n\\nSaufi, S. R., Ahmad, Z. A. Bin, Leong, M. S., & Lim, M. H. (2020). Gearbox Fault \\nDiagnosis Using a Deep Learning Model with Limited Data Sample. IEEE Transactions \\non Industrial Informatics, 16(10), 6263–6271. https://doi.org/10.1109/ \\nTII.2020.2967822. \\n\\nShenfield, A., & Howarth, M. (2020). A novel deep learning model for the detection and \\nidentification of rolling element-bearing faults. Sensors (Switzerland), 20(18), 1–24. \\nhttps://doi.org/10.3390/s20185112 \\n\\nShorten, C., & Khoshgoftaar, T. M. (2019). A survey on image data augmentation for \\ndeep learning. Journal of Big Data, 6(1). https://doi.org/10.1186/s40537-019-0197- \\n0 \\n\\nShyu, M., Chen, S., & Iyengar, S. S. (2020). A survey on deep learning techniques. Strad \\nResearch, 7(8). https://doi.org/10.37896/sr7.8/037. \\n\\nSohaib, M., Kim, C. H., & Kim, J. M. (2017). A hybrid feature model and deep-learning- \\nbased bearing fault diagnosis. Sensors (Switzerland), 17(12). https://doi.org/ \\n10.3390/s17122876 \\n\\nStevenson, M., Mues, C., & Bravo, C. (2021). Deep residential representations: Using \\nunsupervised learning to unlock elevation data for geo-demographic prediction. \\nISPRS Journal of Photogrammetry and Remote Sensing, 187(November 2021), \\n378–392. https://doi.org/10.1016/j.isprsjprs.2022.03.015 \\n\\nSun, J., Yan, C., & Wen, J. (2018). Intelligent bearing fault diagnosis method combining \\ncompressed data acquisition and deep learning. IEEE Transactions on Instrumentation \\nand Measurement, 67(1), 185–195. https://doi.org/10.1109/TIM.2017.2759418 \\n\\nTagawa, Y., Maskeliūnas, R., & Damaševičius, R. (2021). Acoustic anomaly detection of \\nmechanical failures in noisy real-life factory environments. Electronics (Switzerland), \\n10(19). https://doi.org/10.3390/electronics10192329 \\n\\nTao, H., Wang, P., Chen, Y., Stojanovic, V., & Yang, H. (2020). An unsupervised fault \\ndiagnosis method for rolling bearing using STFT and generative neural networks. \\nJournal of the Franklin Institute, 357(11), 7286–7307. https://doi.org/10.1016/j. \\njfranklin.2020.04.024 \\n\\nTavakoli, A., & Heydarian, A. (2022). Multimodal driver state modeling through \\nunsupervised learning. Accident Analysis and Prevention, 170(February), Article \\n106640. https://doi.org/10.1016/j.aap.2022.106640 \\n\\nTran, T., & Lundgren, J. (2020). Drill fault diagnosis based on the scalogram and MEL \\nspectrogram of sound signals using artificial intelligence. IEEE Access, 8, \\n203655–203666. https://doi.org/10.1109/ACCESS.2020.3036769 \\n\\nTung, T. V., & Yang, B.-S. (2009). Machine fault diagnosis and prognosis: The state of the \\nart. International Journal of Fluid Machinery and Systems, 2(1), 61–71. https://doi. \\norg/10.5293/ijfms.2009.2.1.061 \\n\\nVarga, A. (2017). Fault diagnosis. Studies in Systems, Decision and Control, 84(3), 27–56. \\nhttps://doi.org/10.1007/978-3-319-51559-5_3 \\n\\nWang, J., Xue, M., Culhane, R., Diao, E., Ding, J., & Tarokh, V. (2020). Speech emotion \\nrecognition with dual-sequence LSTM architecture, IEEE International Conference on \\nAcoustics, Speech and Signal Processing (ICASSP), 6469–6473. \\n\\nWang, Z., Yao, L., Chen, G., & Ding, J. (2021). Modified multiscale weighted permutation \\nentropy and optimized support vector machine method for rolling bearing fault \\ndiagnosis with complex signals. ISA Transactions, 114, 470–484. https://doi.org/ \\n10.1016/j.isatra.2020.12.054 \\n\\nWu, X., Zhang, Y., Cheng, C., & Peng, Z. (2021). A hybrid classification autoencoder for \\nsemi-supervised fault diagnosis in rotating machinery. Mechanical Systems and Signal \\nProcessing, 149, Article 107327. https://doi.org/10.1016/j.ymssp.2020.107327 \\n\\nXiao, D., Qin, C., Yu, H., Huang, Y., Liu, C., & Zhang, J. (2021). Unsupervised machine \\nfault diagnosis for noisy domain adaptation using marginal denoising autoencoder \\nbased on acoustic signals. Measurement: Journal of the International Measurement \\nConfederation, 176(February), Article 109186. https://doi.org/10.1016/j. \\nmeasurement.2021.109186 \\n\\nXu, J., Ma, L., Zhang, W., Yang, Q., Li, X., & Liu, S. (2019). An Improved Hybrid CNN- \\nSVM based Method for Bearing Fault Diagnosis Under Noisy Environment. \\nProceedings of the 31st Chinese Control and Decision Conference, CCDC 2019, 2018, \\n4660–4665. https://doi.org/10.1109/CCDC.2019.8832683. \\n\\nYang, D., Karimi, H. R., & Sun, K. (2021). Residual wide-kernel deep convolutional auto- \\nencoder for intelligent rotating machinery fault diagnosis with limited samples. \\nNeural Networks, 141, 133–144. https://doi.org/10.1016/j.neunet.2021.04.003 \\n\\nYang, J., Bao, W., Liu, Y., Li, X., Wang, J., Niu, Y., & Li, J. (2021). Joint pairwise graph \\nembedded sparse deep belief network for fault diagnosis. Engineering Applications of \\nArtificial Intelligence, 99(61627901), Article 104149. https://doi.org/10.1016/j. \\nengappai.2020.104149 \\n\\nYao, L., Fang, Z., Xiao, Y., Hou, J., & Fu, Z. (2021). An intelligent fault diagnosis method \\nfor lithium battery systems based on grid search support vector machine. Energy, \\n214, Article 118866. https://doi.org/10.1016/j.energy.2020.118866 \\n\\nZhang, K., Lin, N., Tian, G., Yang, J., Wang, D., & Jin, Z. (2022). Unsupervised-learning \\nbased self-organizing neural network using multi-component seismic data: \\nApplication to Xujiahe tight-sand gas reservoir in China. Journal of Petroleum Science \\nand Engineering, 209(November 2021), Article 109964. https://doi.org/10.1016/j. \\npetrol.2021.109964 \\n\\nG. Hong and D. Suh                                                                                                                                                                                                                            \\n\\nhttps://doi.org/10.1016/j.neucom.2018.07.034\\nhttps://doi.org/10.1016/j.neucom.2018.07.034\\nhttps://doi.org/10.1007/s00170-002-1389-9\\nhttps://doi.org/10.1007/s00170-002-1389-9\\nhttps://doi.org/10.1016/j.ymssp.2021.108202\\nhttps://doi.org/10.1016/j.ymssp.2021.108202\\nhttps://doi.org/10.7776/ASK.2020.39.3.143\\nhttps://doi.org/10.7776/ASK.2020.39.3.143\\nhttps://doi.org/10.1109/RADIOELEK.2019.8733432\\nhttps://doi.org/10.1145/3439950\\nhttps://doi.org/10.1145/3439950\\nhttps://doi.org/10.1016/j.measurement.2021.109352\\nhttps://doi.org/10.1016/j.measurement.2021.109352\\nhttps://doi.org/10.3390/s20185112\\nhttps://doi.org/10.1186/s40537-019-0197-0\\nhttps://doi.org/10.1186/s40537-019-0197-0\\nhttps://doi.org/10.37896/sr7.8/037\\nhttps://doi.org/10.3390/s17122876\\nhttps://doi.org/10.3390/s17122876\\nhttps://doi.org/10.1016/j.isprsjprs.2022.03.015\\nhttps://doi.org/10.1109/TIM.2017.2759418\\nhttps://doi.org/10.3390/electronics10192329\\nhttps://doi.org/10.1016/j.jfranklin.2020.04.024\\nhttps://doi.org/10.1016/j.jfranklin.2020.04.024\\nhttps://doi.org/10.1016/j.aap.2022.106640\\nhttps://doi.org/10.1109/ACCESS.2020.3036769\\nhttps://doi.org/10.5293/ijfms.2009.2.1.061\\nhttps://doi.org/10.5293/ijfms.2009.2.1.061\\nhttps://doi.org/10.1007/978-3-319-51559-5_3\\nhttps://doi.org/10.1016/j.isatra.2020.12.054\\nhttps://doi.org/10.1016/j.isatra.2020.12.054\\nhttps://doi.org/10.1016/j.ymssp.2020.107327\\nhttps://doi.org/10.1016/j.measurement.2021.109186\\nhttps://doi.org/10.1016/j.measurement.2021.109186\\nhttps://doi.org/10.1016/j.neunet.2021.04.003\\nhttps://doi.org/10.1016/j.engappai.2020.104149\\nhttps://doi.org/10.1016/j.engappai.2020.104149\\nhttps://doi.org/10.1016/j.energy.2020.118866\\nhttps://doi.org/10.1016/j.petrol.2021.109964\\nhttps://doi.org/10.1016/j.petrol.2021.109964\\n\\n\\tMel Spectrogram-based advanced deep temporal clustering model with unsupervised data for fault diagnosis\\n\\t1 Introduction\\n\\t2 Related work\\n\\t3 Proposed method\\n\\t3.1 Dataset formulation\\n\\t3.2 Proposed method overview\\n\\t3.3 Feature extractor for unsupervised data\\n\\t3.4 Feature validator for unsupervised data\\n\\t3.5 Centroid based learning using unsupervised data\\n\\t3.6 Classification for fault diagnosis using unsupervised data\\n\\n\\t4 Experimental study\\n\\t4.1 Data description and algorithm setup\\n\\t4.1.1 CWRU bearing dataset\\n\\t4.1.2 MIMII dataset\\n\\t4.1.3 Paderborn University bearing dataset\\n\\n\\t4.2 Data preprocessing\\n\\t4.2.1 Data augmentation\\n\\t4.2.2 Mel spectrogram\\n\\t4.2.3 SSIM\\n\\n\\t4.3 Numerical experiment\\n\\t4.3.1 Performance analysis of mel spectrogram images\\n\\t4.3.2 Domain adaptation performance analysis\\n\\t4.3.3 Bearing dataset analysis considering different noise levels\\n\\t4.3.4 Industrial machine dataset analysis considering different noise\\n\\t4.3.5 Bearing dataset analysis considering different rotational speeds and damage\\n\\t4.3.6 Discussion\\n\\n\\n\\t5 Conclusion\\n\\tCRediT authorship contribution statement\\n\\tDeclaration of Competing Interest\\n\\tData availability\\n\\tAcknowledgements\\n\\tReferences\\n\\n\\n', 'status': 200}\n",
      "<class 'dict'>\n",
      "dict_keys(['metadata', 'content', 'status'])\n",
      "{'pdf:PDFVersion': '1.7', 'pdf:docinfo:title': 'Mel Spectrogram-based advanced deep temporal clustering model with unsupervised data for fault diagnosis', 'xmp:CreatorTool': 'Elsevier', 'pdf:hasXFA': 'false', 'access_permission:can_print_degraded': 'true', 'X-TIKA:Parsed-By-Full-Set': ['org.apache.tika.parser.DefaultParser', 'org.apache.tika.parser.pdf.PDFParser'], 'X-TIKA:content_handler': 'ToTextContentHandler', 'pdf:num3DAnnotations': '0', 'dc:format': 'application/pdf; version=1.7', 'pdf:docinfo:custom:robots': 'noindex', 'pdf:docinfo:creator_tool': 'Elsevier', 'access_permission:fill_in_form': 'true', 'pdf:docinfo:custom:CreationDate--Text': '7th February 2023', 'pdf:hasCollection': 'false', 'pdf:encrypted': 'false', 'dc:title': 'Mel Spectrogram-based advanced deep temporal clustering model with unsupervised data for fault diagnosis', 'pdf:containsNonEmbeddedFont': 'false', 'pdf:docinfo:custom:CrossMarkDomains[1]': 'elsevier.com', 'robots': 'noindex', 'pdf:docinfo:subject': 'Expert Systems With Applications, 217 (2023) 119551. doi:10.1016/j.eswa.2023.119551', 'pdf:hasMarkedContent': 'true', 'pdf:docinfo:creator': 'Geonkyo Hong', 'pdf:docinfo:custom:CrossmarkMajorVersionDate': '2010-04-23', 'access_permission:extract_for_accessibility': 'true', 'resourceName': \"b'Mel-Spectrogram-based-advanced-deep-temporal-clusterin_2023_Expert-Systems-w.pdf'\", 'pdf:docinfo:custom:CrossMarkDomains[2]': 'sciencedirect.com', 'X-TIKA:Parsed-By': ['org.apache.tika.parser.DefaultParser', 'org.apache.tika.parser.pdf.PDFParser'], 'ElsevierWebPDFSpecifications': '7.0', 'pdf:docinfo:custom:doi': '10.1016/j.eswa.2023.119551', 'pdf:docinfo:custom:CrossmarkDomainExclusive': 'true', 'X-TIKA:embedded_depth': '0', 'CrossmarkDomainExclusive': 'true', 'pdf:annotationTypes': 'null', 'pdf:docinfo:producer': 'Acrobat Distiller 8.1.0 (Windows)', 'pdf:annotationSubtypes': 'Link', 'CreationDate--Text': '7th February 2023', 'doi': '10.1016/j.eswa.2023.119551', 'pdf:containsDamagedFont': 'false', 'pdf:unmappedUnicodeCharsPerPage': ['0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0'], 'access_permission:modify_annotations': 'true', 'dc:creator': 'Geonkyo Hong', 'dcterms:created': '2023-02-07T18:16:11Z', 'dcterms:modified': '2023-02-07T18:19:55Z', 'CrossMarkDomains[1]': 'elsevier.com', 'pdf:overallPercentageUnmappedUnicodeChars': '0.0', 'pdf:docinfo:keywords': 'Anomaly detection,Data augmentation,Fault diagnosis,Mel spectrogram,Time series,Unsupervised learning', 'pdf:docinfo:modified': '2023-02-07T18:19:55Z', 'Content-Length': '7956340', 'Content-Type': 'application/pdf', 'dc:language': 'en', 'pdf:producer': 'Acrobat Distiller 8.1.0 (Windows)', 'dc:subject': ['Anomaly detection,Data augmentation,Fault diagnosis,Mel spectrogram,Time series,Unsupervised learning', 'Expert Systems With Applications, 217 (2023) 119551. doi:10.1016/j.eswa.2023.119551'], 'X-TIKA:EXCEPTION:warn': 'org.xml.sax.SAXParseException; lineNumber: 82; columnNumber: 11; The content of elements must consist of well-formed character data or markup.\\n\\tat org.apache.xerces.parsers.DOMParser.parse(Unknown Source)\\n\\tat org.apache.xerces.jaxp.DocumentBuilderImpl.parse(Unknown Source)\\n\\tat java.xml/javax.xml.parsers.DocumentBuilder.parse(DocumentBuilder.java:122)\\n\\tat org.apache.tika.utils.XMLReaderUtils.buildDOM(XMLReaderUtils.java:396)\\n\\tat org.apache.tika.parser.pdf.PDMetadataExtractor.loadDOM(PDMetadataExtractor.java:472)\\n\\tat org.apache.tika.parser.pdf.PDMetadataExtractor.extract(PDMetadataExtractor.java:69)\\n\\tat org.apache.tika.parser.pdf.PDFParser.extractMetadata(PDFParser.java:423)\\n\\tat org.apache.tika.parser.pdf.PDFParser.parse(PDFParser.java:181)\\n\\tat org.apache.tika.parser.CompositeParser.parse(CompositeParser.java:298)\\n\\tat org.apache.tika.parser.CompositeParser.parse(CompositeParser.java:298)\\n\\tat org.apache.tika.parser.AutoDetectParser.parse(AutoDetectParser.java:175)\\n\\tat org.apache.tika.parser.RecursiveParserWrapper.parse(RecursiveParserWrapper.java:163)\\n\\tat org.apache.tika.server.core.resource.TikaResource.parse(TikaResource.java:352)\\n\\tat org.apache.tika.server.core.resource.RecursiveMetadataResource.parseMetadata(RecursiveMetadataResource.java:78)\\n\\tat org.apache.tika.server.core.resource.RecursiveMetadataResource.parseMetadataToMetadataList(RecursiveMetadataResource.java:190)\\n\\tat org.apache.tika.server.core.resource.RecursiveMetadataResource.getMetadata(RecursiveMetadataResource.java:179)\\n\\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\\n\\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\\n\\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\\n\\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)\\n\\tat org.apache.cxf.service.invoker.AbstractInvoker.performInvocation(AbstractInvoker.java:179)\\n\\tat org.apache.cxf.service.invoker.AbstractInvoker.invoke(AbstractInvoker.java:96)\\n\\tat org.apache.cxf.jaxrs.JAXRSInvoker.invoke(JAXRSInvoker.java:201)\\n\\tat org.apache.cxf.jaxrs.JAXRSInvoker.invoke(JAXRSInvoker.java:104)\\n\\tat org.apache.cxf.interceptor.ServiceInvokerInterceptor$1.run(ServiceInvokerInterceptor.java:59)\\n\\tat org.apache.cxf.interceptor.ServiceInvokerInterceptor.handleMessage(ServiceInvokerInterceptor.java:96)\\n\\tat org.apache.cxf.phase.PhaseInterceptorChain.doIntercept(PhaseInterceptorChain.java:307)\\n\\tat org.apache.cxf.transport.ChainInitiationObserver.onMessage(ChainInitiationObserver.java:121)\\n\\tat org.apache.cxf.transport.http.AbstractHTTPDestination.invoke(AbstractHTTPDestination.java:265)\\n\\tat org.apache.cxf.transport.http_jetty.JettyHTTPDestination.doService(JettyHTTPDestination.java:247)\\n\\tat org.apache.cxf.transport.http_jetty.JettyHTTPHandler.handle(JettyHTTPHandler.java:79)\\n\\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)\\n\\tat org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)\\n\\tat org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1440)\\n\\tat org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:190)\\n\\tat org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1355)\\n\\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)\\n\\tat org.eclipse.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:191)\\n\\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)\\n\\tat org.eclipse.jetty.server.Server.handle(Server.java:516)\\n\\tat org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:487)\\n\\tat org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:732)\\n\\tat org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:479)\\n\\tat org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)\\n\\tat org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)\\n\\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)\\n\\tat org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)\\n\\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)\\n\\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)\\n\\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)\\n\\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)\\n\\tat org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)\\n\\tat org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)\\n\\tat org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)\\n\\tat java.base/java.lang.Thread.run(Thread.java:840)\\n', 'pdf:docinfo:custom:ElsevierWebPDFSpecifications': '7.0', 'pdf:totalUnmappedUnicodeChars': '0', 'access_permission:assemble_document': 'true', 'xmpTPg:NPages': '16', 'pdf:hasXMP': 'true', 'pdf:charsPerPage': ['5080', '8647', '7249', '349', '6806', '5847', '4697', '8242', '340', '5601', '331', '2701', '876', '3591', '9060', '8038'], 'access_permission:extract_content': 'true', 'access_permission:can_print': 'true', 'CrossMarkDomains[2]': 'sciencedirect.com', 'X-TIKA:parse_time_millis': '264', 'access_permission:can_modify': 'true', 'pdf:docinfo:created': '2023-02-07T18:16:11Z', 'CrossmarkMajorVersionDate': '2010-04-23'}\n",
      "<class 'dict'>\n",
      "200 <class 'int'>\n"
     ]
    }
   ],
   "source": [
    "from parse_documents import *\n",
    "\n",
    "filepath = 'upload/Mel-Spectrogram-based-advanced-deep-temporal-clusterin_2023_Expert-Systems-w.pdf'  # Replace with the path of your file\n",
    "\n",
    "parse_document(filepath)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f581976-9cb0-449e-ae8e-e10e4cf05801",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
