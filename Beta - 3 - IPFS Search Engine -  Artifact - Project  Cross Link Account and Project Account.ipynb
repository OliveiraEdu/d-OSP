{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a043d51-4a22-4186-975e-7e3e8a4b54ef",
   "metadata": {},
   "source": [
    "1 - Deploys a smart contract into the Iroha 1 blockchain for details (attributes) setting;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a1c5a2-75c3-482e-999c-70eb25226078",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tEntering \"create_contract\"\n",
      "('STATELESS_VALIDATION_SUCCESS', 1, 0)\n",
      "('ENOUGH_SIGNATURES_COLLECTED', 9, 0)\n",
      "('STATEFUL_VALIDATION_SUCCESS', 3, 0)\n",
      "('COMMITTED', 5, 0)\n",
      "\tLeaving \"create_contract\"\n",
      "\tEntering \"get_engine_receipts_result\"\n",
      "\n",
      "\tLeaving \"get_engine_receipts_result\"\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "from Crypto.Hash import keccak\n",
    "import os\n",
    "import binascii\n",
    "from iroha import IrohaCrypto\n",
    "from iroha import Iroha, IrohaGrpc\n",
    "from iroha.ed25519 import H\n",
    "import integration_helpers\n",
    "from iroha.primitive_pb2 import can_set_my_account_detail\n",
    "import sys\n",
    "# import csv\n",
    "import json\n",
    "import icecream as ic\n",
    "from iroha_helper import *\n",
    "from new_helper import *\n",
    "\n",
    "# if sys.version_info[0] < 3:\n",
    "#     raise Exception(\"Python 3 or a more recent version is required.\")\n",
    "\n",
    "# # Load configuration from config.json file\n",
    "# config_path = \"config.json\"  # Update this path as needed\n",
    "# with open(config_path, \"r\") as f:\n",
    "#     config = json.load(f)\n",
    "\n",
    "# IROHA_HOST_ADDR = config[\"IROHA_HOST_ADDR\"]\n",
    "# IROHA_PORT = config[\"IROHA_PORT\"]\n",
    "# ADMIN_ACCOUNT_ID = config[\"ADMIN_ACCOUNT_ID\"]\n",
    "# ADMIN_PRIVATE_KEY = config[\"ADMIN_PRIVATE_KEY\"]\n",
    "\n",
    "# iroha = Iroha(ADMIN_ACCOUNT_ID)\n",
    "# net = IrohaGrpc(\"{}:{}\".format(IROHA_HOST_ADDR, IROHA_PORT))\n",
    "\n",
    "\n",
    "# @integration_helpers.trace\n",
    "# def create_contract():\n",
    "#     bytecode = \"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\"\n",
    "#     \"\"\"Bytecode was generated using remix editor  https://remix.ethereum.org/ from file detail.sol. \"\"\"\n",
    "#     tx = iroha.transaction(\n",
    "#         [iroha.command(\"CallEngine\", caller=ADMIN_ACCOUNT_ID, input=bytecode)]\n",
    "#     )\n",
    "#     IrohaCrypto.sign_transaction(tx, ADMIN_PRIVATE_KEY)\n",
    "#     net.send_tx(tx)\n",
    "#     hex_hash = binascii.hexlify(IrohaCrypto.hash(tx))\n",
    "#     for status in net.tx_status_stream(tx):\n",
    "#         print(status)\n",
    "#     return hex_hash\n",
    "\n",
    "hash = create_contract()\n",
    "integration_helpers.get_engine_receipts_result(hash)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ea1051-cb1c-4c29-97e5-38ba90248081",
   "metadata": {},
   "source": [
    "2 - Data extraction from JSON-LD.\n",
    "\n",
    "Extracts account ids from `datasets/accounts.json` and `datasets/projects.json`.\n",
    "\n",
    "Must update `json_ld_index` with a entry number related to an existing object in `datasets/accounts.json` and `datasets/projects.json`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f8384a9-49db-44a2-b222-f3657a3bc9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index for objects in both user account and project account JSON-LDs.\n",
    "json_ld_index = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e068d0-2247-4fd3-827f-4144b66965e1",
   "metadata": {},
   "source": [
    "4 - Sets details for both User and Project accounts providing a logical link between them for later references."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126df4cd-d358-43cc-997f-e17453a5b8dc",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tEntering \"get_engine_receipts_address\"\n",
      "\tLeaving \"get_engine_receipts_address\"\n",
      "\tEntering \"get_engine_receipts_address\"\n",
      "\tLeaving \"get_engine_receipts_address\"\n",
      "('STATELESS_VALIDATION_SUCCESS', 1, 0)\n",
      "('ENOUGH_SIGNATURES_COLLECTED', 9, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('STATEFUL_VALIDATION_SUCCESS', 3, 0)\n",
      "('COMMITTED', 5, 0)\n",
      "('STATELESS_VALIDATION_SUCCESS', 1, 0)\n",
      "('ENOUGH_SIGNATURES_COLLECTED', 9, 0)\n",
      "('STATEFUL_VALIDATION_SUCCESS', 3, 0)\n",
      "('COMMITTED', 5, 0)\n",
      "Updated user account crazy_nash@test with linked project 06535@test\n",
      "Updated project account 06535@test with linked user crazy_nash@test\n",
      "User account crazy_nash@test linked to project 06535@test\n",
      "Project account 06535@test linked to user crazy_nash@test\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import binascii\n",
    "\n",
    "address = integration_helpers.get_engine_receipts_address(hash)\n",
    "\n",
    "\n",
    "# # Function to link details using blockchain\n",
    "# def set_account_detail(address, account, key, value):\n",
    "#     params = integration_helpers.get_first_four_bytes_of_keccak(\n",
    "#         b\"setAccountDetail(string,string,string)\"\n",
    "#     )\n",
    "#     no_of_param = 3\n",
    "#     for x in range(no_of_param):\n",
    "#         params = params + integration_helpers.left_padded_address_of_param(\n",
    "#             x, no_of_param\n",
    "#         )\n",
    "#     params = params + integration_helpers.argument_encoding(account)  # account id\n",
    "#     params = params + integration_helpers.argument_encoding(key)  # key\n",
    "#     params = params + integration_helpers.argument_encoding(value)  # value\n",
    "#     tx = iroha.transaction(\n",
    "#         [\n",
    "#             iroha.command(\n",
    "#                 \"CallEngine\", caller=ADMIN_ACCOUNT_ID, callee=address, input=params\n",
    "#             )\n",
    "#         ]\n",
    "#     )\n",
    "#     IrohaCrypto.sign_transaction(tx, ADMIN_PRIVATE_KEY)\n",
    "#     response = net.send_tx(tx)\n",
    "#     for status in net.tx_status_stream(tx):\n",
    "#         print(status)\n",
    "#     hex_hash = binascii.hexlify(IrohaCrypto.hash(tx))\n",
    "#     return hex_hash\n",
    "\n",
    "# # Function to update user account with linked project\n",
    "# def update_user_account_link(user_account_id, linked_project_id, accounts_filename=\"datasets/accounts.json\"):\n",
    "#     try:\n",
    "#         if os.path.exists(accounts_filename):\n",
    "#             with open(accounts_filename, mode='r', encoding='utf-8') as file:\n",
    "#                 data = json.load(file)\n",
    "#         else:\n",
    "#             print(f\"{accounts_filename} does not exist.\")\n",
    "#             return\n",
    "\n",
    "#         user_found = False\n",
    "\n",
    "#         # Look for the user account and update it\n",
    "#         for entry in data[\"@graph\"]:\n",
    "#             if entry[\"@type\"] == \"foaf:Person\" and entry.get(\"foaf:holdsAccount\", {}).get(\"schema:identifier\") == user_account_id:\n",
    "#                 entry[\"schema:linked_project\"] = linked_project_id\n",
    "#                 user_found = True\n",
    "#                 print(f\"Updated user account {user_account_id} with linked project {linked_project_id}\")\n",
    "#                 break\n",
    "\n",
    "#         if not user_found:\n",
    "#             print(f\"User account {user_account_id} not found.\")\n",
    "\n",
    "#         # Write back the updated data\n",
    "#         with open(accounts_filename, mode='w', encoding='utf-8') as file:\n",
    "#             json.dump(data, file, indent=4)\n",
    "\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error updating user account in JSON-LD: {str(e)}\")\n",
    "\n",
    "\n",
    "# # Function to update project account with linked user\n",
    "# def update_project_account_link(project_account_id, linked_user_id, projects_filename=\"datasets/projects.json\"):\n",
    "#     try:\n",
    "#         if os.path.exists(projects_filename):\n",
    "#             with open(projects_filename, mode='r', encoding='utf-8') as file:\n",
    "#                 data = json.load(file)\n",
    "#         else:\n",
    "#             print(f\"{projects_filename} does not exist.\")\n",
    "#             return\n",
    "\n",
    "#         project_found = False\n",
    "\n",
    "#         # Look for the project account and update it\n",
    "#         for entry in data[\"@graph\"]:\n",
    "#             if entry[\"@type\"] == \"schema:ResearchProject\" and entry.get(\"schema:identifier\") == project_account_id:\n",
    "#                 entry[\"schema:linked_user\"] = linked_user_id\n",
    "#                 project_found = True\n",
    "#                 print(f\"Updated project account {project_account_id} with linked user {linked_user_id}\")\n",
    "#                 break\n",
    "\n",
    "#         if not project_found:\n",
    "#             print(f\"Project account {project_account_id} not found.\")\n",
    "\n",
    "#         # Write back the updated data\n",
    "#         with open(projects_filename, mode='w', encoding='utf-8') as file:\n",
    "#             json.dump(data, file, indent=4)\n",
    "\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error updating project account in JSON-LD: {str(e)}\")\n",
    "\n",
    "\n",
    "# # Function to read accounts from JSON-LD\n",
    "# def read_user_accounts_from_jsonld(file_path):\n",
    "#     with open(file_path, mode='r', encoding='utf-8') as file:\n",
    "#         data = json.load(file)\n",
    "#         user_accounts = []\n",
    "#         for entry in data[\"@graph\"]:\n",
    "#             if entry[\"@type\"] == \"foaf:Person\":\n",
    "#                 account_id = entry.get(\"foaf:holdsAccount\", {}).get(\"schema:identifier\")\n",
    "#                 if account_id:\n",
    "#                     user_accounts.append({'account_id': account_id})\n",
    "#         return user_accounts\n",
    "\n",
    "\n",
    "# def read_project_accounts_from_jsonld(file_path):\n",
    "#     with open(file_path, mode='r', encoding='utf-8') as file:\n",
    "#         data = json.load(file)\n",
    "#         project_accounts = []\n",
    "#         for entry in data[\"@graph\"]:\n",
    "#             if entry[\"@type\"] == \"schema:ResearchProject\":\n",
    "#                 project_id = entry.get(\"schema:identifier\")\n",
    "#                 if project_id:\n",
    "#                     project_accounts.append({'account_id': project_id})\n",
    "#         return project_accounts\n",
    "\n",
    "\n",
    "# Example execution of the previous snippet\n",
    "address = integration_helpers.get_engine_receipts_address(hash)\n",
    "\n",
    "# Read accounts from JSON-LD\n",
    "user_accounts = read_user_accounts_from_jsonld('datasets/accounts.json')\n",
    "project_accounts = read_project_accounts_from_jsonld('datasets/projects.json')\n",
    "\n",
    "# Assuming json_ld_index is defined\n",
    "user_account = user_accounts[json_ld_index]\n",
    "project_account = project_accounts[json_ld_index]\n",
    "\n",
    "# Set project_id as a detail for the user account\n",
    "hash_user_to_project = set_account_detail(\n",
    "    address, \n",
    "    user_account['account_id'], \n",
    "    \"linked_project\", \n",
    "    project_account['account_id']\n",
    ")\n",
    "\n",
    "# Set user_account_id as a detail for the project account\n",
    "hash_project_to_user = set_account_detail(\n",
    "    address, \n",
    "    project_account['account_id'], \n",
    "    \"linked_user\", \n",
    "    user_account['account_id']\n",
    ")\n",
    "\n",
    "# Update the JSON-LD files with the linked details\n",
    "update_user_account_link(user_account['account_id'], project_account['account_id'])\n",
    "update_project_account_link(project_account['account_id'], user_account['account_id'])\n",
    "\n",
    "# Confirming the operation\n",
    "print(f\"User account {user_account['account_id']} linked to project {project_account['account_id']}\")\n",
    "print(f\"Project account {project_account['account_id']} linked to user {user_account['account_id']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3562857c-d86d-42cf-a24b-23a5c3f5cb4e",
   "metadata": {},
   "source": [
    "3 - Queries Iroha 1 for User account and checks its values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b52e47a4-b1c5-4ebe-a2d8-8edae10063d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Account id = {'account_id': 'crazy_nash@test'}, { \"admin@test\" : { \"linked_project\" : \"06535@test\", \"user_json_ld_cid\" : \"QmVQLbPmAqVYWPT1x9niJEC3w1YK5zxXYJPC8FraoasHuU\" } }\n"
     ]
    }
   ],
   "source": [
    "#Query - GetAccountDetail\n",
    "query = iroha.query('GetAccountDetail',account_id=user_account['account_id'])\n",
    "# print(query)\n",
    "IrohaCrypto.sign_query(query, ADMIN_PRIVATE_KEY)\n",
    "response = net.send_query(query)\n",
    "# print(response)\n",
    "\n",
    "user_data = response.account_detail_response\n",
    "user_details = user_data.detail\n",
    "\n",
    "\n",
    "print(f'User Account id = {user_account}, {user_details}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168a556f-b657-4a6a-8c9f-b18aac8f8375",
   "metadata": {},
   "source": [
    "3 - Queries Iroha 1 for Project account and checks its values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d39cb27c-4f7d-48dd-a137-6bceb294c15f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project Account id = {'account_id': '06535@test'}, { \"admin@test\" : { \"file_1\" : \"QmVk8gxENq6PThSGZTuk7RtbufR2XeN7LtXBj2LVTUoAdN, QmRxGqNkpdBVeq2GmfbK2ZbW1oZyX14VtiYRZnmSq6nnm7\", \"file_2\" : \"QmT7ximApXtExAedhzUHGHDwRismRzuKykpH4dgTvGrNZs, QmbqyQAkQVELXkkU3jaCTUHDPLHYrMCc7fUckeh83hmRcU\", \"file_3\" : \"QmZnh5Uuo7moZKMESFHpRjQFbbND5e3nArCzZg8uLARAgg, QmXgwRkPFxG2FWQTbVGgKsaEz7thbg4WLBcndsRfKUfeaa\", \"file_4\" : \"QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW, QmbKquQj5bMdMMHaNfacbXkT9NgwWbj157EPpRVi1tPPdx\", \"file_5\" : \"QmV1vYkuiwKGPA5Tyi4ECNFfWYocyTtQ3E5j7CSvPBX49Q, QmY7xwK4beVPQLbeKxEAeStqxY69f7GzRhqTukXXsLMkMh\", \"linked_user\" : \"crazy_nash@test\", \"project_metadata_cid\" : \"QmbmyecKUbwCDFPt6Uddx411bCvefLiRXPxHs5vnYz4XZm\" } }\n"
     ]
    }
   ],
   "source": [
    "#Query - GetAccountDetail\n",
    "query = iroha.query('GetAccountDetail',account_id=project_account['account_id'])\n",
    "IrohaCrypto.sign_query(query, ADMIN_PRIVATE_KEY)\n",
    "response = net.send_query(query)\n",
    "# print(response)\n",
    "project_data = response.account_detail_response\n",
    "project_details = project_data.detail\n",
    "print(f'Project Account id = {project_account}, {project_details}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f33098-43df-47f3-8708-f3212dec1c0f",
   "metadata": {},
   "source": [
    "6 - Queries the user account, locates the project id, queries the project account, gets the metadata and files from IPFS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "374843b3-6862-4a93-b298-1bdd0320c4c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{ \"admin@test\" : { \"linked_project\" : \"06535@test\", \"user_json_ld_cid\" : \"QmVQLbPmAqVYWPT1x9niJEC3w1YK5zxXYJPC8FraoasHuU\" } }\n",
      "{'admin@test': {'linked_project': '06535@test', 'user_json_ld_cid': 'QmVQLbPmAqVYWPT1x9niJEC3w1YK5zxXYJPC8FraoasHuU'}}\n",
      "06535@test\n"
     ]
    }
   ],
   "source": [
    "from ipfs_functions import *\n",
    "\n",
    "print(user_details)\n",
    "\n",
    "# Process the account details response\n",
    "user_details_dict = json.loads(user_details)  # Convert the string to a JSON object\n",
    "print(user_details_dict)\n",
    "\n",
    "# Now you can access the specific key like this\n",
    "linked_project = user_details_dict[\"admin@test\"][\"linked_project\"]\n",
    "print(linked_project)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "66b2f2c1-00b1-4b1b-8951-196af1f25208",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project Account id = {'account_id': '06535@test'}, { \"admin@test\" : { \"file_1\" : \"QmVk8gxENq6PThSGZTuk7RtbufR2XeN7LtXBj2LVTUoAdN, QmRxGqNkpdBVeq2GmfbK2ZbW1oZyX14VtiYRZnmSq6nnm7\", \"file_2\" : \"QmT7ximApXtExAedhzUHGHDwRismRzuKykpH4dgTvGrNZs, QmbqyQAkQVELXkkU3jaCTUHDPLHYrMCc7fUckeh83hmRcU\", \"file_3\" : \"QmZnh5Uuo7moZKMESFHpRjQFbbND5e3nArCzZg8uLARAgg, QmXgwRkPFxG2FWQTbVGgKsaEz7thbg4WLBcndsRfKUfeaa\", \"file_4\" : \"QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW, QmbKquQj5bMdMMHaNfacbXkT9NgwWbj157EPpRVi1tPPdx\", \"file_5\" : \"QmV1vYkuiwKGPA5Tyi4ECNFfWYocyTtQ3E5j7CSvPBX49Q, QmY7xwK4beVPQLbeKxEAeStqxY69f7GzRhqTukXXsLMkMh\", \"linked_user\" : \"crazy_nash@test\", \"project_metadata_cid\" : \"QmbmyecKUbwCDFPt6Uddx411bCvefLiRXPxHs5vnYz4XZm\" } }\n"
     ]
    }
   ],
   "source": [
    "#Query - GetAccountDetail\n",
    "query = iroha.query('GetAccountDetail', account_id=linked_project)\n",
    "IrohaCrypto.sign_query(query, ADMIN_PRIVATE_KEY)\n",
    "response = net.send_query(query)\n",
    "# print(response)\n",
    "project_data = response.account_detail_response\n",
    "project_details = project_data.detail\n",
    "print(f'Project Account id = {project_account}, {project_details}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6e7130f8-ad7d-4d0b-a521-ba0de69e9271",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'admin@test': {'file_1': 'QmVk8gxENq6PThSGZTuk7RtbufR2XeN7LtXBj2LVTUoAdN, QmRxGqNkpdBVeq2GmfbK2ZbW1oZyX14VtiYRZnmSq6nnm7', 'file_2': 'QmT7ximApXtExAedhzUHGHDwRismRzuKykpH4dgTvGrNZs, QmbqyQAkQVELXkkU3jaCTUHDPLHYrMCc7fUckeh83hmRcU', 'file_3': 'QmZnh5Uuo7moZKMESFHpRjQFbbND5e3nArCzZg8uLARAgg, QmXgwRkPFxG2FWQTbVGgKsaEz7thbg4WLBcndsRfKUfeaa', 'file_4': 'QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW, QmbKquQj5bMdMMHaNfacbXkT9NgwWbj157EPpRVi1tPPdx', 'file_5': 'QmV1vYkuiwKGPA5Tyi4ECNFfWYocyTtQ3E5j7CSvPBX49Q, QmY7xwK4beVPQLbeKxEAeStqxY69f7GzRhqTukXXsLMkMh', 'linked_user': 'crazy_nash@test', 'project_metadata_cid': 'QmbmyecKUbwCDFPt6Uddx411bCvefLiRXPxHs5vnYz4XZm'}}\n",
      "QmbmyecKUbwCDFPt6Uddx411bCvefLiRXPxHs5vnYz4XZm\n",
      "{'@context': {'dc': 'http://purl.org/dc/terms/', 'schema': 'http://schema.org/'}, '@type': 'schema:ResearchProject', 'dc:abstract': 'This study explores the impact of quantum computing in supply chain management, focusing on biodiversity.', 'schema:endDate': '2026-07-23', 'schema:funding': {'@type': 'schema:Organization', 'schema:name': 'National Science Foundation'}, 'schema:keywords': ['quantum computing', 'supply chain management', 'biodiversity'], 'schema:location': {'@type': 'schema:Place', 'schema:name': 'Lagos, Nigeria'}, 'schema:name': 'Investigating the Role of quantum computing in supply chain management', 'schema:startDate': '2023-07-03'}\n"
     ]
    }
   ],
   "source": [
    "# Convert the JSON string to a Python dictionary\n",
    "project_details_dict = json.loads(project_details)\n",
    "print(project_details_dict)\n",
    "\n",
    "# Now you can access the specific key like this\n",
    "project_metadata_cid = project_details_dict[\"admin@test\"][\"project_metadata_cid\"]\n",
    "print(project_metadata_cid)\n",
    "\n",
    "\n",
    "project_metadata = download_json_from_ipfs(project_metadata_cid)\n",
    "\n",
    "# print(20*\"-\")\n",
    "\n",
    "print(project_metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845d265a-50e1-423d-9e53-26226afe7756",
   "metadata": {},
   "source": [
    "7 -  Sends every file in the `upload` directory to IPFS, extracts theirs respective metadata with Apache Tika and sends it to IPFS, get the CIDs back and store in Iroha as details of the project account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4fcb7790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06535@test"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Opened existing index.\n",
      "INFO:root:Processing file: Integration Test.ipynb\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:File Integration Test.ipynb uploaded to IPFS with CID: QmVk8gxENq6PThSGZTuk7RtbufR2XeN7LtXBj2LVTUoAdN\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'metadata': {'X-TIKA:Parsed-By': ['org.apache.tika.parser.DefaultParser', 'org.apache.tika.parser.csv.TextAndCSVParser'], 'X-TIKA:Parsed-By-Full-Set': ['org.apache.tika.parser.DefaultParser', 'org.apache.tika.parser.csv.TextAndCSVParser'], 'X-TIKA:content_handler': 'ToTextContentHandler', 'Content-Encoding': 'ISO-8859-1', 'X-TIKA:parse_time_millis': '2', 'X-TIKA:embedded_depth': '0', 'resourceName': \"b'Integration Test.ipynb'\", 'Content-Length': '12716', 'Content-Type': 'text/plain; charset=ISO-8859-1'}, 'content': '\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n{\\n \"cells\": [\\n  {\\n   \"cell_type\": \"code\",\\n   \"execution_count\": 1,\\n   \"id\": \"b27efec9\",\\n   \"metadata\": {},\\n   \"outputs\": [],\\n   \"source\": [\\n    \"from new_helper import *\\\\n\",\\n    \"from super_helper import *\"\\n   ]\\n  },\\n  {\\n   \"cell_type\": \"code\",\\n   \"execution_count\": null,\\n   \"id\": \"79650b49\",\\n   \"metadata\": {},\\n   \"outputs\": [\\n    {\\n     \"name\": \"stdout\",\\n     \"output_type\": \"stream\",\\n     \"text\": [\\n      \"----------------------------------------\\\\n\"\\n     ]\\n    }\\n   ],\\n   \"source\": [\\n    \"id = \\\\\"96858\\\\\"\\\\n\",\\n    \"DOMAIN = \\\\\"test\\\\\"\\\\n\",\\n    \"\\\\n\",\\n    \"project_id = f\\\\\"{id}@{DOMAIN}\\\\\"\\\\n\",\\n    \"\\\\n\",\\n    \"directory_path = \\\\\"upload\\\\\"\\\\n\",\\n    \"\\\\n\",\\n    \"print(40*\\\\\"-\\\\\")\\\\n\",\\n    \"\\\\n\"\\n   ]\\n  },\\n  {\\n   \"cell_type\": \"code\",\\n   \"execution_count\": 3,\\n   \"id\": \"4d0d0bcb\",\\n   \"metadata\": {},\\n   \"outputs\": [\\n    {\\n     \"name\": \"stdout\",\\n     \"output_type\": \"stream\",\\n     \"text\": [\\n      \"<Schema: [\\'abstract\\', \\'cid\\', \\'created\\', \\'creator\\', \\'date\\', \\'description\\', \\'format\\', \\'full_text\\', \\'language\\', \\'modified\\', \\'project_id\\', \\'publisher\\', \\'subject\\', \\'title\\']>\\\\n\",\\n      \"file path:  upload/Aeroacoustic-airfoil-shape-optimization-enhance_2023_Expert-Systems-with-App.pdf\\\\n\",\\n      \"file name:  Aeroacoustic-airfoil-shape-optimization-enhance_2023_Expert-Systems-with-App.pdf\\\\n\",\\n      \"file cid:  QmXh37WXcrLXkJX2cAPjbPdKZ2cxJXD58XX6eU1Zc41ka4\\\\n\",\\n      \"file metadata cid:  QmWxedMfVwuGfyqnWZQpLi6PrpKmqiYLA1JziC2iwnMPyw\\\\n\",\\n      \"file_key : file_1\\\\n\",\\n      \"joined_cids : QmXh37WXcrLXkJX2cAPjbPdKZ2cxJXD58XX6eU1Zc41ka4, QmWxedMfVwuGfyqnWZQpLi6PrpKmqiYLA1JziC2iwnMPyw\\\\n\",\\n      \"\\\\tEntering \\\\\"create_contract\\\\\"\\\\n\",\\n      \"(\\'STATELESS_VALIDATION_SUCCESS\\', 1, 0)\\\\n\",\\n      \"(\\'ENOUGH_SIGNATURES_COLLECTED\\', 9, 0)\\\\n\",\\n      \"(\\'STATEFUL_VALIDATION_SUCCESS\\', 3, 0)\\\\n\",\\n      \"(\\'COMMITTED\\', 5, 0)\\\\n\",\\n      \"\\\\tLeaving \\\\\"create_contract\\\\\"\\\\n\",\\n      \"\\\\tEntering \\\\\"get_engine_receipts_address\\\\\"\\\\n\",\\n      \"\\\\tLeaving \\\\\"get_engine_receipts_address\\\\\"\\\\n\",\\n      \"\\\\tEntering \\\\\"set_account_detail\\\\\"\\\\n\",\\n      \"None\\\\n\",\\n      \"(\\'STATELESS_VALIDATION_SUCCESS\\', 1, 0)\\\\n\",\\n      \"(\\'ENOUGH_SIGNATURES_COLLECTED\\', 9, 0)\\\\n\"\\n     ]\\n    },\\n    {\\n     \"name\": \"stderr\",\\n     \"output_type\": \"stream\",\\n     \"text\": [\\n      \"\\\\u001b[32m2024-12-30 22:51:20.937\\\\u001b[0m | \\\\u001b[1mINFO    \\\\u001b[0m | \\\\u001b[36msuper_helper\\\\u001b[0m:\\\\u001b[36msetup_index\\\\u001b[0m:\\\\u001b[36m216\\\\u001b[0m - \\\\u001b[1mOpened existing index.\\\\u001b[0m\\\\n\",\\n      \"\\\\u001b[32m2024-12-30 22:51:21.091\\\\u001b[0m | \\\\u001b[1mINFO    \\\\u001b[0m | \\\\u001b[36msuper_helper\\\\u001b[0m:\\\\u001b[36mindex_metadata\\\\u001b[0m:\\\\u001b[36m95\\\\u001b[0m - \\\\u001b[1mMetadata indexed successfully: QmWxedMfVwuGfyqnWZQpLi6PrpKmqiYLA1JziC2iwnMPyw\\\\u001b[0m\\\\n\"\\n     ]\\n    },\\n    {\\n     \"name\": \"stdout\",\\n     \"output_type\": \"stream\",\\n     \"text\": [\\n      \"(\\'STATEFUL_VALIDATION_SUCCESS\\', 3, 0)\\\\n\",\\n      \"(\\'COMMITTED\\', 5, 0)\\\\n\",\\n      \"\\\\tLeaving \\\\\"set_account_detail\\\\\"\\\\n\",\\n      \"hash : b\\'90332ef5cdca10b8377c5ac37d0327d169d28c461d146c3219afe8d87aacf68b\\'\\\\n\",\\n      \"This is ix:  FileIndex(FileStorage(\\'indexdir\\'), \\'MAIN\\')\\\\n\",\\n      \"file path:  upload/bitcoin.pdf\\\\n\",\\n      \"file name:  bitcoin.pdf\\\\n\",\\n      \"file cid:  QmRA3NWM82ZGynMbYzAgYTSXCVM14Wx1RZ8fKP42G6gjgj\\\\n\",\\n      \"file metadata cid:  QmYAfm2E6b5EhzmN3QkzyfVgRSRUczBpaVDNYGhHrG3gQA\\\\n\",\\n      \"file_key : file_2\\\\n\",\\n      \"joined_cids : QmRA3NWM82ZGynMbYzAgYTSXCVM14Wx1RZ8fKP42G6gjgj, QmYAfm2E6b5EhzmN3QkzyfVgRSRUczBpaVDNYGhHrG3gQA\\\\n\",\\n      \"\\\\tEntering \\\\\"set_account_detail\\\\\"\\\\n\",\\n      \"None\\\\n\",\\n      \"(\\'STATELESS_VALIDATION_SUCCESS\\', 1, 0)\\\\n\",\\n      \"(\\'ENOUGH_SIGNATURES_COLLECTED\\', 9, 0)\\\\n\"\\n     ]\\n    },\\n    {\\n     \"name\": \"stderr\",\\n     \"output_type\": \"stream\",\\n     \"text\": [\\n      \"\\\\u001b[32m2024-12-30 22:51:23.984\\\\u001b[0m | \\\\u001b[1mINFO    \\\\u001b[0m | \\\\u001b[36msuper_helper\\\\u001b[0m:\\\\u001b[36msetup_index\\\\u001b[0m:\\\\u001b[36m216\\\\u001b[0m - \\\\u001b[1mOpened existing index.\\\\u001b[0m\\\\n\",\\n      \"\\\\u001b[32m2024-12-30 22:51:24.076\\\\u001b[0m | \\\\u001b[1mINFO    \\\\u001b[0m | \\\\u001b[36msuper_helper\\\\u001b[0m:\\\\u001b[36mindex_metadata\\\\u001b[0m:\\\\u001b[36m95\\\\u001b[0m - \\\\u001b[1mMetadata indexed successfully: QmYAfm2E6b5EhzmN3QkzyfVgRSRUczBpaVDNYGhHrG3gQA\\\\u001b[0m\\\\n\"\\n     ]\\n    },\\n    {\\n     \"name\": \"stdout\",\\n     \"output_type\": \"stream\",\\n     \"text\": [\\n      \"(\\'STATEFUL_VALIDATION_SUCCESS\\', 3, 0)\\\\n\",\\n      \"(\\'COMMITTED\\', 5, 0)\\\\n\",\\n      \"\\\\tLeaving \\\\\"set_account_detail\\\\\"\\\\n\",\\n      \"hash : b\\'b98e82f87fbc532c4a3be6fc4a3854515601ab22dfa133d2f902a36c0b1ca437\\'\\\\n\",\\n      \"This is ix:  FileIndex(FileStorage(\\'indexdir\\'), \\'MAIN\\')\\\\n\"\\n     ]\\n    }\\n   ],\\n   \"source\": [\\n    \"\\\\n\",\\n    \"\\\\n\",\\n    \"schema = get_schema() #super_helper.py\\\\n\",\\n    \"\\\\n\",\\n    \"print(schema)\\\\n\",\\n    \"\\\\n\",\\n    \"processed_data = process_files(directory_path, project_id, schema) #new_helper.py\\\\n\",\\n    \" \\\\n\",\\n    \"    \"\\n   ]\\n  },\\n  {\\n   \"cell_type\": \"code\",\\n   \"execution_count\": 4,\\n   \"id\": \"96c16c27\",\\n   \"metadata\": {},\\n   \"outputs\": [\\n    {\\n     \"name\": \"stdout\",\\n     \"output_type\": \"stream\",\\n     \"text\": [\\n      \"Project Account id = id, { \\\\\"admin@test\\\\\" : { \\\\\"file_1\\\\\" : \\\\\"QmXh37WXcrLXkJX2cAPjbPdKZ2cxJXD58XX6eU1Zc41ka4, QmWxedMfVwuGfyqnWZQpLi6PrpKmqiYLA1JziC2iwnMPyw\\\\\", \\\\\"file_2\\\\\" : \\\\\"QmRA3NWM82ZGynMbYzAgYTSXCVM14Wx1RZ8fKP42G6gjgj, QmYAfm2E6b5EhzmN3QkzyfVgRSRUczBpaVDNYGhHrG3gQA\\\\\", \\\\\"project_metadata_cid\\\\\" : \\\\\"QmbmyecKUbwCDFPt6Uddx411bCvefLiRXPxHs5vnYz4XZm\\\\\" } }\\\\n\"\\n     ]\\n    }\\n   ],\\n   \"source\": [\\n    \"account_detail = get_account_detail(project_id)\\\\n\"\\n   ]\\n  },\\n  {\\n   \"cell_type\": \"code\",\\n   \"execution_count\": 5,\\n   \"id\": \"053afc13\",\\n   \"metadata\": {},\\n   \"outputs\": [],\\n   \"source\": [\\n    \"# recreate_index() #Controls the reset of the index manually\"\\n   ]\\n  },\\n  {\\n   \"cell_type\": \"code\",\\n   \"execution_count\": 6,\\n   \"id\": \"02b32910\",\\n   \"metadata\": {},\\n   \"outputs\": [\\n    {\\n     \"name\": \"stderr\",\\n     \"output_type\": \"stream\",\\n     \"text\": [\\n      \"\\\\u001b[32m2024-12-30 22:51:24.161\\\\u001b[0m | \\\\u001b[1mINFO    \\\\u001b[0m | \\\\u001b[36msuper_helper\\\\u001b[0m:\\\\u001b[36msearch_index\\\\u001b[0m:\\\\u001b[36m150\\\\u001b[0m - \\\\u001b[1mStarting keyword search...\\\\u001b[0m\\\\n\",\\n      \"\\\\u001b[32m2024-12-30 22:51:24.163\\\\u001b[0m | \\\\u001b[1mINFO    \\\\u001b[0m | \\\\u001b[36msuper_helper\\\\u001b[0m:\\\\u001b[36msearch_index\\\\u001b[0m:\\\\u001b[36m151\\\\u001b[0m - \\\\u001b[1mKeyword: \\'airfoil\\'\\\\u001b[0m\\\\n\",\\n      \"\\\\u001b[32m2024-12-30 22:51:24.188\\\\u001b[0m | \\\\u001b[1mINFO    \\\\u001b[0m | \\\\u001b[36msuper_helper\\\\u001b[0m:\\\\u001b[36msearch_index\\\\u001b[0m:\\\\u001b[36m162\\\\u001b[0m - \\\\u001b[1mSearch successful: Found 1 result(s).\\\\u001b[0m\\\\n\",\\n      \"\\\\u001b[32m2024-12-30 22:51:24.191\\\\u001b[0m | \\\\u001b[1mINFO    \\\\u001b[0m | \\\\u001b[36msuper_helper\\\\u001b[0m:\\\\u001b[36msearch_index\\\\u001b[0m:\\\\u001b[36m164\\\\u001b[0m - \\\\u001b[1m1. Project Id: 06535@test, Metadata CID: QmWxedMfVwuGfyqnWZQpLi6PrpKmqiYLA1JziC2iwnMPyw, Title: aeroacoustic airfoil shape optimization enhanced by autoencoders\\\\u001b[0m\\\\n\"\\n     ]\\n    },\\n    {\\n     \"name\": \"stdout\",\\n     \"output_type\": \"stream\",\\n     \"text\": [\\n      \"[\\'06535@test\\']\\\\n\"\\n     ]\\n    }\\n   ],\\n   \"source\": [\\n    \"\\\\n\",\\n    \"# Open an existing index (adjust the path to your index directory)\\\\n\",\\n    \"index_path = \\\\\"indexdir\\\\\"\\\\n\",\\n    \"index = open_dir(index_path)\\\\n\",\\n    \"\\\\n\",\\n    \"# Perform a keyword search\\\\n\",\\n    \"keyword = \\\\\"airfoil\\\\\"\\\\n\",\\n    \"# results = search_index(index, keyword)\\\\n\",\\n    \"\\\\n\",\\n    \"search_results, project_ids = search_index(index, keyword)\\\\n\",\\n    \"\\\\n\",\\n    \"print(project_ids)  # Will print a list of extracted project IDs\\\\n\",\\n    \"\\\\n\",\\n    \"# Convert project_ids to a set to remove duplicates\\\\n\",\\n    \"unique_project_ids = set(project_ids)\"\\n   ]\\n  },\\n  {\\n   \"cell_type\": \"code\",\\n   \"execution_count\": 7,\\n   \"id\": \"fe8d9292\",\\n   \"metadata\": {},\\n   \"outputs\": [\\n    {\\n     \"name\": \"stdout\",\\n     \"output_type\": \"stream\",\\n     \"text\": [\\n      \"[{\\'account_id\\': \\'06535@test\\', \\'project_details\\': \\'{ \\\\\"admin@test\\\\\" : { \\\\\"file_1\\\\\" : \\\\\"QmXh37WXcrLXkJX2cAPjbPdKZ2cxJXD58XX6eU1Zc41ka4, QmWxedMfVwuGfyqnWZQpLi6PrpKmqiYLA1JziC2iwnMPyw\\\\\", \\\\\"file_2\\\\\" : \\\\\"QmRA3NWM82ZGynMbYzAgYTSXCVM14Wx1RZ8fKP42G6gjgj, QmYAfm2E6b5EhzmN3QkzyfVgRSRUczBpaVDNYGhHrG3gQA\\\\\", \\\\\"project_metadata_cid\\\\\" : \\\\\"QmbmyecKUbwCDFPt6Uddx411bCvefLiRXPxHs5vnYz4XZm\\\\\" } }\\'}]\\\\n\"\\n     ]\\n    }\\n   ],\\n   \"source\": [\\n    \"\\\\n\",\\n    \"# Step 2: Fetch project details for matched project IDs\\\\n\",\\n    \"project_details = get_project_details(unique_project_ids, net, iroha)\\\\n\",\\n    \"print(project_details)\\\\n\",\\n    \"\\\\n\"\\n   ]\\n  },\\n  {\\n   \"cell_type\": \"code\",\\n   \"execution_count\": 8,\\n   \"id\": \"80b3e00f\",\\n   \"metadata\": {},\\n   \"outputs\": [\\n    {\\n     \"ename\": \"TypeError\",\\n     \"evalue\": \"the JSON object must be str, bytes or bytearray, not list\",\\n     \"output_type\": \"error\",\\n     \"traceback\": [\\n      \"\\\\u001b[0;31m---------------------------------------------------------------------------\\\\u001b[0m\",\\n      \"\\\\u001b[0;31mTypeError\\\\u001b[0m                                 Traceback (most recent call last)\",\\n      \"Cell \\\\u001b[0;32mIn[8], line 2\\\\u001b[0m\\\\n\\\\u001b[1;32m      1\\\\u001b[0m \\\\u001b[38;5;66;03m# Convert the JSON string to a Python dictionary\\\\u001b[39;00m\\\\n\\\\u001b[0;32m----> 2\\\\u001b[0m project_details_dict \\\\u001b[38;5;241m=\\\\u001b[39m \\\\u001b[43mjson\\\\u001b[49m\\\\u001b[38;5;241;43m.\\\\u001b[39;49m\\\\u001b[43mloads\\\\u001b[49m\\\\u001b[43m(\\\\u001b[49m\\\\u001b[43mproject_details\\\\u001b[49m\\\\u001b[43m)\\\\u001b[49m\\\\n\\\\u001b[1;32m      4\\\\u001b[0m \\\\u001b[38;5;66;03m# Convert the JSON string to a Python dictionary\\\\u001b[39;00m\\\\n\\\\u001b[1;32m      5\\\\u001b[0m project_details_dict \\\\u001b[38;5;241m=\\\\u001b[39m json\\\\u001b[38;5;241m.\\\\u001b[39mloads(project_details)\\\\n\",\\n      \"File \\\\u001b[0;32m/usr/local/lib/python3.9/json/__init__.py:339\\\\u001b[0m, in \\\\u001b[0;36mloads\\\\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\\\\u001b[0m\\\\n\\\\u001b[1;32m    337\\\\u001b[0m \\\\u001b[38;5;28;01melse\\\\u001b[39;00m:\\\\n\\\\u001b[1;32m    338\\\\u001b[0m     \\\\u001b[38;5;28;01mif\\\\u001b[39;00m \\\\u001b[38;5;129;01mnot\\\\u001b[39;00m \\\\u001b[38;5;28misinstance\\\\u001b[39m(s, (\\\\u001b[38;5;28mbytes\\\\u001b[39m, \\\\u001b[38;5;28mbytearray\\\\u001b[39m)):\\\\n\\\\u001b[0;32m--> 339\\\\u001b[0m         \\\\u001b[38;5;28;01mraise\\\\u001b[39;00m \\\\u001b[38;5;167;01mTypeError\\\\u001b[39;00m(\\\\u001b[38;5;124mf\\\\u001b[39m\\\\u001b[38;5;124m\\'\\\\u001b[39m\\\\u001b[38;5;124mthe JSON object must be str, bytes or bytearray, \\\\u001b[39m\\\\u001b[38;5;124m\\'\\\\u001b[39m\\\\n\\\\u001b[1;32m    340\\\\u001b[0m                         \\\\u001b[38;5;124mf\\\\u001b[39m\\\\u001b[38;5;124m\\'\\\\u001b[39m\\\\u001b[38;5;124mnot \\\\u001b[39m\\\\u001b[38;5;132;01m{\\\\u001b[39;00ms\\\\u001b[38;5;241m.\\\\u001b[39m\\\\u001b[38;5;18m__class__\\\\u001b[39m\\\\u001b[38;5;241m.\\\\u001b[39m\\\\u001b[38;5;18m__name__\\\\u001b[39m\\\\u001b[38;5;132;01m}\\\\u001b[39;00m\\\\u001b[38;5;124m\\'\\\\u001b[39m)\\\\n\\\\u001b[1;32m    341\\\\u001b[0m     s \\\\u001b[38;5;241m=\\\\u001b[39m s\\\\u001b[38;5;241m.\\\\u001b[39mdecode(detect_encoding(s), \\\\u001b[38;5;124m\\'\\\\u001b[39m\\\\u001b[38;5;124msurrogatepass\\\\u001b[39m\\\\u001b[38;5;124m\\'\\\\u001b[39m)\\\\n\\\\u001b[1;32m    343\\\\u001b[0m \\\\u001b[38;5;28;01mif\\\\u001b[39;00m (\\\\u001b[38;5;28mcls\\\\u001b[39m \\\\u001b[38;5;129;01mis\\\\u001b[39;00m \\\\u001b[38;5;28;01mNone\\\\u001b[39;00m \\\\u001b[38;5;129;01mand\\\\u001b[39;00m object_hook \\\\u001b[38;5;129;01mis\\\\u001b[39;00m \\\\u001b[38;5;28;01mNone\\\\u001b[39;00m \\\\u001b[38;5;129;01mand\\\\u001b[39;00m\\\\n\\\\u001b[1;32m    344\\\\u001b[0m         parse_int \\\\u001b[38;5;129;01mis\\\\u001b[39;00m \\\\u001b[38;5;28;01mNone\\\\u001b[39;00m \\\\u001b[38;5;129;01mand\\\\u001b[39;00m parse_float \\\\u001b[38;5;129;01mis\\\\u001b[39;00m \\\\u001b[38;5;28;01mNone\\\\u001b[39;00m \\\\u001b[38;5;129;01mand\\\\u001b[39;00m\\\\n\\\\u001b[1;32m    345\\\\u001b[0m         parse_constant \\\\u001b[38;5;129;01mis\\\\u001b[39;00m \\\\u001b[38;5;28;01mNone\\\\u001b[39;00m \\\\u001b[38;5;129;01mand\\\\u001b[39;00m object_pairs_hook \\\\u001b[38;5;129;01mis\\\\u001b[39;00m \\\\u001b[38;5;28;01mNone\\\\u001b[39;00m \\\\u001b[38;5;129;01mand\\\\u001b[39;00m \\\\u001b[38;5;129;01mnot\\\\u001b[39;00m kw):\\\\n\",\\n      \"\\\\u001b[0;31mTypeError\\\\u001b[0m: the JSON object must be str, bytes or bytearray, not list\"\\n     ]\\n    }\\n   ],\\n   \"source\": [\\n    \"# Convert the JSON string to a Python dictionary\\\\n\",\\n    \"project_details_dict = json.loads(project_details)\\\\n\",\\n    \"\\\\n\",\\n    \"# Convert the JSON string to a Python dictionary\\\\n\",\\n    \"project_details_dict = json.loads(project_details)\\\\n\",\\n    \"\\\\n\",\\n    \"# Get the value of the dictionary (actual file metadata)\\\\n\",\\n    \"files_metadata = project_details_dict[\\'admin@test\\']\\\\n\",\\n    \"print(files_metadata)\"\\n   ]\\n  }\\n ],\\n \"metadata\": {\\n  \"kernelspec\": {\\n   \"display_name\": \"Python 3 (ipykernel)\",\\n   \"language\": \"python\",\\n   \"name\": \"python3\"\\n  },\\n  \"language_info\": {\\n   \"codemirror_mode\": {\\n    \"name\": \"ipython\",\\n    \"version\": 3\\n   },\\n   \"file_extension\": \".py\",\\n   \"mimetype\": \"text/x-python\",\\n   \"name\": \"python\",\\n   \"nbconvert_exporter\": \"python\",\\n   \"pygments_lexer\": \"ipython3\",\\n   \"version\": \"3.9.21\"\\n  }\\n },\\n \"nbformat\": 4,\\n \"nbformat_minor\": 5\\n}\\n\\n', 'status': 200}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Indexed Integration Test.ipynb with CID: QmWuj7Rr8PjwGzGW5otvAVTDUywUt8BHh7uvawFqEreMJo\n",
      "INFO:root:Document Integration Test.ipynb indexed successfully.\n",
      "INFO:root:updated project entry\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Error processing file 'Integration Test.ipynb': sequence item 0: expected a bytes-like object, str found\n",
      "INFO:root:Processing file: Diabetic-retinopathy-identification-using-parallel-convo_2023_Expert-Systems.pdf\n",
      "INFO:root:File Diabetic-retinopathy-identification-using-parallel-convo_2023_Expert-Systems.pdf uploaded to IPFS with CID: QmT7ximApXtExAedhzUHGHDwRismRzuKykpH4dgTvGrNZs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dublin Core Metadata:\n",
      "{}\n",
      "Loaded project data successfully.\n",
      "Current project_data: {\n",
      "    \"@context\": {\n",
      "        \"schema\": \"http://schema.org/\",\n",
      "        \"dc\": \"http://purl.org/dc/terms/\"\n",
      "    },\n",
      "    \"@graph\": [\n",
      "        {\n",
      "            \"@type\": \"schema:ResearchProject\",\n",
      "            \"schema:identifier\": \"06535@test\",\n",
      "            \"schema:publicKey\": \"7851c382158dc0349df2136ae8821753b98b65be412387181764005baf9bff20\",\n",
      "            \"schema:description\": {\n",
      "                \"@context\": {\n",
      "                    \"schema\": \"http://schema.org/\",\n",
      "                    \"dc\": \"http://purl.org/dc/terms/\"\n",
      "                },\n",
      "                \"@type\": \"schema:ResearchProject\",\n",
      "                \"schema:name\": \"Investigating the Role of quantum computing in supply chain management\",\n",
      "                \"dc:abstract\": \"This study explores the impact of quantum computing in supply chain management, focusing on biodiversity.\",\n",
      "                \"schema:keywords\": [\n",
      "                    \"quantum computing\",\n",
      "                    \"supply chain management\",\n",
      "                    \"biodiversity\"\n",
      "                ],\n",
      "                \"schema:startDate\": \"2023-07-03\",\n",
      "                \"schema:endDate\": \"2026-07-23\",\n",
      "                \"schema:funding\": {\n",
      "                    \"@type\": \"schema:Organization\",\n",
      "                    \"schema:name\": \"National Science Foundation\"\n",
      "                },\n",
      "                \"schema:location\": {\n",
      "                    \"@type\": \"schema:Place\",\n",
      "                    \"schema:name\": \"Lagos, Nigeria\"\n",
      "                }\n",
      "            },\n",
      "            \"schema:metadataCID\": \"QmbmyecKUbwCDFPt6Uddx411bCvefLiRXPxHs5vnYz4XZm\",\n",
      "            \"schema:linked_user\": \"crazy_nash@test\"\n",
      "        },\n",
      "        {\n",
      "            \"@type\": \"schema:ResearchProject\",\n",
      "            \"schema:identifier\": \"96858@test\",\n",
      "            \"schema:publicKey\": \"964dbc74f346b43a17060e1c451b5fd50873d0a2fe69188f32b2f8dbab052cfa\",\n",
      "            \"schema:description\": {\n",
      "                \"@context\": {\n",
      "                    \"schema\": \"http://schema.org/\",\n",
      "                    \"dc\": \"http://purl.org/dc/terms/\"\n",
      "                },\n",
      "                \"@type\": \"schema:ResearchProject\",\n",
      "                \"schema:name\": \"Analyzing the Influence of gene therapy on urban resilience\",\n",
      "                \"dc:abstract\": \"This paper analyzes how gene therapy influences urban resilience, providing insights into how to maximize its climate resilience.\",\n",
      "                \"schema:keywords\": [\n",
      "                    \"gene therapy\",\n",
      "                    \"urban resilience\",\n",
      "                    \"climate resilience\"\n",
      "                ],\n",
      "                \"schema:startDate\": \"2018-04-08\",\n",
      "                \"schema:endDate\": \"2026-06-05\",\n",
      "                \"schema:funding\": {\n",
      "                    \"@type\": \"schema:Organization\",\n",
      "                    \"schema:name\": \"National Science Foundation\"\n",
      "                },\n",
      "                \"schema:location\": {\n",
      "                    \"@type\": \"schema:Place\",\n",
      "                    \"schema:name\": \"Phuket, Thailand\"\n",
      "                }\n",
      "            },\n",
      "            \"schema:metadataCID\": \"QmRgbWW7QFgTWTRQqmjDv7fX6YypV8absEUSXwiw8f1Pn6\"\n",
      "        },\n",
      "        {\n",
      "            \"@type\": \"schema:ResearchProject\",\n",
      "            \"schema:identifier\": \"37887@test\",\n",
      "            \"schema:publicKey\": \"64593fc6dc0eb621cc258ffb3b180a171bcccb225bfea253084600c768776432\",\n",
      "            \"schema:description\": {\n",
      "                \"@context\": {\n",
      "                    \"schema\": \"http://schema.org/\",\n",
      "                    \"dc\": \"http://purl.org/dc/terms/\"\n",
      "                },\n",
      "                \"@type\": \"schema:ResearchProject\",\n",
      "                \"schema:name\": \"Analyzing the Influence of bioinformatics on climate adaptation\",\n",
      "                \"dc:abstract\": \"This paper analyzes how bioinformatics influences climate adaptation, providing insights into how to maximize its scientific discovery.\",\n",
      "                \"schema:keywords\": [\n",
      "                    \"bioinformatics\",\n",
      "                    \"climate adaptation\",\n",
      "                    \"scientific discovery\"\n",
      "                ],\n",
      "                \"schema:startDate\": \"2021-01-20\",\n",
      "                \"schema:endDate\": \"2028-06-16\",\n",
      "                \"schema:funding\": {\n",
      "                    \"@type\": \"schema:Organization\",\n",
      "                    \"schema:name\": \"World Wildlife Fund\"\n",
      "                },\n",
      "                \"schema:location\": {\n",
      "                    \"@type\": \"schema:Place\",\n",
      "                    \"schema:name\": \"Tokyo, Japan\"\n",
      "                }\n",
      "            },\n",
      "            \"schema:metadataCID\": \"QmT1cPcYNcGntxCc2goVmkJuQG9EdVthjvG6SVNs7WCXc8\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "Checking project with ID: '06535@test' against '06535@test'\n",
      "Match found for project ID: 06535@test\n",
      "Updated project 06535@test with new file entry: {'file_index': 1, 'file_cid': 'QmVk8gxENq6PThSGZTuk7RtbufR2XeN7LtXBj2LVTUoAdN', 'metadata_cid': 'QmWuj7Rr8PjwGzGW5otvAVTDUywUt8BHh7uvawFqEreMJo', 'metadata': {}}\n",
      "Successfully wrote updated data to datasets/projects.json\n",
      "----------------------------------------\n",
      "{'X-TIKA:Parsed-By': ['org.apache.tika.parser.DefaultParser', 'org.apache.tika.parser.csv.TextAndCSVParser'], 'X-TIKA:Parsed-By-Full-Set': ['org.apache.tika.parser.DefaultParser', 'org.apache.tika.parser.csv.TextAndCSVParser'], 'X-TIKA:content_handler': 'ToTextContentHandler', 'Content-Encoding': 'ISO-8859-1', 'X-TIKA:parse_time_millis': '2', 'X-TIKA:embedded_depth': '0', 'resourceName': \"b'Integration Test.ipynb'\", 'Content-Length': '12716', 'Content-Type': 'text/plain; charset=ISO-8859-1'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Indexed Diabetic-retinopathy-identification-using-parallel-convo_2023_Expert-Systems.pdf with CID: QmcqzQsw6F8w5vYV49gQYmzMM1WuQcrXFVASqwThDgyb14\n",
      "INFO:root:Document Diabetic-retinopathy-identification-using-parallel-convo_2023_Expert-Systems.pdf indexed successfully.\n",
      "INFO:root:updated project entry\n",
      "ERROR:root:Error processing file 'Diabetic-retinopathy-identification-using-parallel-convo_2023_Expert-Systems.pdf': sequence item 0: expected a bytes-like object, str found\n",
      "INFO:root:Processing file: Editorial-Board_2023_Expert-Systems-with-Applications.pdf\n",
      "INFO:root:File Editorial-Board_2023_Expert-Systems-with-Applications.pdf uploaded to IPFS with CID: QmZnh5Uuo7moZKMESFHpRjQFbbND5e3nArCzZg8uLARAgg\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'metadata': {'pdf:PDFVersion': '1.7', 'xmp:CreatorTool': 'Elsevier', 'pdf:docinfo:title': 'Diabetic retinopathy identification using parallel convolutional neural network based feature extractor and ELM classifier', 'pdf:hasXFA': 'false', 'access_permission:can_print_degraded': 'true', 'X-TIKA:Parsed-By-Full-Set': ['org.apache.tika.parser.DefaultParser', 'org.apache.tika.parser.pdf.PDFParser'], 'X-TIKA:content_handler': 'ToTextContentHandler', 'pdf:num3DAnnotations': '0', 'dc:format': 'application/pdf; version=1.7', 'pdf:docinfo:custom:robots': 'noindex', 'pdf:docinfo:creator_tool': 'Elsevier', 'access_permission:fill_in_form': 'true', 'pdf:docinfo:custom:CreationDate--Text': '7th February 2023', 'pdf:hasCollection': 'false', 'pdf:encrypted': 'false', 'dc:title': 'Diabetic retinopathy identification using parallel convolutional neural network based feature extractor and ELM classifier', 'pdf:containsNonEmbeddedFont': 'false', 'xmp:CreateDate': '2023-02-04T09:40:15Z', 'pdf:docinfo:custom:CrossMarkDomains[1]': 'elsevier.com', 'robots': 'noindex', 'pdf:docinfo:subject': 'Expert Systems With Applications, 217 (2023) 119557. doi:10.1016/j.eswa.2023.119557', 'pdf:hasMarkedContent': 'true', 'xmp:ModifyDate': '2023-02-07T17:54:35Z', 'pdf:docinfo:creator': 'Md. Nahiduzzaman', 'pdf:docinfo:custom:CrossmarkMajorVersionDate': '2010-04-23', 'access_permission:extract_for_accessibility': 'true', 'resourceName': \"b'Diabetic-retinopathy-identification-using-parallel-convo_2023_Expert-Systems.pdf'\", 'pdf:docinfo:custom:CrossMarkDomains[2]': 'sciencedirect.com', 'X-TIKA:Parsed-By': ['org.apache.tika.parser.DefaultParser', 'org.apache.tika.parser.pdf.PDFParser'], 'ElsevierWebPDFSpecifications': '7.0', 'pdf:docinfo:custom:doi': '10.1016/j.eswa.2023.119557', 'pdf:docinfo:custom:CrossmarkDomainExclusive': 'true', 'X-TIKA:embedded_depth': '0', 'CrossmarkDomainExclusive': 'true', 'pdf:annotationTypes': 'null', 'pdf:docinfo:producer': 'Acrobat Distiller 8.1.0 (Windows)', 'pdf:annotationSubtypes': 'Link', 'CreationDate--Text': '7th February 2023', 'doi': '10.1016/j.eswa.2023.119557', 'pdf:containsDamagedFont': 'false', 'pdf:unmappedUnicodeCharsPerPage': ['0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0'], 'dc:description': 'Expert Systems With Applications, 217 (2023) 119557. doi:10.1016/j.eswa.2023.119557', 'access_permission:modify_annotations': 'true', 'dc:creator': ['Md. Nahiduzzaman', 'Md. Robiul Islam', 'Md. Omaer Faruq Goni', 'Md. Shamim Anower', 'Mominul Ahsan', 'Julfikar Haider', 'Marcin Kowalski'], 'dcterms:created': '2023-02-04T09:40:15Z', 'dcterms:modified': '2023-02-07T17:54:35Z', 'xmpMM:DocumentID': 'uuid:1b499bed-4ce8-4c0c-b682-0d58baae1cbe', 'CrossMarkDomains[1]': 'elsevier.com', 'pdf:overallPercentageUnmappedUnicodeChars': '0.0', 'pdf:docinfo:keywords': 'Contrast limited adaptive histogram equalization (CLAHE),Diabetic retinopathy (DR),Parallel convolutional neural network (PCNN),Extreme LEARNING MACHine (ELM)', 'pdf:docinfo:modified': '2023-02-07T17:54:35Z', 'Content-Length': '6122917', 'Content-Type': 'application/pdf', 'xmp:MetadataDate': '2023-02-07T17:54:35Z', 'dc:language': 'en', 'pdf:producer': 'Acrobat Distiller 8.1.0 (Windows)', 'dc:subject': ['Contrast limited adaptive histogram equalization (CLAHE),Diabetic retinopathy (DR),Parallel convolutional neural network (PCNN),Extreme LEARNING MACHine (ELM)', 'Expert Systems With Applications, 217 (2023) 119557. doi:10.1016/j.eswa.2023.119557'], 'pdf:docinfo:custom:ElsevierWebPDFSpecifications': '7.0', 'pdf:totalUnmappedUnicodeChars': '0', 'access_permission:assemble_document': 'true', 'xmpTPg:NPages': '11', 'pdf:hasXMP': 'true', 'pdf:charsPerPage': ['4980', '8262', '7998', '1077', '4759', '5305', '3814', '3469', '7158', '10210', '4231'], 'access_permission:extract_content': 'true', 'access_permission:can_print': 'true', 'CrossMarkDomains[2]': 'sciencedirect.com', 'meta:keyword': 'Contrast limited adaptive histogram equalization (CLAHE),Diabetic retinopathy (DR),Parallel convolutional neural network (PCNN),Extreme LEARNING MACHine (ELM)', 'X-TIKA:parse_time_millis': '173', 'access_permission:can_modify': 'true', 'pdf:docinfo:created': '2023-02-04T09:40:15Z', 'CrossmarkMajorVersionDate': '2010-04-23'}, 'content': '\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nDiabetic retinopathy identification using parallel convolutional neural network based feature extractor and ELM classifier\\n\\n\\nExpert Systems With Applications 217 (2023) 119557\\n\\nAvailable online 13 January 2023\\n0957-4174/ 2023 The Authors. Published by Elsevier Ltd. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-\\nnc-nd/4.0/).\\n\\nDiabetic retinopathy identification using parallel convolutional neural \\nnetwork based feature extractor and ELM classifier \\n\\nMd. Nahiduzzaman a,f, Md. Robiul Islam a, Md. Omaer Faruq Goni a, Md. Shamim Anower b, \\nMominul Ahsan c, Julfikar Haider d, Marcin Kowalski e,* \\n\\na Department of Electrical & Computer Engineering, Rajshahi University of Engineering & Technology, Rajshahi 6204, Bangladesh \\nb Department of Electrical & Electronic Engineering, Rajshahi University of Engineering & Technology, Rajshahi 6204, Bangladesh \\nc Department of Computer Science, University of York, Deramore Lane, Heslington, York YO10 5GH, UK \\nd Department of Engineering, Manchester Metropolitan University, Chester St, Manchester M1 5GD, UK \\ne Institute of Optoelectronics, Military University of Technology, Gen. S. Kaliskiego 2, 00-908 Warsaw, Poland \\nf Department of Electrical Engineering, Qatar University, Doha 2713, Qatar   \\n\\nA R T I C L E  I N F O   \\n\\nKeywords: \\nContrast limited adaptive histogram \\nequalization (CLAHE) \\nDiabetic retinopathy (DR) \\nParallel convolutional neural network (PCNN) \\nExtreme LEARNING MACHine (ELM) \\n\\nA B S T R A C T   \\n\\nDiabetic retinopathy (DR) is an incurable retinal condition caused by excessive blood sugar that, if left untreated, \\ncan result in even blindness. A novel automated technique for DR detection has been proposed in this paper. To \\naccentuate the lesions, the fundus images (FIs) were preprocessed using Contrast Limited Adaptive Histogram \\nEqualization (CLAHE). A parallel convolutional neural network (PCNN) was employed for feature extraction and \\nthen the extreme learning machine (ELM) technique was utilized for the DR classification. In comparison to the \\nsimilar CNN structure, the PCNN design uses fewer parameters and layers, which minimizes the time required to \\nextract distinctive features. The effectiveness of the technique was evaluated on two datasets (Kaggle DR 2015 \\ncompetition (Dataset 1; 34,984 FIs) and APTOS 2019 (3,662 FIs)), and the results are promising. For the two \\ndatasets mentioned, the proposed technique attained accuracies of 91.78 % and 97.27 % respectively. However, \\none of the studys subsidiary discoveries was that the proposed framework demonstrated stability for both larger \\nand smaller datasets, as well as for balanced and imbalanced datasets. Furthermore, in terms of classifier per-\\nformance metrics, model parameters and layers, and prediction time, the suggested approach outscored existing \\nstate-of-the-art models, which would add significant benefit for the medical practitioners in accurately identi-\\nfying the DR.   \\n\\n1. Introduction \\n\\nDiabetic retinopathy (DR) is a chronic retinal disease that is regarded \\nas the sixth most common cause of blindness worldwide. Its a hidden \\nprogressive chronic disease among the diabetic patients. According to \\nthe 2013 statistics, 382 million people are affected by diabetes-related \\nretinal disease, and by 2025, it is projected to exceed 592 million \\n(Pandey & Sharma, 2018). DR shows no clear early sign of appearance; \\nas the condition degrades, complete blindness is basically the obvious \\nend result. Regular screening can help to identify the DR at an early \\nstage, which can help in arresting any further damage through appro-\\npriate medication. Fundus images (FIs) with high resolution are utilized \\nfor detecting the teensy lesions and grading the severity level. Non- \\nproliferative DR (NPDR) and proliferative DR (PDR) are the two \\n\\nprimary forms of the DR. Again, NPDR can be classified with four \\nseverity levels: No DR, Mild stage, Moderate stage, and Severe stage \\n(Mumtaz et al., 2018). Fig. 1 reveals some common symptoms of the DR \\n(Mumtaz et al., 2018). The small dark reddish dot-like lesion is visible \\nnear the blood vessels terminal point, called a microaneurysm (MA). \\nHypertension and blockage of the retinal veins cause retinal hemorrhage \\n(HM), another DR consequence. Small HMs might look a lot similar to \\nthe MAs at times. Exudates are yellow flicks that filter out the injured \\ncapillaries and are made up of lipids and protein residues. \\n\\nIn its later phases, the DR is difficult to treat. There are only a few \\nmicroaneurysms that appear in the Mild NPDR. In contrast, multiple \\nMAs, hemorrhages, and venous beading occur in the moderate NPDR, \\nleading patients capacity to transfer blood to the retina to be compro-\\nmised. Severe NPDR is defined by the appearance of more than 20 intra- \\n\\n* Corresponding author. \\nE-mail addresses: md.ahsan2@mail.dcu.ie (M. Ahsan), J.Haider@mmu.ac.uk (J. Haider), marcin.kowalski@wat.edu.pl (M. Kowalski).  \\n\\nContents lists available at ScienceDirect \\n\\nExpert Systems With Applications \\n\\njournal homepage: www.elsevier.com/locate/eswa \\n\\nhttps://doi.org/10.1016/j.eswa.2023.119557 \\nReceived 15 February 2022; Received in revised form 2 December 2022; Accepted 12 January 2023   \\n\\nmailto:md.ahsan2@mail.dcu.ie\\nmailto:J.Haider@mmu.ac.uk\\nmailto:marcin.kowalski@wat.edu.pl\\nwww.sciencedirect.com/science/journal/09574174\\nhttps://www.elsevier.com/locate/eswa\\nhttps://doi.org/10.1016/j.eswa.2023.119557\\nhttps://doi.org/10.1016/j.eswa.2023.119557\\nhttps://doi.org/10.1016/j.eswa.2023.119557\\nhttp://crossmark.crossref.org/dialog/?doi=10.1016/j.eswa.2023.119557&domain=pdf\\nhttp://creativecommons.org/licenses/by-nc-nd/4.0/\\nhttp://creativecommons.org/licenses/by-nc-nd/4.0/\\n\\n\\nExpert Systems With Applications 217 (2023) 119557\\n\\n2\\n\\nretinal hemorrhages in each of the four quadrants, visible venous \\nbeading in two or more quadrants, and substantial intraretinal micro-\\nvascular abnormality (IRMA) in one or more quadrants. New blood \\nvessels are formed in the PDR stage, along with the aforementioned \\nanomalies (Chudzik et al., 2018). \\n\\nDR is diagnosed using fundus images. Expert ophthalmologists find \\nexisting lesions on the images based on which they grade the DR level \\nand suggest appropriate treatment accordingly. As the lesions are small \\nand often having an overlapping boundaries between the consecutive \\nDR grades, even the expert ophthalmologists cannot provide consistent \\ndiagnosis for the same fundus images and it is also a time-consuming \\nprocess. Therefore, an urgent need for a computer-aided system has \\nbeen realized by the research community. \\n\\nVarious computer-aided systems have been proposed so far for the \\nDR screening. Ophthalmologists grade the severity level by screening \\nthe lesions present in FIs and providing treatment based on the level. \\nSome lesion segmentation techniques were developed to copy this style \\nto mark out these tiny lesions and assist the ophthalmologists in correct \\ndiagnosis. Image processing techniques were frequently used for seg-\\nmenting lesions of FIs. Using image processing techniques, Mumtaz et al. \\n(2018), showed the automatic identification of one of the red lesions, i. \\ne., hemorrhage, which is one of the most recognizable symptoms of \\nretinal disorders among diabetic patients. Akram et al. (2014), detected \\nthe MA from small patches extracted from the FIs while PCA was used \\nfor dimensionality reduction. Rahim et al. (2016), used fuzzy C-means \\n(FCM) image processing techniques to provide a novel automated \\ndiagnosis of the DR and maculopathy in eye fundus pictures. Kar and \\nMaity (2017), developed a four-part lesion detection technique that \\nincluded extraction of vessels and removal of the optic disc, pre- \\nprocessing, detection of candidate lesion, and post-processing. The \\ndark lesions were separated from the weakly lit retinal backgrounds \\nusing curvelet-based edge enhancement, while the contrast between the \\nbright lesions and the background was improved using a well-designed \\nwideband bandpass filter. Subsequently, the mutual information of the \\nmaximum matched filter response and the maximum Laplacian of \\nGaussian response was maximized together. Finally, morphology-based \\npost-processing was used to exclude the candidate pixels that were \\nincorrectly identified. Umapathy et al. (2019), extracted texture features \\nusing the image processing and classified by Decision Tree (DT) classi-\\nfier. For the second method the authors utilized the transfer learning \\nmethod. As the complex features were extracted using the image pro-\\ncessing technique, the accuracy was not so high. For this, deep learning \\nmodels were also proposed for the lesion segmentation. For the seg-\\nmentation of microaneurysms, Chudzik et al. (2018), presented a patch- \\nbased Convolutional Neural Network (CNN) with batch normalization \\nlayers and a dice loss function Pixel-wise exudate detection with a deep \\nCNN was proposed by Yu et al. (2017). Gondal et al. (2017), presented a \\nweakly-supervised CNN model that highlighted denoting regions of the \\nretinal images. The authors obtained high classification and sensitivity \\nscores. The Mask-RCNN model was proposed to segment small lesions \\n(MA and exudates) by Shenavarmasouleh and Arabnia (2007). The \\n\\nauthors utilized the transfer learning (TL) approach to reuse the pre- \\ntrained model ResNet101s weights and achieved an mAP score of 45 \\n%. Besides segmentation, image-level classification is also popular for \\nthe DR grading. The whole image is classified into its classification \\ngrades based on unique features in the image-level classification. \\n\\nSeveral of the studies utilized traditional machine learning (ML) \\nmethods such as DT, support vector machine (SVM), Random forests \\n(RF), logistic regression (LR), and Gaussian Nave Bayes (GNB). For \\nusing traditional ML-based classification, features were extracted using \\nimage processing techniques later deployed to develop the models. For \\nexample, Lachure et al. (2015), used morphological image processing \\nlike erosion, dilation, opening, closing, etc., to segment MAs and exu-\\ndates. Later the features were fed to the SVM and k-nearest neighbors \\n(KNN) classifiers for grading the FIs. Asha and Karpagavalli (2015), \\ndetected retinal exudates using machine learning techniques where the \\nFIs were segmented using the fuzzy C means algorithm, then exudates \\nfeatures were detected from the Luv color space. The classifiers utilized \\nincluded NB, Multilayer Perceptron (MLP), and Extreme Learning Ma-\\nchine (ELM), with ELM providing the best results. ML techniques for \\nautomatically identifying and categorizing the DR from the retina im-\\nages were studied by Honnungar et al. (2016). The proposed method \\nentailed image preprocessing (Contrast Limited Adaptive Histogram \\nEqualization, CLAHE), feature extraction using the bag of visual words \\nmodel, and image classification into distinct DR phases using a multi- \\nclass classifier (logistic regression, SVM, and RF). Raman et al. applied \\nCLAHE to enhance the images, then Sobel operator and contour with \\ncircular hough transformation for optic disk segmentation, morpholog-\\nical operation for blood vessel segmentation, regions growing for exu-\\ndates segmentation, and a mixture model for microaneurysm \\nsegmentation (Raman et al., 2016). Finally, an artificial neural network \\n(ANN) was used as a classifier. Carrera et al. (2017), utilized image \\nprocessing to isolate blood vessels, microaneurysms, and hard exudates \\nfor extracting features, which were later deployed to the SVM classifier. \\nThey obtained a sensitivity of 95 % and an accuracy of 94 %. Soma-\\nsundaram and Ali (2017), developed a ML bagging ensemble classifier \\n(ML-BEC) and extracted t-distribution Stochastic Neighbor Embedding \\n(t-SNE) features. Ramani et al. (2017), proposed a two-level classifica-\\ntion for the DR grading. Ensemble of Best First Trees (BFTs) was used, \\nwhereas misclassified instances were removed and deployed to second \\nlevel ensemble classifiers with J48 Graft Trees. Using Local Ternary \\nPattern (LTP) and Local Energy-based Shape Histogram, Chetoui et al. \\n(2018), identified texture characteristics (LESH). For classification, SVM \\nwas used with various kernel functions. For feature representation, a \\nhistogram binning method was utilized. They demonstrated that using \\nSVM with an RBF kernel, LESH is the best method, with an accuracy of \\n90 %. ML approaches for segmentation and categorization of the DR \\nwere presented by Ali et al. (2020). They proposed a new regional- \\ngrowing paradigm based on clustering. They used four types of char-\\nacteristics for texture analysis: histogram (H), wavelet (W), co- \\noccurrence matrix (COM), and run-length matrix (RLM). The authors \\nutilized data fusion to create hybrid-feature datasets to increase classi-\\nfication accuracy. To obtain 13 optimal features, they used Fisher, \\ncorrelation-based feature selection, mutual information, and probability \\nof error plus average correlation. Finally, five classifiers were used: SMO \\n(sequential minimum optimization), Lg (logistic), MLP (multilayer \\nperceptron), and SLg (simple logistic). Gayathri et al. (2021), designed a \\nmultipath convolutional neural network (M CNN) for extracting global \\nand local features from fundus images. Then SVM, RF, and J48 classifiers \\nwere used for the final DR grade prediction. The M CNN network ob-\\ntained the best result with the J48 classifier. Mahmoud et al. (2021), \\nintroduced a hybrid inductive ML algorithm (HIMLA) for automatic DR \\ndetection. \\n\\nColor FIs were normalized and a convolutional encoder-decoder was \\nused for segmenting blood vessels. A multiple instance learning tech-\\nnique was utilized for feature extraction and classification. Reddy et al. \\n(2020), experimented with an ensemble learning method with \\n\\nFig. 1. Fundus image with various lesions for DR classification.  \\n\\nMd. Nahiduzzaman et al.                                                                                                                                                                                                                     \\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119557\\n\\n3\\n\\nAdaboost, RF, DT, KNN, and Logistic Regression. The authors used the \\ngrid search technique for hyperparameter tuning. Odeh et al. (2016), \\nproposed an ensemble method using RF for robust and powerful \\nlearning, NN for improving precision, and SVM for accurate, time-saving \\nprediction. For feature selection, the authors used info gain attribute \\nevaluation and wrapper subset evaluation algorithms. \\n\\nOne problem with the traditional ML is that the complex features \\nneed to be extracted first. This manual feature extraction using image \\nprocessing sometimes fail to capture all the complex features necessary \\nfor an accurate classification. Here comes the deep learning (DL) \\napproach, which is used for imaging in a wide range of applications \\nnowadays. DL models were also deployed in the DR identification with \\nsignificant success through accurate extraction of the complex feature \\nusing the convolution layers. A 4  4 kernel-based CNN architecture \\nwith some preprocessing and augmentation methods was proposed by \\nIslam et al. (2018), for detecting the DR where the authors employed L2 \\nregularizer and dropout to eliminate overfitting and achieved 98 % \\nsensitivity and 94 % specificity with a kappa score of 85 %. Zhou et al. \\n(2018), proposed a multitasking deep learning model for the DR \\ngrading. Because of the interrelationship among the DR stages, the au-\\nthors followed the multitasking approach that predicted the labels with \\nboth the classification and regression and got a kappa score of 84 %. A \\nSiamese-like architecture was also proposed for the DR detection by \\nZeng et al. (2019). The model used binocular fundus images as input and \\nwas trained with a transfer learning strategy. An attention-based DL \\nmodel, BiRA-Net was proposed by Zhao et al. (2019). Islam et al. (2020), \\nproposed a VGG16 based transfer learning approach with a color pre-\\nprocessing version. The authors used stratified K-fold cross-validation to \\nreduce the overfitting problem. For a smaller Kaggle dataset, Samanta \\net al. (2020), suggested transfer learning-based DenseNet and attained a \\nkappa score of 0.8836 on the validation set. On the Messidor-1 and \\nAPTOS datasets, Gangwar and Ravi (2021), used a pre-trained model, \\nInception-ResNet-v2, and built a custom layer on top, achieving an ac-\\ncuracy of 72.33 % and 82.18 % respectively. Islam et al. (2021), \\ndeveloped a customized VGG19 model and down sampling technique for \\nDR detection. Majumder and Kehtarnavaz (2021), proposed a multi-\\ntasking deep learning model to detect the five grades of the DR \\ncomposed of one regression model, one classification model, and one \\nregression model for inter-dependency. For the APTOS and EyePACS \\ndatasets, they achieved a kappa score of 90 % and 88 %. Also, an inte-\\ngrated shallow network was proposed by Chen et al. (2020). \\n\\nThough various models have been developed, still further improve-\\nment is required particularly in the case of multiclass classification. \\nSeveral ML models were employed in some research, but in this case, the \\nclassification performance was not satisfactory despite the model \\ncomplexity being lower than the existing DL models. Researchers used \\ndifferent transfer learning (TL) models to achieve higher classification \\nperformance to overcome these shortcomings. However, the TL models \\nhave a vast number of parameters, layers and consume a lot of time for \\ntraining. Therefore, this study proposes a framework that makes a trade- \\noff between the ML and DL models, increasing classification perfor-\\nmance and reducing the vast number of parameters and layers, which \\nreduces the processing time. In this study, the FIs were preprocessed \\nusing CLAHE to highlight the lesions of DR. A lightweight parallel CNN \\nmodel has been developed to extract the most discriminant features, \\nwhich are standardized using a standard scaler. Finally, a single-layer \\nML algorithm model named ELM has been used for classification of \\nthe DR. The proposed framework brings its novelty through a smaller \\nnumber of parameters, layers, and comparatively lower processing time. \\nThe proposed framework also offers versatile capabilities in any domain, \\nfor instance, small or large datasets, balanced or imbalanced datasets, \\nand low-resolution FIs. \\n\\n2. Dataset description \\n\\nIn this study, two prevalent datasets were used: Kaggle DR 2015 \\n\\ncompetition (Dataset 1) and APTOS, 2019 respectively provided by \\nEyePACS and Aravind Eye Hospital via Kaggle (California Healthcare \\nFoundation, 2019; APTOS, 2019). The datasets contained five grades of \\nthe DR to detect with 34,984 FIs in Dataset 1 and 3,662 images in \\nAPTOS, 2019. 80 % of the data was used for training, and the rest was for \\ntesting. During image extraction from the Kaggle DR 2015 dataset, some \\nFIs were lost. As both the datasets were collected from Kaggle compe-\\ntition, their corresponding test images were kept in private. Hence, only \\nthe trained data was used for the DR classification. The trained dataset \\nthen further split into both training and testing set for carried out the \\nclassification task. Table 1 shows the number of FIs per class for both \\ndatasets. Representative samples from each class are demonstrated in \\nFig. 2. \\n\\n3. Proposed framework \\n\\nAn adequate framework was proposed in this study for severity \\ngrading of the DR. The benefits of ML and DL algorithms were merged to \\ndevelop a robust framework with a trade-off between the models pro-\\ncessing performance and classification performance. Fig. 3 exhibits the \\nproposed framework to detect DR from the FIs. First, the FIs were pre-\\nprocessed using CLAHE to highlight the lesions more clearly, then \\nnormalized and finally reshaped. Afterward, a lightweight CNN model \\nwas developed to extract the most discriminant features from the pro-\\ncessed FIs. The extracted features were standardized to be fed into the \\nELM algorithm, which to classify the severity level of the DR. In the \\nsubsequent sections, all components of the framework have been \\nexplained comprehensively. \\n\\n3.1. Pre-processing \\n\\nImage preprocessing is crucial for medical image analysis because \\nthe classification performance varies depending on how well the image \\nhas been preprocessed. CLAHE reveals a favorable result for enhancing \\nimage quality in the case of medical image preprocessing (Nahiduzza-\\nman et al., 2021a,b). Since the datasets contained different quality of \\nimages, hence for improving the quality of low contrast images while \\nfocusing on the lesions of FIs, CLAHE was utilized. The intensification in \\nCLAHE was controlled by clipping the histogram at a user-defined value \\ncalled the clip limit. The clipping level determined the amount of \\ndistortion in the histogram should be eliminated and this defined the \\nlimit of contrast adjustment. In this study, the tile size was (4  4), and \\nthe clip limit was 2.0 while using the color version of the CLAHE. After \\napplying CLAHE, the FIs have been normalized dividing by 255 to make \\neach image range between 0 and 1, which also reduced the complexity \\nof the model. Since the datasets contained diverse FIs, making the FIs \\nwith the same size was an essential step to follow. Hence, the FIs were \\nresized to (124  124) to fit into the CNN model. Fig. 4 shows the effect \\nof CLAHE in the FIs. \\n\\n3.2. Features extraction using parallel convolutional layers \\n\\nOne of the main focuses of this study was to design a CNN that \\nreduced both parameters and layers, which eventually shortened the \\nprocessing time while extracting the most prominent features. The \\n\\nTable 1 \\nThe number of FIs per class for Dataset-1 and APTOS, 2019.  \\n\\nLevel Dataset-1 (Image Ratio) APTOS, 2019 (Image Ratio) \\n\\nNo DR 25,707 (0.73) 1,805 (0.49) \\nMild DR 2,435 (0.07) 370 (0.10) \\nModerate DR 5,268 (0.15) 999 (0.27) \\nSevere DR 869 (0.025) 193 (0.05) \\nPDR 705 (0.02) 295 (0.08) \\nTotal 34,984 3,662  \\n\\nMd. Nahiduzzaman et al.                                                                                                                                                                                                                     \\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119557\\n\\n4\\n\\nnotable features assisted the ELM model in accurately detecting the \\nlevels of DR. Basically, in CNN, the convolutional layer (CL) was posi-\\ntioned sequentially for obtaining the best features. For instance, select-\\ning a small number of CL layers might result in the loss of some \\n\\ndiscriminant features, whereas a large number of CL layers might lead to \\noverfitting the model. Hence, the number of CL layers needed to be \\nchosen adequately to extract the most relevant features. In this study, six \\nCL layers were selected to extract the prominent features while reducing \\n\\nFig. 2. Samples of No DR, Mild, Moderate, Severe, and PDR from Dataset-1 and APTOS, 2019.  \\n\\nFig. 3. A proposed framework to detect the five levels of DR.  \\n\\nFig. 4. Five levels of FIs without preprocessing and preprocessing with CLAHE.  \\n\\nMd. Nahiduzzaman et al.                                                                                                                                                                                                                     \\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119557\\n\\n5\\n\\noverfitting. The lightweight parallax CNN has been shown in Fig. 5. \\nIn the lightweight parallel CNN, four CLs were placed in parallel, \\n\\nwhich resulted in lowering the parameters and processing time. Since \\nthe four CLs were run in parallel, which could be considered as a single \\nCL but performed just like four CLs. The size of each CL was 64. The \\nkernel sizes of the first, second, third, and fourth CLs were 9  9, 7  7, \\n5  5, and 3  3, respectively and the activation function was ReLU. In \\nthis study, the padding size was kept the same in the first four CLs to \\ncheck the border element. As sometimes the border element might hold \\nimportant information in the FIs which were checked using the same \\npadding. Afterwards, the result of these parallel CLs were concatenated \\nand fed into the sequential CNN. The sizes of the last two CLs were 32 \\nand 16, respectively, with a kernel size of 3  3. The padding size in the \\nrest of the CLs was kept valid. Each CL was followed by batch \\nnormalization, activation, and a max-pooling layer. Max-pooling with 2 \\n 2 filters was used to extract the most important regions of the FIs by \\nobtaining the highest value in each region at the CLs. There were two \\nfully connected (FC) layers, and the features were extracted from the last \\nFC layer. Two dropouts were used with a 0.5 probability: one after the \\nlast CL and another after the first FC layer. Dropout was used to reduce \\noverfitting and speed up the training process by randomly skipping 50 % \\nof all nodes. For extracting the features, the CNN model was run for 50 \\nepochs with a batch size 64 while considering the learning rate of 0.001 \\nwith the ADAM optimizer and handling the loss using sparse categorical \\ncross-entropy. A total of 120 features were selected from the last FC \\nlayer by using a trial-and-error process. The summary of the CNN model \\nis shown in Table 2. \\n\\n3.3. Extreme learning machine \\n\\nBefore fitting the features into ELM, features were standardized by \\nsubtracting the mean and scaling to meanvariance. The standard scaler \\nwas employed to regularize the extracted features, which improved the \\nclassification performance of the models (), (Nahiduzzaman et al., \\n2019). The standard score for the sample x has been calculated using Eq. \\n(1) (Farrell and Saloner, 1985). \\n\\ny =\\nx  x\\n\\n (1)  \\n\\nwhere x is the mean of the samples and  is the standard deviation of the \\nsamples. \\n\\nHuang et al. (2006), proposed ELM, a forward feed network-based \\nneural network. The standardized 120 features were classified using a \\nsingle hidden layer. The number of nodes in the hidden layer for Dataset- \\n1 and APTOS, 2019 were 1000 and 200, respectively, which were \\nselected by trial-and-error method. The number of nodes in the input \\nand output layers of the ELM model for both datasets were 120 and 5, \\nrespectively, whereas the ReLU was used as an activation function. Due \\nto the absence of backpropagation, the training time was a thousand \\ntimes faster than the typical NN, resulting in better generalization power \\nand higher classification performance (Huang et al. (2006); Nahi-\\nduzzaman et al., 2021a,b). The parameters from the input to the hidden \\nlayer were calculated randomly, whereas the parameters from the hid-\\nden layer to the output layer were calculated using pseudoinverse. For \\nextracting features using lightweight CNN, the entire trainable param-\\neters for the DR classification are 3, 505,939. For classification using \\nDataset-1 and APTOS, 2019, the complete parameters of the ELM were \\n125,500, and 25,000, resulting in total trainable parameters of 3, 630, \\n939, and 3,530, 939, respectively. \\n\\nFig. 5. The lightweight parallel CNN to extract the features from FIs.  \\n\\nTable 2 \\nSummary of proposed lightweight CNN for feature extraction.  \\n\\nLayer (Type) Output Shape Parameters \\n\\nmodel (Functional) (None, 124, 124, 256) 31, 744 \\nconv5 (Conv2D) (None, 122, 122, 32) 73, 760 \\nbn1 (BatchNormalization) (None, 122, 122, 32) 128 \\nav5 (Activation) (None, 122, 122, 32) 0 \\nmp1 (MaxPooling2D) (None, 61, 61, 32) 0 \\nconv6 (Conv2D) (None, 59, 59, 16) 4, 624 \\nbn2 (BatchNormalization) (None, 59, 59, 16) 64 \\nav2 (Activation) (None, 59, 59, 16) 0 \\nmp2 (MaxPooling2D) (None, 29, 29, 16) 0 \\ndp1 (Dropout) (None, 29, 29, 16) 0 \\nft (Flatten) (None, 13456) 0 \\ndense (Dense) (None, 250) 3, 364, 250 \\nbn4 (BatchNormalization) (None, 250) 1, 000 \\nav4 (Activation) (None, 250) 0 \\ndp2 (Dropout) (None, 250) 0 \\nFeature Extraction (Dense) (None, 120) 30, 120 \\nTotal Parameters 3, 506, 775 \\nTrainable Parameters 3, 505, 939 \\nNon-trainable Parameters 836  \\n\\nMd. Nahiduzzaman et al.                                                                                                                                                                                                                     \\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119557\\n\\n6\\n\\nAlgorithm 1: Extreme Learning Machine  \\n\\nX(n,m) =\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nx(1,1) x(1,2)  x(1,m)\\n\\nx(2,1) x(2,2)  x(1,m)\\n\\nx(3,1) x(3,2)  x(1,m)\\n\\n   \\nx(n,1) x(n,2)  x(n,m)\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nY(n,t) =\\n\\n\\n\\n\\n\\n\\n\\n\\n\\ny(1,1) y(1,2)  y(1,t)\\ny(2,1) y(2,2)  y(1,t)\\ny(3,1) y(3,2)  y(1,t)\\n\\n   \\ny(n,1) y(n,2)  y(n,t)\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n1: Randomly generates the input weight W(m,N) and bias B(1,N) matrix. \\n\\nW(m,N) =\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nw(1,1) w(1,2)  w(1,N)\\n\\nw(2,1) w(2,2)  w(1,N)\\n\\nw(3,1) w(3,2)  w(1,N)\\n\\n   \\nw(m,1) w(m,2)  w(m,N)\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nB(1,N) =\\n[\\n\\nb(1,1) b(1,2)  b(1,N)\\n\\n]\\n\\n2: Determine the output H(n,N) of the hidden layer. \\nH(n,N) = G(X(n,m)W(m,N) + B(1,N))\\n\\nH(n,N) =\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nh(1,1) h(1,2)  h(1,N)\\n\\nh(2,1) h(2,2)  h(1,N)\\n\\nh(3,1) h(3,2)  h(1,N)\\n\\n   \\nh(n,1) h(n,2)  h(n,N)\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n3: Determine the output weight matrix (N,t)\\n\\n(N,t) = H\\n\\n(N,n)T(n,t)\\n\\n4: Make prediction using (N,t)\\n\\n4. Result and discussion \\n\\nSeveral performance metrics, such as accuracy, precision, recall, f1- \\nscore, and Area Under the Curve (AUC) curve, were used to evaluate the \\nperformance of the proposed framework. Equations (2) through Equa-\\ntion (6) can be used to define the metrics (Powers, 2010). \\n\\nAccuracy =\\nTP + TN\\n\\nTP + TN + FP + FN\\n(2)  \\n\\nPrecision =\\nTP\\n\\nTP + FP\\n(3)  \\n\\nRecall =\\nTP\\n\\nTN + FP\\n(4)  \\n\\nF1  Score =\\n2  (Precision  Recall)\\n\\nPrecision + Recall\\n(5)  \\n\\nAUC =\\n1\\n2\\n(\\n\\nTP\\n\\nTP + FN\\n+\\n\\nTN\\n\\nTN + FP\\n) (6)  \\n\\nwhere true positives, true negatives, false positives, and false negatives \\nare symbolized as TP, TN, FP and FN, respectively. True positives indi-\\ncated that the normal patients were correctly detected as normal, true \\nnegatives indicated that the DR affected patients were correctly identi-\\nfied as DR whereas false positives indicated that the normal patients \\nwere wrongly detected as DR and false negatives indicated that the DR \\npatients were wrongly detected as normal. \\n\\nPyCharm Community Edition (2021.2.3) software was used to run all \\nof the codes, which were written in the python programming language. \\nKeras was used to build the CNN model, with TensorFlow as the back-\\nend. The ELM models were trained and tested on a PC with a 64-bit \\nWindows 10 Pro operating system, an Intel (R) Core (TM) i9-11900 \\nCPU @ 2.50 GHz, 32 GB of RAM, and an NVIDIA GeForce, RTX 3090 \\n24 GB GPU. \\n\\nIn this section, the different types of performance were investigated \\nto show the robustness of the proposed framework. A lightweight \\ncustomized CNN has extracted 120 prominent features from the pre-\\nprocessed FIs. These prominent features were further preprocessed and \\nfitted into the ELM model to classify different levels of DR. In abridge-\\nment, the feature deriving capability was incorporated with the ELM. \\nThe proposed combination was examined with two datasets. \\n\\n4.1. Results of Dataset-1 \\n\\nThe ELM model was trained using 27,978 FIs, whereas the numbers \\nof No DR, Mild, Moderate, Severe, and PDR FIs were 20566, 1948, 4214, \\n695, and 564 respectively. The training process required only one iter-\\nation as there was no backpropagation in the ELM. Therefore, the ELM \\ntraining process was faster than the traditional neural network (NN) and \\nthe DL models. Another point that needs to be noted was that to classify \\nthe DR levels correctly, a number of iterations needs to be carried out to \\ntrain the NN and DL models. However, in this study, the proposed ELM \\nachieved a promising result for only one epoch for both the datasets. \\nAfter completing the training, 6,997 FIs (No DR: 5141, Mild: 487, \\nModerate: 1054, Severe: 174, and PDR: 141) were employed for \\nassessing the classification performance of the ELM model. The CM \\nobtained by the ELM for Dataset-1 is shown in Fig. 6. Clearly, in the case \\nmoderate level, misclassified number of images were much higher than \\nthe other levels. \\n\\nThe average precision, recall, f1-score, and accuracy of the ELM for \\ndataset-1 were 0.91, 0.83, 0.87, and 91.78 %, respectively, as shown in \\nTable 3. Furthermore, to demonstrate the superior performance of ELM \\nin this study, five well-known ML algorithms such as SVM, GNB, RF, DT \\nand LR were also employed to obtain the classification results as pre-\\nsented in Tables 35 and Fig. 7. The best classification results were \\nobtained from SVM among these five models. The average precision, \\nrecall, f1-score, and accuracy of the SVM were 0.58, 0.44, 0.49, 75.83 % \\nrespectively which were also quite lower than ELM. In fact, SVM pro-\\nduced good results during the binary classification whereas NN models \\nshowed good results for multiclass classifications (Nahiduzzaman et al., \\n2019). As ELM is like traditional NN except the back-propagation al-\\ngorithm and for that reason ELM is faster and the rate of learning and \\ngeneralization are more effective. This provides promising results in the \\ncase of multiclass classifications (Afza et al., 2021; Alenezi et al., 2023). \\n\\nThe average AUC of the ELM for the Dataset-1 was 95.08 %, whereas \\nthe class-wise AUCs of the ELM are demonstrated in Fig. 7. It was \\nobserved that each class contributed almost equally to the final classi-\\nfication result (AUC values for all classes higher than 92 %). It could be \\nconcluded that though the class distribution was imbalanced, the pro-\\nposed framework showed its consistency in detecting every class of DR. \\n\\nFig. 6. Confusion Matrix (CM) of ELM for Dataset-1.  \\n\\nMd. Nahiduzzaman et al.                                                                                                                                                                                                                     \\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119557\\n\\n7\\n\\n4.2. Results of APTOS, 2019 Dataset \\n\\nIn the previous section, the proposed framework revealed promising \\nresults for the Dataset-1, which contained a total of 34,984 FIs. Since the \\nDL models worked well for larger datasets, the proposed framework \\nvalidated this by showing favorable classification performance. In this \\nstudy, it was also checked whether the proposed framework could \\nachieve promising classification performance with a small dataset. \\nHence, a small dataset, APTOS, 2019 was used that contained FIs, almost \\nten times less than the Dataset-1. \\n\\nAmong the total 3,662 FIs, 2,929 FIs were used for training the ELM \\n\\nand other five ML models, whereas the numbers of No DR, Mild, Mod-\\nerate, Severe, and PDR were 1444, 296, 799, 154, and 236, respectively. \\nFor evaluating the ELM classification performance, a CM was developed \\nusing 733 FIs (No DR: 361, Mild: 74, Moderate: 200, Severe: 39, and \\nPDR: 59). The level-wise precision, f1-score and recall shown in \\nTables 68 demonstrated that the ELM model performed well in the case \\nof the imbalance or smaller dataset. The best accuracy (97.27 %) was \\nachieved by ELM model for the APTOS, 2019 dataset with a recall of 95 \\n\\nTable 3 \\nClassification performance comparison by Precision for Dataset-1.  \\n\\nDR Level Precision \\n\\nELM SVM GNB RF DT LR \\n\\nNo DR  0.93  0.82  0.86  0.82  0.82  0.82 \\nMild  0.87  0.42  0.24  0.42  0.28  0.41 \\nModerate  0.87  0.48  0.40  0.47  0.44  0.47 \\nSevere  0.95  0.56  0.47  0.55  0.46  0.52 \\nPDR  0.94  0.61  0.56  0.64  0.61  0.65 \\nAverage  0.91  0.58  0.50  0.58  0.52  0.57  \\n\\nTable 4 \\nClassification performance comparison by F-1Precision for Dataset-1.  \\n\\nDR Level F1-Score \\n\\nELM SVM GNB RF DT LR \\n\\nNo DR  0.95  0.86  0.82  0.86  0.85  0.86 \\nMild  0.77  0.31  0.28  0.30  0.25  0.31 \\nModerate  0.82  0.43  0.45  0.43  0.41  0.43 \\nSevere  0.89  0.39  0.40  0.39  0.36  0.39 \\nPDR  0.91  0.46  0.46  0.47  0.44  0.49 \\nAverage  0.87  0.49  0.48  0.49  0.46  0.49  \\n\\nTable 5 \\nClassification performance comparison by Recall for Dataset-1.  \\n\\nDR Level Recall \\n\\nELM SVM GNB RF DT LR \\n\\nNo DR  0.97  0.91  0.78  0.90  0.87  0.90 \\nMild  0.70  0.24  0.33  0.24  0.23  0.25 \\nModerate  0.78  0.39  0.52  0.40  0.39  0.39 \\nSevere  0.84  0.30  0.35  0.30  0.29  0.31 \\nPDR  0.89  0.37  0.39  0.37  0.34  0.39 \\nAverage  0.83  0.44  0.48  0.44  0.43  0.45  \\n\\nFig. 7. Accuracies of employed ML techniques for Dataset-1.  \\n\\nTable 6 \\nClassification performance comparison by Precision for APTOS, 2019 dataset.  \\n\\nDR Level Precision \\n\\nELM SVM GNB RF DT LR \\n\\nNo DR  1.0  0.96  0.96  0.97  0.96  0.97 \\nMild  0.99  0.74  0.74  0.79  0.74  0.75 \\nModerate  0.94  0.8  0.8  0.79  0.79  0.8 \\nSevere  0.9  0.75  0.75  0.71  0.69  0.71 \\nPDR  0.96  0.73  0.73  0.68  0.57  0.72 \\nAverage  0.96  0.8  0.8  0.79  0.75  0.79  \\n\\nTable 7 \\nClassification performance comparison by F-1Precision for APTOS, 2019 \\ndataset.  \\n\\nDR Level F1-Score \\n\\nELM SVM GNB RF DT LR \\n\\nNo DR  0.99  0.97  0.97  0.98  0.97  0.98 \\nMild  0.97  0.72  0.72  0.74  0.7  0.73 \\nModerate  0.96  0.84  0.84  0.83  0.81  0.83 \\nSevere  0.92  0.68  0.68  0.63  0.59  0.63 \\nPDR  0.92  0.62  0.62  0.6  0.58  0.63 \\nAverage  0.95  0.77  0.77  0.76  0.73  0.76  \\n\\nTable 8 \\nClassification performance comparison by Recall for APTOS, 2019 dataset.  \\n\\nDR Level Recall \\n\\nELM SVM GNB RF DT LR \\n\\nNo DR  0.99  0.98  0.98  0.99  0.97  0.98 \\nMild  0.96  0.7  0.7  0.7  0.66  0.7 \\nModerate  0.97  0.88  0.88  0.87  0.83  0.88 \\nSevere  0.95  0.62  0.62  0.56  0.51  0.56 \\nPDR  0.88  0.54  0.54  0.54  0.59  0.56 \\nAverage  0.95  0.74  0.74  0.73  0.72  0.74  \\n\\nFig. 8. Receiver Operating Characteristic (ROC) curve of ELM for Dataset-1.  \\n\\nMd. Nahiduzzaman et al.                                                                                                                                                                                                                     \\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119557\\n\\n8\\n\\n% and a precision of 96 % (Fig. 10). Whereas the best accuracy obtained \\nby SVM (87.04 %) among other models was almost 10 % lower than the \\nELM model. In the case of medical image analysis, the recall must be \\nmaximized i.e., the affected patient should be identified accurately. \\n\\nThe class-wise ROC is shown in Fig. 9 to assess the ELMs ability to \\ndistinguish between the DR levels. The estimated ROC of the ELM model \\nfor the APTOS, 2019 dataset was 98.87 %. The ROC of each class was \\nquite good even if the dataset was unbalanced, demonstrating the \\nmodels robustness (See Fig. 11). \\n\\nA graphical illustration is shown in Fig. 10 to make the results more \\nlegible and comparable between the two datasets. The suggested \\nframework is compatible in any setting, such as smaller (APTOS, 2019) \\nor larger (Dataset 1) datasets. This was accomplished by employing \\nCLAHE to highlight the lesions. Hence, it is easy for the parallel CNN \\nmodel to extract the most discriminating features and the ELM based on \\ndeep learning mechanism can accurately detected the DR levels. The \\nframework was also straightforward to use as it performed well even \\nwhen dealing with an unbalanced dataset, which is common with real- \\nworld medical data (See Fig. 12). \\n\\n4.3. Comparison with previous works \\n\\nTables 9 and 10 show the classification performance compared with \\nprevious state-of-the-art (SOTA) models for both the datasets. For \\nDataset-1, the proposed framework (PF) was compared with two studies. \\nPratt et al. processed the FIs using color normalization, and developed a \\nCNN with 10 CLs and two FC layers (Pratt et al., 2016). The number of \\nfilters in 10 CLs were 32, 32, 64, 64, 128, 128, 256, 256, 512, and 512, \\nrespectively, and both the FC layers had 1,024 nodes. Apart from these, \\nthey used 5,000 FIs (the shape of the FIs were 512  512) for testing and \\nachieved an overall accuracy and sensitivity (recall) of 75 % and 30 %, \\nrespectively. In contrast, Qummar et al. (2019), used five TL models: \\nResnet50, Inceptionv3, Xception, Dense121, and Dense169 for classi-\\nfying DR from the FIs. In addition, they ensemble these five TL models \\nfor final prediction. They also resized the FIs into 512  512 and ach-\\nieved an accuracy, recall, precision, and f1-score of 80.8 %, 51.5 %, \\n63.85 %, and 53.74 %, respectively, while testing the model on 5,608 FIs \\nand performing up and down sampling. The proposed PCNN-ELM has \\nonly 8 CLs with 3.6 million parameters, which was quite fewer than the \\nother two works. Again, the contrast of the FIs were enhanced using \\nCLAHE, and for that reason, the lesion was highlighted as shown in \\nFig. 4. Finally, the FIs were resized into 124  124 and the framework \\nhas been tested using 5608 FIs and achieved an accuracy of 91.88 %, \\nwhich is 10 % higher than the previous study, and a recall of 83 %, \\nwhich is almost 30 % higher than the previous study. The prior two \\nresearch were significantly affected by the imbalanced dataset. No DR \\n\\nFig. 9. Confusion matrix of ELM for APTOS, 2019 dataset.  \\n\\nFig. 10. Accuracies of employed ML techniques for Dataset-1.  \\n\\nFig. 11. ROC matrix of ELM for APTOS, 2019 dataset.  \\n\\nFig. 12. Graphical illustration of the classification performance of pro-\\nposed framework. \\n\\nMd. Nahiduzzaman et al.                                                                                                                                                                                                                     \\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119557\\n\\n9\\n\\nlevel highly dominated the final classification result and showed a \\npreliminary result in the case of other classes as seen in Table 9. On the \\ncontrary, each class almost equally contributed to the final classification \\nresult, which validated the handling capability of the unbalanced \\ndataset of the proposed framework. Pratt et al. (2016), showed that their \\nproposed methodology required 0.04 s to classify-one FI. In contrast, the \\nproposed framework required only 0.0009987 s to test the total of 5608 \\nFIs, whereas 2 s were required for classifying one FI. These two studies \\nreshaped the FIs by 512  512, whereas this study used 124  124 but \\nstill ensuring a promising result with a calculated AUC of 92.10 % \\n(Qummar et al. achieved an average AUC of 86.8 %) that showed the \\nrobustness of the proposed model. \\n\\nSeveral researchers used the APTOS, 2019 dataset to detect the levels \\nof DR. Table 10 shows the average classification performance of the \\nSOTA models for the APTOS, 2019 dataset as class wise results were not \\navailable. Sikder et al. achieved the highest classification accuracy of \\n94.20 %, and the highest AUC of 97.90 % was achieved by Alyoubi et al. \\n(2021), from the SOTA models (Sikder et al., 2021). In contrast, the \\nproposed framework outperformed all the SOTA models with an \\n\\naccuracy and an AUC of 97.27 % and 98.87 %, respectively. Table 11 \\nshows the comparison of the proposed frameworks performance with \\nthe previous works. From the table, most of the SOTA models employed \\ntransfer learning (TL) models to extract the features and classify the DR \\nfrom the FIs. The TL models have many layers and parameters; for \\ninstance, the VGG16 model has almost 138.3 million parameters, and \\nDenseNet-169 has 169 layers, which are too many. They also required \\nhigh-resolution FIs (512  512, 380  380, 224  224, etc.) to distin-\\nguish the DR levels correctly. \\n\\nIn contrast, the proposed framework only employed six CLs, where \\nfour of them were run in parallel, which was considered a single CL. \\nHence, there were total eight layers, including four CLs, two FC layers, \\nand three from the ELM. The total parameters of the proposed frame-\\nwork are almost 3.6 million, including both the parallel CNN and ELM \\nmodel parameters that validated the lightweight capability of the CNN. \\nThis framework required an image size of 124  124, which was another \\nobjective of this study to detect DR levels using low-resolution FIs. \\nTable 11 shows that the proposed framework has the lowest number of \\nparameters and layers, which could be the main reason for shorter \\nprocessing time. \\n\\nFrom the above comparison, it was concluded that the proposed \\nframework could classify the levels of DR accurately with lower pa-\\nrameters, layers, low-resolution FIs, and relatively shorter time. It was \\nalso revealed that the framework is capable of adapting to any dataset \\nenvironment, small or large, balanced or imbalanced and that classi-\\nfying a FI requires only 2 s seconds, allowing for real-time patient \\nfeedback. \\n\\nIn fact, the diabetic retinopathy datasets used in this study were \\nhighly imbalanced particularly for the multiclass classification due to \\nthe unavailability of the PDR images. Since in real life consideration, the \\nnumber of PDR patients are not many, and most datasets contain small \\nportion of PDR images with respect to the other classes. Since the dataset \\nwas fairly imbalanced, some researchers used data augmentation and \\nother techniques (adding weight to the poorly detected class, up sam-\\npling, down sampling) to improve the classification performance (Pratt \\net al., 2016; Dondeti. al., 2020). However, the results were not better \\nthan the findings obtained by the proposed framework. Using data \\naugmentation, more data can be produced, but it needs additional time \\nfor processing. Most studies, while using these two imbalanced datasets, \\nreported results without any data balancing (Nahiduzzaman et al., \\n2021a,b; Pratt et al., 2016; Dondeti. al., 2020; Bodapati et al., 2020; \\nBodapati et al., 2021). Apart from these, the results presented for \\nDataset-1 in Table 4 to Table 6, it was observed that the precision, recall \\nand f1-score of PDR images were 0.94, 0.91 and 0.89 respectively which \\nwere quite satisfactory. Though there were a smaller number of PDR \\nimages, but the classification results were similar to the normal images \\n(precision, f1-score and recall of No DR images are 0.93, 0.97 and 0.95 \\nrespectively). Again, similar observations were made for the APTOS, \\n2019 dataset. In addition, from Fig. 8, it was found that the class wise \\nROC of PDR was 97.73 % whereases for No DR it was 94.51 % in the case \\nof Dataset-1. Therefore, it can be concluded that without implementing \\nany data augmentation technique, the proposed CNN-ELM model \\ndetected the DR accurately without producing any biased results due to \\n\\nTable 9 \\nClass-wise classification performance of the proposed framework (PF) compared with the previous studies for the Dataset-1.  \\n\\nLevel/ \\nRef. No. \\n\\nPrecision Recall F1-Score AUC \\n\\n(Pratt \\net al., \\n2016) \\n\\n(Qummar \\net al., 2019) \\n\\nPF (Pratt \\net al., \\n2016) \\n\\n(Qummar \\net al., 2019) \\n\\nPF (Pratt \\net al., \\n2016) \\n\\n(Qummar \\net al., 2019) \\n\\nPF (Pratt \\net al., \\n2016) \\n\\n(Qummar \\net al., 2019) \\n\\nPF \\n\\nNo DR  0.78  0.84  0.93  0.95  0.97  0.97  0.85  0.90  0.95   0.85  0.94 \\nMild  0.00  0.51  0.89  0.00  0.80  0.68  0.00  0.15  0.78   0.71  0.92 \\nModerate  0.23  0.65  0.87  0.23  0.41  0.78  0.29  0.50  0.82   0.85  0.95 \\nSevere  0.78  0.48  0.92  0.78  0.51  0.83  0.10  0.49  0.88   0.96  0.96 \\nPDR  0.44  0.69  0.93  0.44  0.56  0.88  0.37  0.62  0.90   0.97  0.97  \\n\\nTable 10 \\nClassification performance compared with SOTA models for the APTOS, 2019.  \\n\\nRef. No. Precision (%) Recall (%) Accuracy (%) AUC (%) \\n\\n(Dondeti et al., 2020)  76.00  77.00  77.90   \\n(Bodapati et al., 2020)  80.00  81.00  81.70   \\n(Liu et al., 2020)  91.37    86.34   \\n(Kassani et al., 2019)  87.00  88.24  83.09  91.80 \\n(Bodapati et al., 2021)  82.00  83.00  82.54  79.00 \\n(Sikder et al., 2021)  94.34  92.69  94.20   \\n(Alyoubi et al., 2021)  89.00    89.00  97.90 \\nProposed Framework  96.00  95.00  97.27  98.87  \\n\\nTable 11 \\nSimplicity of the proposed framework compared with SOTA models.  \\n\\nModel Name [Ref. No.] No. of \\nLayers \\n\\nNo. of Parameters \\n(million) \\n\\nResNet 50 (Qummar et al., 2019; Kassani et al., \\n2019) \\n\\n50  25.6 \\n\\nInception-V3 (Qummar et al., 2019; Kassani \\net al., 2019) \\n\\n48  23.8 \\n\\nXception (Qummar et al., 2019; Bodapati et al., \\n2020; Liu et al., 2020; Kassani et al., 2019; \\nBodapati et al., 2021) \\n\\n71  22.9 \\n\\nDense 121 (Qummar et al., 2019) 121  8.0 \\nDense 169 (Qummar et al., 2019) 169  14.3 \\nVGG16 (Bodapati et al., 2020; Bodapati et al., \\n\\n2021) \\n16  138.3 \\n\\nNasNet-Large (Bodapati et al., 2020; Liu et al., \\n2020) \\n\\n  88.9 \\n\\nInception Resnet V2 (Bodapati et al., 2020; Liu \\net al., 2020) \\n\\n164  55.8 \\n\\nEfficientNetB4 (Liu et al., 2020)   19.4 \\nEfficientNetB5 (Liu et al., 2020)   30.5 \\nCNN512 (Alyoubi et al., 2021) 9  8.2 \\nProposed Framework 8  3.6  \\n\\nMd. Nahiduzzaman et al.                                                                                                                                                                                                                     \\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119557\\n\\n10\\n\\nthe imbalanced datasets. The proposed framework achieved a promising \\noutcome based on the performance metrics considered in this study and \\neliminated additional time required for data augmentation. \\n\\n5. Conclusion \\n\\nThis study proposed a novel framework to enable fast and accurate \\ndetection of the levels of DR from the FIs, which can aid diabetic patients \\nin preventing or delaying vision loss. CLAHE was adopted to make the \\nlesson clear so that a CNN model can easily extract the most discrimi-\\nnating features. 120 features were extracted using a lightweight parallel \\nCNN to reduce processing time and complexity. Finally, these features \\nwere standardized and fit into the ELM model to adequately distinguish \\nthe different levels of the DR. The proposed framework exhibited a \\npromising result in the cases of 34,984 (Dataset-1) and 3,662 (APTOS, \\n2019) FI datasets with not only higher classification performance but \\nalso lowering the parameters, layers, and processing time significantly. \\nThe framework also outperformed the existing SOTA models for both the \\ndatasets. The proposed model can accurately detect the severity degree \\nof the DR earlier on, hence reducing vision loss of the patients and saving \\nvaluable time of the medical practitioners. \\n\\nCRediT authorship contribution statement \\n\\nMd. Nahiduzzaman: Data curation, Conceptualization, Investiga-\\ntion, Methodology, Validation, Formal analysis, Writing  original draft. \\nMd. Robiul Islam: Conceptualization, Investigation, Methodology, \\nValidation, Formal analysis, Data curation, Writing  original draft. Md. \\nOmaer Faruq Goni: Conceptualization, Methodology, Validation, \\nFormal analysis, Data curation, Writing  original draft, Writing  re-\\nview & editing. Md. Shamim Anower: Conceptualization, Methodol-\\nogy, Validation, Formal analysis, Investigation, Writing  review & \\nediting, Supervision. Mominul Ahsan: Methodology, Visualization, \\nConceptualization, Formal analysis, Writing  review & editing, Super-\\nvision. Julfikar Haider: Visualization, Formal analysis, Conceptuali-\\nzation, Methodology, Validation, Writing  review & editing, \\nSupervision. Marcin Kowalski: Conceptualization, Methodology, \\nFormal analysis, Writing  review & editing, Supervision. \\n\\nDeclaration of Competing Interest \\n\\nThe authors declare that they have no known competing financial \\ninterests or personal relationships that could have appeared to influence \\nthe work reported in this paper. \\n\\nData availability \\n\\nThe authors do not have permission to share data. \\n\\nReferences \\n\\nAfza, F., Sharif, M., Khan, M. A., Tariq, U., Yong, H. S., & Cha, J. (2021). Multiclass skin \\nlesion classification using hybrid deep features selection and extreme learning \\nmachine. Sensors, 22(3), 799. \\n\\nAkram, M. U., Khalid, S., Tariq, A., Khan, S. A., & Azam, F. (2014). Detection and \\nclassification of retinal lesions for grading of diabetic retinopathy. Computers in \\nBiology and Medicine, 45, 161171. \\n\\nAli, A., Qadri, S., Mashwani, W. K., Kumam, W., Kumam, P., Naeem, S.,  Anam, S. \\n(2020). Machine learning based automated segmentation and hybrid feature analysis \\nfor diabetic retinopathy classification using fundus image. Entropy, 22(5), 567. \\n\\nAlenezi, F., Armghan, A., & Polat, K. (2023). Wavelet transform based deep residual \\nneural network and ReLU based Extreme Learning Machine for skin lesion \\nclassification. Expert Systems with Applications, 213, Article 119064. \\n\\nAlyoubi, W. L., Abulkhair, M. F., & Shalash, W. M. (2021). Diabetic retinopathy fundus \\nimage classification and lesions localization system using deep learning. Sensors, 21 \\n(11), 3704. \\n\\nAsha, P. and Karpagavalli, S. Diabetic retinal exudates detection using extreme learning \\nmachine, in Emerging ICT for Bridging the Future- Proceedings of the 49th Annual \\nConvention of the Computer Society of India CSI Volume 2. Springer, 2015, pp. \\n573578. \\n\\nBodapati, J. D., Naralasetti, V., Shareef, S. N., Hakak, S., Bilal, M., Maddikunta, P. K. R., \\n& Jo, O. (2020). Blended multi-modal deep convnet features for diabetic retinopathy \\nseverity prediction. Electronics, 9(6), 914. \\n\\nBodapati, J. D., Shaik, N. S., & Naralasetti, V. (2021). Composite deep neural network \\nwith gated-attention mechanism for diabetic retinopathy severity classification. \\nJournal of Ambient Intelligence and Humanized Computing, 115. \\n\\nChudzik, P., Majumdar, S., Caliva, F., Al-Diri, B., & Hunter, A. (2018). Microaneurysm \\ndetection using fully convolutional neural networks. Computer methods and programs \\nin biomedicine, 158, 185192. \\n\\nChetoui, M., Akhloufi, M. A., & Kardouchi, M. (2018). Diabetic retinopathy detection \\nusing machine learning and texture features. In In 2018 IEEE Canadian Conference on \\nElectrical & Computer Engineering (CCECE) (pp. 14). IEEE.  \\n\\nChen, W., Yang, B., Li, J., and Wang, J., An approach to detecting diabetic retinopathy \\nbased on integrated shallow convolutional neural networks, IEEE Access, vol. 8, pp. \\n178 552178 562, 2020. \\n\\nCarrera, E. V., Gonzalez, A. and Carrera, R. Automated detection of diabetic retinopathy \\nusing SVM, in 2017 IEEE XXIV international conference on electronics, electrical \\nengineering and computing (INTERCON). IEEE, 2017, pp. 14. \\n\\nDondeti, V., Bodapati, J. D., Shareef, S. N., & Veeranjaneyulu, N. (2020). Deep \\nconvolution features in non-linear embedding space for fundus image classification. \\nRev. dIntelligence Artif., 34(3), 307313. \\n\\n[dataset 1] California Healthcare Foundation, Diabetic retinopathy detection, http \\ns://www.kaggle.com/c/diabetic-retinopathy-detection/data, 2015, [accessed on 1- \\nFebruary-2022]. \\n\\n[dataset 2] Asia Pacific Tele-Ophthalmology Society (APTOS), Aptos 2019 blindness \\ndetection, https://www.kaggle.com/c/aptos2019-blindness-detection/data, 2019, \\n[Accessed: 1-February- 2022]. \\n\\nFarrell, J., & Saloner, G. (1985). Standardization, compatibility, and innovation. the \\nRAND Journal of Economics, 7083. \\n\\nGangwar, A. K., & Ravi, V. (2021). Diabetic retinopathy detection using transfer learning \\nand deep learning. In Evolution in Computational Intelligence (pp. 679689). Springer.  \\n\\nGayathri, S., Gopi, V. P., & Palanisamy, P. (2021). Diabetic retinopathy classification \\nbased on multipath cnn and machine learning classifiers. Physical and Engineering \\nSciences in Medicine, 115. \\n\\nGondal, W. M., Kohler, J. M., Grzeszick, R., Fink, G. A. and Hirsch, M. Weakly- \\nsupervised localization of diabetic retinopathy lesions in retinal fundus images, in \\n2017 IEEE international conference on image processeing (ICIP). IEEE, 2017, pp. \\n20692073. \\n\\nHuang, G.-B., Zhu, Q.-Y., & Siew, C.-K. (2006). Extreme learning machine: Theory and \\napplications. Neurocomputing, 70(13), 489501. \\n\\nHonnungar, S., Mehra, S. and Joseph, S. Diabetic retinopathy identification and severity \\nclassification, Fall 2016, 2016. \\n\\nIslam, M. R., M. A. M. Hasan, and Sayeed, A. Transfer learning based diabetic \\nretinopathy detection with a novel preprocessed layer, in 2020 IEEE Region 10 \\nSymposium (TENSYMP). IEEE, 2020, pp. 888891. \\n\\nIslam, M. R., Hasan, M. N., and Nahiduzzaman, M., Severity grading of diabetic \\nretinopathy using deep convolutional neural network. International Journal of \\nInnovative Science and Research Technology, vol. 6 no. 1, pp. 13951401. \\n\\nIslam, S. M. S., Hasan, M. M. and Abdullah, S. Deep learning based early detection and \\ngrading of diabetic retinopathy using retinal fundus images, arXiv preprint arXiv: \\n1812.10595, 2018. \\n\\nKassani, S. H., Kassani, P. H., Khazaeinezhad, R., Wesolowski, M. J., Schneider, K. A. and \\nDeters, R. Diabetic retinopathy classification using a modified xception \\narchitecture, in 2019 IEEE International Symposium on Signal Processing and \\nInformation Technology (ISSPIT). IEEE, 2019, pp. 16. \\n\\nKar, S. S., & Maity, S. P. (2017). Automatic detection of retinal lesions for screening of \\ndiabetic retinopathy. IEEE Transactions on Biomedical Engineering, 65(3), 608618. \\n\\nLiu, H., Yue, K., Cheng, S., Pan, C., Sun, J., & Li, W. (2020). Hybrid model structure for \\ndiabetic retinopathy classification. Journal of Healthcare Engineering, 2020. \\n\\nLachure, J., Deorankar, A., Lachure, S., Gupta, S. and Jadhav, R. Diabetic retinopathy \\nusing morphological operations and machine learning, in 2015 IEEE international \\nadvance computing conference (IACC). IEEE, 2015, pp. 617622. \\n\\nMajumder, S. and Kehtarnavaz, N., Multitasking deep learning model for detection of \\nfive stages of diabetic retinopathy, arXiv preprint arXiv:2103.04207, 2021. \\n\\nMahmoud, M. H., Alamery, S., Fouad, H., Altinawi, A., & Youssef, A. E. (2021). An \\nautomatic detection system of diabetic retinopathy using a hybrid inductive machine \\nlearning algorithm. Personal and Ubiquitous Computing, 115. \\n\\nMumtaz, R., Hussain, M., Sarwar, S., Khan, K., Mumtaz, S., & Mumtaz, M. (2018). \\nAutomatic detection of retinal hemorrhages by exploiting image processing \\ntechniques for screening retinal diseases in diabetic patients. International Journal of \\nDiabetes in Developing Countries, 38(1), 8087. \\n\\nNahiduzzaman, M., Islam, M. R., Islam, S. R., Goni, M. O. F. Anower, M. S., and Kwak, K. \\nS. Hybrid cnn-svd based prominent feature extraction and selection for grading \\ndiabetic retinopathy using extreme learning machine algorithm, IEEE Access, vol. 9, \\npp. 152 261152 274, 2021. \\n\\nNahiduzzaman, M., Nayeem, M. J., Ahmed, M. T. and Zaman, M. S. U. Prediction of \\nheart disease using multi-layer perceptron neural network and support vector \\nmachine, in 2019 4th International conference on electrical information and \\ncommunication technology (EICT). IEEE, 2019, pp. 16. \\n\\nNahiduzzaman, M., Goni, M. O. F., Anower, M. S., Islam, M. R., Ahsan, M., Haider, J., \\nGurusamy, S., Hassan, R. and Islam, M. R., A novel method for multivariant \\npneumonia classification based on hybrid CNN-PCA based feature extraction using \\nextreme learning machine with CXR images, IEEE Access, vol. 9, pp. 147 512147 \\n526, 2021. \\n\\nOdeh, I., Alkasassbeh, M. and Alauthman, M., Diabetic retinopathy detection using \\nensemble machine learning, arXiv preprint arXiv:2106.12545, 2021. \\n\\nMd. Nahiduzzaman et al.                                                                                                                                                                                                                     \\n\\nhttp://refhub.elsevier.com/S0957-4174(23)00058-1/h0005\\nhttp://refhub.elsevier.com/S0957-4174(23)00058-1/h0005\\nhttp://refhub.elsevier.com/S0957-4174(23)00058-1/h0005\\nhttp://refhub.elsevier.com/S0957-4174(23)00058-1/h0010\\nhttp://refhub.elsevier.com/S0957-4174(23)00058-1/h0010\\nhttp://refhub.elsevier.com/S0957-4174(23)00058-1/h0010\\nhttp://refhub.elsevier.com/S0957-4174(23)00058-1/h0015\\nhttp://refhub.elsevier.com/S0957-4174(23)00058-1/h0015\\nhttp://refhub.elsevier.com/S0957-4174(23)00058-1/h0015\\nhttp://refhub.elsevier.com/S0957-4174(23)00058-1/h0020\\nhttp://refhub.elsevier.com/S0957-4174(23)00058-1/h0020\\nhttp://refhub.elsevier.com/S0957-4174(23)00058-1/h0020\\nhttp://refhub.elsevier.com/S0957-4174(23)00058-1/h0025\\nhttp://refhub.elsevier.com/S0957-4174(23)00058-1/h0025\\nhttp://refhub.elsevier.com/S0957-4174(23)00058-1/h0025\\nhttp://refhub.elsevier.com/S0957-4174(23)00058-1/h0035\\nhttp://refhub.elsevier.com/S0957-4174(23)00058-1/h0035\\nhttp://refhub.elsevier.com/S0957-4174(23)00058-1/h0035\\nhttp://refhub.elsevier.com/S0957-4174(23)00058-1/h0040\\nhttp://refhub.elsevier.com/S0957-4174(23)00058-1/h0040\\nhttp://refhub.elsevier.com/S0957-4174(23)00058-1/h0040\\nhttp://refhub.elsevier.com/S0957-4174(23)00058-1/h0045\\nhttp://refhub.elsevier.com/S0957-4174(23)00058-1/h0045\\nhttp://refhub.elsevier.com/S0957-4174(23)00058-1/h0045\\nhttp://refhub.elsevier.com/S0957-4174(23)00058-1/h0050\\nhttp://refhub.elsevier.com/S0957-4174(23)00058-1/h0050\\nhttp://refhub.elsevier.com/S0957-4174(23)00058-1/h0050\\nhttp://refhub.elsevier.com/S0957-4174(23)00058-1/h0065\\nhttp://refhub.elsevier.com/S0957-4174(23)00058-1/h0065\\nhttp://refhub.elsevier.com/S0957-4174(23)00058-1/h0065\\nhttps://www.kaggle.com/c/diabetic-retinopathy-detection/data\\nhttps://www.kaggle.com/c/diabetic-retinopathy-detection/data\\nhttps://www.kaggle.com/c/aptos2019-blindness-detection/data\\nhttp://refhub.elsevier.com/S0957-4174(23)00058-1/h0080\\nhttp://refhub.elsevier.com/S0957-4174(23)00058-1/h0080\\nhttp://refhub.elsevier.com/S0957-4174(23)00058-1/h0085\\nhttp://refhub.elsevier.com/S0957-4174(23)00058-1/h0085\\nhttp://refhub.elsevier.com/S0957-4174(23)00058-1/h0090\\nhttp://refhub.elsevier.com/S0957-4174(23)00058-1/h0090\\nhttp://refhub.elsevier.com/S0957-4174(23)00058-1/h0090\\nhttp://refhub.elsevier.com/S0957-4174(23)00058-1/h0100\\nhttp://refhub.elsevier.com/S0957-4174(23)00058-1/h0100\\nhttp://refhub.elsevier.com/S0957-4174(23)00058-1/h0130\\nhttp://refhub.elsevier.com/S0957-4174(23)00058-1/h0130\\nhttp://refhub.elsevier.com/S0957-4174(23)00058-1/h0135\\nhttp://refhub.elsevier.com/S0957-4174(23)00058-1/h0135\\nhttp://refhub.elsevier.com/S0957-4174(23)00058-1/h0150\\nhttp://refhub.elsevier.com/S0957-4174(23)00058-1/h0150\\nhttp://refhub.elsevier.com/S0957-4174(23)00058-1/h0150\\nhttp://refhub.elsevier.com/S0957-4174(23)00058-1/h0155\\nhttp://refhub.elsevier.com/S0957-4174(23)00058-1/h0155\\nhttp://refhub.elsevier.com/S0957-4174(23)00058-1/h0155\\nhttp://refhub.elsevier.com/S0957-4174(23)00058-1/h0155\\n\\n\\nExpert Systems With Applications 217 (2023) 119557\\n\\n11\\n\\nPandey, S. K., & Sharma, V. (2018). World diabetes day 2018: Battling the emerging \\nepidemic of diabetic retinopathy. Indian Journal of Ophthalmology, 66(11), 1652. \\n\\nPowers, D. M. Evaluation: from precision, recall and f-measure to roc, informedness, \\nmarkedness and correlation, arXiv preprint arXiv:2010.16061, 2020. \\n\\nPratt, H., Coenen, F., Broadbent, D. M., Harding, S. P., & Zheng, Y. (2016). Convolutional \\nneural networks for diabetic retinopathy. Procedia Computer Science, 90, 200205. \\n\\nQummar, S., Khan, F. G., Shah, S., Khan, A., Shamshirband, S., Rehman, Z. U., Khan, I. A. \\nand Jadoon, W. A deep learning ensemble approach for diabetic retinopathy \\ndetection, IEEE Access, vol. 7, pp. 150 530 150 539, 2019. \\n\\nRahim, S. S., Palade, V., Shuttleworth, J., & Jayne, C. (2016). Automatic screening and \\nclassification of diabetic retinopathy and maculopathy using fuzzy image processing. \\nBrain informatics, 3(4), 249267. \\n\\nRaman, V., Then, P., & Sumari, P. (2016). Proposed retinal abnormality detection and \\nclassification approach: Computer aided detection for diabetic retinopathy by \\nmachine learning approaches. In In 2016 8th IEEE International Conference on \\nCommunication Software and Networks (ICCSN) (pp. 636641). IEEE.  \\n\\nRamani, R. G., & Lakshmi, B. (2017). Automatic diabetic retinopathy detection through \\nensemble classification techniques automated diabetic retinopathy classification. In \\nIn 2017 IEEE International Conference on Computational Intelligence and Computing \\nResearch (ICCIC) (pp. 14). IEEE.  \\n\\nReddy, G. T., Bhattacharya, S., Ramakrishnan, S. S., Chowdhary, C. L., Hakak, S., Kaluri, \\nR. and Reddy, M. P. K. An ensemble-based machine learning model for diabetic \\nretinopathy classification, in 2020 international conference on emerging trends in \\ninformation technology and engineering (ic-ETITE). IEEE, 2020, pp. 16. \\n\\nSamanta, A., Saha, A., Satapathy, S. C., Fernandes, S. L., & Zhang, Y.-D. (2020). \\nAutomated detection of diabetic retinopathy using convolutional neural networks on \\na small dataset. Pattern Recognition Letters, 135, 293298. \\n\\nSikder, N., Masud, M., Bairagi, A. K., Arif, A. S. M., Nahid, A. A., & Alhumyani, H. A. \\n(2021). Severity classification of diabetic retinopathy using an ensemble learning \\nalgorithm through analyzing retinal images. Symmetry, 13(4), 670. \\n\\nShenavarmasouleh, F. and Arabnia, H. R. Drdr: Automatic masking of exudates and \\nmicroaneurysms caused by diabetic retinopathy using mask r-cnn and transfer \\nlearning, arXiv preprint arXiv:2007.02026, 2020. \\n\\nSomasundaram, S., & Ali, P. (2017). A machine learning ensemble classifier for early \\nprediction of diabetic retinopathy. Journal of Medical Systems, 41(12), 112. \\n\\nUmapathy, A., Sreenivasan, A., Nairy, D. S., Natarajan, S. and Rao, B. N., Image \\nprocessing, textural feature extraction and transfer learning based detection of \\ndiabetic retinopathy, in Proceedings of the 2019 9th International Conference on \\nBioscience, Biochemistry and Bioinformatics, 2019, pp. 1721. \\n\\nYu, S., Xiao, D., and Kanagasingam, Y. Exudate detection for diabetic retinopathy with \\nconvolutional neural networks, in 2017 39th Annual International Conference of \\nthe IEEE Engineering in Medicine and Biology Society (EMBC). IEEE, 2017, pp. \\n17441747. \\n\\nZhou, K., Gu, Z., Liu, W., Luo, W., Cheng, J., Gao, S. and Liu, J. Multi-cell multi-task \\nconvolutional neural networks for diabetic retinopathy grading, in 2018 40th \\nAnnual International Conference of the IEEE Engineering in Medicine and Biology \\nSociety (EMBC). IEEE, 2018, pp. 27242727. \\n\\nZeng, X., Chen, H., Luo, Y. and Ye, W. Automated diabetic retinopathy detection based \\non binocular siamese-like convolutional neural network, IEEE Access, vol. 7, pp. 30 \\n74430 753, 2019. \\n\\nZhao, Z., Zhang, K., Hao, X., Tian, J., Chua, M. C. H., Chen, L. and Xu, X. Bira-net: \\nBilinear attention net for diabetic retinopathy grading, in 2019 IEEE International \\nConference on Image Processing (ICIP). IEEE, 2019, pp. 13851389. \\n\\nMd. Nahiduzzaman et al.                                                                                                                                                                                                                     \\n\\nhttp://refhub.elsevier.com/S0957-4174(23)00058-1/h0180\\nhttp://refhub.elsevier.com/S0957-4174(23)00058-1/h0180\\nhttp://refhub.elsevier.com/S0957-4174(23)00058-1/h0190\\nhttp://refhub.elsevier.com/S0957-4174(23)00058-1/h0190\\nhttp://refhub.elsevier.com/S0957-4174(23)00058-1/h0200\\nhttp://refhub.elsevier.com/S0957-4174(23)00058-1/h0200\\nhttp://refhub.elsevier.com/S0957-4174(23)00058-1/h0200\\nhttp://refhub.elsevier.com/S0957-4174(23)00058-1/h0205\\nhttp://refhub.elsevier.com/S0957-4174(23)00058-1/h0205\\nhttp://refhub.elsevier.com/S0957-4174(23)00058-1/h0205\\nhttp://refhub.elsevier.com/S0957-4174(23)00058-1/h0205\\nhttp://refhub.elsevier.com/S0957-4174(23)00058-1/h0210\\nhttp://refhub.elsevier.com/S0957-4174(23)00058-1/h0210\\nhttp://refhub.elsevier.com/S0957-4174(23)00058-1/h0210\\nhttp://refhub.elsevier.com/S0957-4174(23)00058-1/h0210\\nhttp://refhub.elsevier.com/S0957-4174(23)00058-1/h0220\\nhttp://refhub.elsevier.com/S0957-4174(23)00058-1/h0220\\nhttp://refhub.elsevier.com/S0957-4174(23)00058-1/h0220\\nhttp://refhub.elsevier.com/S0957-4174(23)00058-1/h0225\\nhttp://refhub.elsevier.com/S0957-4174(23)00058-1/h0225\\nhttp://refhub.elsevier.com/S0957-4174(23)00058-1/h0225\\nhttp://refhub.elsevier.com/S0957-4174(23)00058-1/h0235\\nhttp://refhub.elsevier.com/S0957-4174(23)00058-1/h0235\\n\\n\\tDiabetic retinopathy identification using parallel convolutional neural network based feature extractor and ELM classifier\\n\\t1 Introduction\\n\\t2 Dataset description\\n\\t3 Proposed framework\\n\\t3.1 Pre-processing\\n\\t3.2 Features extraction using parallel convolutional layers\\n\\t3.3 Extreme learning machine\\n\\n\\t4 Result and discussion\\n\\t4.1 Results of Dataset-1\\n\\t4.2 Results of APTOS, 2019 Dataset\\n\\t4.3 Comparison with previous works\\n\\n\\t5 Conclusion\\n\\tCRediT authorship contribution statement\\n\\tDeclaration of Competing Interest\\n\\tData availability\\n\\tReferences\\n\\n\\n', 'status': 200}\n",
      "Dublin Core Metadata:\n",
      "{\n",
      "    \"dc:format\": \"application/pdf; version=1.7\",\n",
      "    \"dc:title\": \"Diabetic retinopathy identification using parallel convolutional neural network based feature extractor and ELM classifier\",\n",
      "    \"dc:description\": \"Expert Systems With Applications, 217 (2023) 119557. doi:10.1016/j.eswa.2023.119557\",\n",
      "    \"dc:creator\": [\n",
      "        \"Md. Nahiduzzaman\",\n",
      "        \"Md. Robiul Islam\",\n",
      "        \"Md. Omaer Faruq Goni\",\n",
      "        \"Md. Shamim Anower\",\n",
      "        \"Mominul Ahsan\",\n",
      "        \"Julfikar Haider\",\n",
      "        \"Marcin Kowalski\"\n",
      "    ],\n",
      "    \"dcterms:created\": \"2023-02-04T09:40:15Z\",\n",
      "    \"dcterms:modified\": \"2023-02-07T17:54:35Z\",\n",
      "    \"dc:language\": \"en\",\n",
      "    \"dc:subject\": [\n",
      "        \"Contrast limited adaptive histogram equalization (CLAHE),Diabetic retinopathy (DR),Parallel convolutional neural network (PCNN),Extreme LEARNING MACHine (ELM)\",\n",
      "        \"Expert Systems With Applications, 217 (2023) 119557. doi:10.1016/j.eswa.2023.119557\"\n",
      "    ]\n",
      "}\n",
      "Loaded project data successfully.\n",
      "Current project_data: {\n",
      "    \"@context\": {\n",
      "        \"schema\": \"http://schema.org/\",\n",
      "        \"dc\": \"http://purl.org/dc/terms/\"\n",
      "    },\n",
      "    \"@graph\": [\n",
      "        {\n",
      "            \"@type\": \"schema:ResearchProject\",\n",
      "            \"schema:identifier\": \"06535@test\",\n",
      "            \"schema:publicKey\": \"7851c382158dc0349df2136ae8821753b98b65be412387181764005baf9bff20\",\n",
      "            \"schema:description\": {\n",
      "                \"@context\": {\n",
      "                    \"schema\": \"http://schema.org/\",\n",
      "                    \"dc\": \"http://purl.org/dc/terms/\"\n",
      "                },\n",
      "                \"@type\": \"schema:ResearchProject\",\n",
      "                \"schema:name\": \"Investigating the Role of quantum computing in supply chain management\",\n",
      "                \"dc:abstract\": \"This study explores the impact of quantum computing in supply chain management, focusing on biodiversity.\",\n",
      "                \"schema:keywords\": [\n",
      "                    \"quantum computing\",\n",
      "                    \"supply chain management\",\n",
      "                    \"biodiversity\"\n",
      "                ],\n",
      "                \"schema:startDate\": \"2023-07-03\",\n",
      "                \"schema:endDate\": \"2026-07-23\",\n",
      "                \"schema:funding\": {\n",
      "                    \"@type\": \"schema:Organization\",\n",
      "                    \"schema:name\": \"National Science Foundation\"\n",
      "                },\n",
      "                \"schema:location\": {\n",
      "                    \"@type\": \"schema:Place\",\n",
      "                    \"schema:name\": \"Lagos, Nigeria\"\n",
      "                }\n",
      "            },\n",
      "            \"schema:metadataCID\": \"QmbmyecKUbwCDFPt6Uddx411bCvefLiRXPxHs5vnYz4XZm\",\n",
      "            \"schema:linked_user\": \"crazy_nash@test\",\n",
      "            \"schema:files\": [\n",
      "                {\n",
      "                    \"file_index\": 1,\n",
      "                    \"file_cid\": \"QmVk8gxENq6PThSGZTuk7RtbufR2XeN7LtXBj2LVTUoAdN\",\n",
      "                    \"metadata_cid\": \"QmWuj7Rr8PjwGzGW5otvAVTDUywUt8BHh7uvawFqEreMJo\",\n",
      "                    \"metadata\": {}\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"@type\": \"schema:ResearchProject\",\n",
      "            \"schema:identifier\": \"96858@test\",\n",
      "            \"schema:publicKey\": \"964dbc74f346b43a17060e1c451b5fd50873d0a2fe69188f32b2f8dbab052cfa\",\n",
      "            \"schema:description\": {\n",
      "                \"@context\": {\n",
      "                    \"schema\": \"http://schema.org/\",\n",
      "                    \"dc\": \"http://purl.org/dc/terms/\"\n",
      "                },\n",
      "                \"@type\": \"schema:ResearchProject\",\n",
      "                \"schema:name\": \"Analyzing the Influence of gene therapy on urban resilience\",\n",
      "                \"dc:abstract\": \"This paper analyzes how gene therapy influences urban resilience, providing insights into how to maximize its climate resilience.\",\n",
      "                \"schema:keywords\": [\n",
      "                    \"gene therapy\",\n",
      "                    \"urban resilience\",\n",
      "                    \"climate resilience\"\n",
      "                ],\n",
      "                \"schema:startDate\": \"2018-04-08\",\n",
      "                \"schema:endDate\": \"2026-06-05\",\n",
      "                \"schema:funding\": {\n",
      "                    \"@type\": \"schema:Organization\",\n",
      "                    \"schema:name\": \"National Science Foundation\"\n",
      "                },\n",
      "                \"schema:location\": {\n",
      "                    \"@type\": \"schema:Place\",\n",
      "                    \"schema:name\": \"Phuket, Thailand\"\n",
      "                }\n",
      "            },\n",
      "            \"schema:metadataCID\": \"QmRgbWW7QFgTWTRQqmjDv7fX6YypV8absEUSXwiw8f1Pn6\"\n",
      "        },\n",
      "        {\n",
      "            \"@type\": \"schema:ResearchProject\",\n",
      "            \"schema:identifier\": \"37887@test\",\n",
      "            \"schema:publicKey\": \"64593fc6dc0eb621cc258ffb3b180a171bcccb225bfea253084600c768776432\",\n",
      "            \"schema:description\": {\n",
      "                \"@context\": {\n",
      "                    \"schema\": \"http://schema.org/\",\n",
      "                    \"dc\": \"http://purl.org/dc/terms/\"\n",
      "                },\n",
      "                \"@type\": \"schema:ResearchProject\",\n",
      "                \"schema:name\": \"Analyzing the Influence of bioinformatics on climate adaptation\",\n",
      "                \"dc:abstract\": \"This paper analyzes how bioinformatics influences climate adaptation, providing insights into how to maximize its scientific discovery.\",\n",
      "                \"schema:keywords\": [\n",
      "                    \"bioinformatics\",\n",
      "                    \"climate adaptation\",\n",
      "                    \"scientific discovery\"\n",
      "                ],\n",
      "                \"schema:startDate\": \"2021-01-20\",\n",
      "                \"schema:endDate\": \"2028-06-16\",\n",
      "                \"schema:funding\": {\n",
      "                    \"@type\": \"schema:Organization\",\n",
      "                    \"schema:name\": \"World Wildlife Fund\"\n",
      "                },\n",
      "                \"schema:location\": {\n",
      "                    \"@type\": \"schema:Place\",\n",
      "                    \"schema:name\": \"Tokyo, Japan\"\n",
      "                }\n",
      "            },\n",
      "            \"schema:metadataCID\": \"QmT1cPcYNcGntxCc2goVmkJuQG9EdVthjvG6SVNs7WCXc8\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "Checking project with ID: '06535@test' against '06535@test'\n",
      "Match found for project ID: 06535@test\n",
      "Updated project 06535@test with new file entry: {'file_index': 2, 'file_cid': 'QmT7ximApXtExAedhzUHGHDwRismRzuKykpH4dgTvGrNZs', 'metadata_cid': 'QmcqzQsw6F8w5vYV49gQYmzMM1WuQcrXFVASqwThDgyb14', 'metadata': {'dc:format': 'application/pdf; version=1.7', 'dc:title': 'Diabetic retinopathy identification using parallel convolutional neural network based feature extractor and ELM classifier', 'dc:description': 'Expert Systems With Applications, 217 (2023) 119557. doi:10.1016/j.eswa.2023.119557', 'dc:creator': ['Md. Nahiduzzaman', 'Md. Robiul Islam', 'Md. Omaer Faruq Goni', 'Md. Shamim Anower', 'Mominul Ahsan', 'Julfikar Haider', 'Marcin Kowalski'], 'dcterms:created': '2023-02-04T09:40:15Z', 'dcterms:modified': '2023-02-07T17:54:35Z', 'dc:language': 'en', 'dc:subject': ['Contrast limited adaptive histogram equalization (CLAHE),Diabetic retinopathy (DR),Parallel convolutional neural network (PCNN),Extreme LEARNING MACHine (ELM)', 'Expert Systems With Applications, 217 (2023) 119557. doi:10.1016/j.eswa.2023.119557']}}\n",
      "Successfully wrote updated data to datasets/projects.json\n",
      "----------------------------------------\n",
      "{'pdf:PDFVersion': '1.7', 'xmp:CreatorTool': 'Elsevier', 'pdf:docinfo:title': 'Diabetic retinopathy identification using parallel convolutional neural network based feature extractor and ELM classifier', 'pdf:hasXFA': 'false', 'access_permission:can_print_degraded': 'true', 'X-TIKA:Parsed-By-Full-Set': ['org.apache.tika.parser.DefaultParser', 'org.apache.tika.parser.pdf.PDFParser'], 'X-TIKA:content_handler': 'ToTextContentHandler', 'pdf:num3DAnnotations': '0', 'dc:format': 'application/pdf; version=1.7', 'pdf:docinfo:custom:robots': 'noindex', 'pdf:docinfo:creator_tool': 'Elsevier', 'access_permission:fill_in_form': 'true', 'pdf:docinfo:custom:CreationDate--Text': '7th February 2023', 'pdf:hasCollection': 'false', 'pdf:encrypted': 'false', 'dc:title': 'Diabetic retinopathy identification using parallel convolutional neural network based feature extractor and ELM classifier', 'pdf:containsNonEmbeddedFont': 'false', 'xmp:CreateDate': '2023-02-04T09:40:15Z', 'pdf:docinfo:custom:CrossMarkDomains[1]': 'elsevier.com', 'robots': 'noindex', 'pdf:docinfo:subject': 'Expert Systems With Applications, 217 (2023) 119557. doi:10.1016/j.eswa.2023.119557', 'pdf:hasMarkedContent': 'true', 'xmp:ModifyDate': '2023-02-07T17:54:35Z', 'pdf:docinfo:creator': 'Md. Nahiduzzaman', 'pdf:docinfo:custom:CrossmarkMajorVersionDate': '2010-04-23', 'access_permission:extract_for_accessibility': 'true', 'resourceName': \"b'Diabetic-retinopathy-identification-using-parallel-convo_2023_Expert-Systems.pdf'\", 'pdf:docinfo:custom:CrossMarkDomains[2]': 'sciencedirect.com', 'X-TIKA:Parsed-By': ['org.apache.tika.parser.DefaultParser', 'org.apache.tika.parser.pdf.PDFParser'], 'ElsevierWebPDFSpecifications': '7.0', 'pdf:docinfo:custom:doi': '10.1016/j.eswa.2023.119557', 'pdf:docinfo:custom:CrossmarkDomainExclusive': 'true', 'X-TIKA:embedded_depth': '0', 'CrossmarkDomainExclusive': 'true', 'pdf:annotationTypes': 'null', 'pdf:docinfo:producer': 'Acrobat Distiller 8.1.0 (Windows)', 'pdf:annotationSubtypes': 'Link', 'CreationDate--Text': '7th February 2023', 'doi': '10.1016/j.eswa.2023.119557', 'pdf:containsDamagedFont': 'false', 'pdf:unmappedUnicodeCharsPerPage': ['0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0'], 'dc:description': 'Expert Systems With Applications, 217 (2023) 119557. doi:10.1016/j.eswa.2023.119557', 'access_permission:modify_annotations': 'true', 'dc:creator': ['Md. Nahiduzzaman', 'Md. Robiul Islam', 'Md. Omaer Faruq Goni', 'Md. Shamim Anower', 'Mominul Ahsan', 'Julfikar Haider', 'Marcin Kowalski'], 'dcterms:created': '2023-02-04T09:40:15Z', 'dcterms:modified': '2023-02-07T17:54:35Z', 'xmpMM:DocumentID': 'uuid:1b499bed-4ce8-4c0c-b682-0d58baae1cbe', 'CrossMarkDomains[1]': 'elsevier.com', 'pdf:overallPercentageUnmappedUnicodeChars': '0.0', 'pdf:docinfo:keywords': 'Contrast limited adaptive histogram equalization (CLAHE),Diabetic retinopathy (DR),Parallel convolutional neural network (PCNN),Extreme LEARNING MACHine (ELM)', 'pdf:docinfo:modified': '2023-02-07T17:54:35Z', 'Content-Length': '6122917', 'Content-Type': 'application/pdf', 'xmp:MetadataDate': '2023-02-07T17:54:35Z', 'dc:language': 'en', 'pdf:producer': 'Acrobat Distiller 8.1.0 (Windows)', 'dc:subject': ['Contrast limited adaptive histogram equalization (CLAHE),Diabetic retinopathy (DR),Parallel convolutional neural network (PCNN),Extreme LEARNING MACHine (ELM)', 'Expert Systems With Applications, 217 (2023) 119557. doi:10.1016/j.eswa.2023.119557'], 'pdf:docinfo:custom:ElsevierWebPDFSpecifications': '7.0', 'pdf:totalUnmappedUnicodeChars': '0', 'access_permission:assemble_document': 'true', 'xmpTPg:NPages': '11', 'pdf:hasXMP': 'true', 'pdf:charsPerPage': ['4980', '8262', '7998', '1077', '4759', '5305', '3814', '3469', '7158', '10210', '4231'], 'access_permission:extract_content': 'true', 'access_permission:can_print': 'true', 'CrossMarkDomains[2]': 'sciencedirect.com', 'meta:keyword': 'Contrast limited adaptive histogram equalization (CLAHE),Diabetic retinopathy (DR),Parallel convolutional neural network (PCNN),Extreme LEARNING MACHine (ELM)', 'X-TIKA:parse_time_millis': '173', 'access_permission:can_modify': 'true', 'pdf:docinfo:created': '2023-02-04T09:40:15Z', 'CrossmarkMajorVersionDate': '2010-04-23'}\n",
      "{'metadata': {'pdf:unmappedUnicodeCharsPerPage': ['0', '0', '0'], 'pdf:PDFVersion': '1.7', 'xmp:CreatorTool': 'Elsevier', 'pdf:hasXFA': 'false', 'access_permission:modify_annotations': 'true', 'access_permission:can_print_degraded': 'true', 'X-TIKA:Parsed-By-Full-Set': ['org.apache.tika.parser.DefaultParser', 'org.apache.tika.parser.pdf.PDFParser'], 'X-TIKA:content_handler': 'ToTextContentHandler', 'pdf:num3DAnnotations': '0', 'dcterms:created': '2023-02-07T10:24:44Z', 'dcterms:modified': '2023-02-07T10:25:02Z', 'dc:format': 'application/pdf; version=1.7', 'xmpMM:DocumentID': 'xmp.id:88483799D0A6ED118966FC0221C82C06', 'pdf:docinfo:creator_tool': 'Elsevier', 'pdf:overallPercentageUnmappedUnicodeChars': '0.0', 'access_permission:fill_in_form': 'true', 'pdf:docinfo:modified': '2023-02-07T10:25:02Z', 'pdf:hasCollection': 'false', 'pdf:encrypted': 'false', 'pdf:containsNonEmbeddedFont': 'false', 'Content-Length': '142113', 'pdf:hasMarkedContent': 'true', 'Content-Type': 'application/pdf', 'pdf:producer': 'Adobe PDF Library 10.0.1', 'pdf:totalUnmappedUnicodeChars': '0', 'access_permission:extract_for_accessibility': 'true', 'access_permission:assemble_document': 'true', 'xmpTPg:NPages': '3', 'resourceName': \"b'Editorial-Board_2023_Expert-Systems-with-Applications.pdf'\", 'pdf:hasXMP': 'true', 'pdf:charsPerPage': ['7393', '5386', '2644'], 'access_permission:extract_content': 'true', 'access_permission:can_print': 'true', 'pdf:docinfo:trapped': 'False', 'X-TIKA:Parsed-By': ['org.apache.tika.parser.DefaultParser', 'org.apache.tika.parser.pdf.PDFParser'], 'X-TIKA:parse_time_millis': '51', 'X-TIKA:embedded_depth': '0', 'access_permission:can_modify': 'true', 'pdf:docinfo:producer': 'Adobe PDF Library 10.0.1', 'pdf:docinfo:created': '2023-02-07T10:24:44Z', 'pdf:containsDamagedFont': 'false'}, 'content': '\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nEDITOR-IN-CHIEF \\nBinshan Lin,  Louisiana State University at Shreveport, One University Place, Shreveport, LA 71115, Louisiana, USA\\n\\nFounding Editor \\nJay Liebowitz, University of Maryland University College, Adelphi, Maryland, USA\\n\\nEXPERT SYSTEMS WITH APPLICATIONS \\n\\nAn International Journal \\n\\nEDITOR-IN-CHIEF \\nBinshan Lin , Louisiana State University at Shreveport, One University Place, Shreveport, LA 71115, Louisiana, USA \\n\\nFounding Editor \\nJay Liebowitz , University of Maryland University College, Adelphi, Maryland, USA \\n\\nEDITORIAL ADVISORY BOARD \\n\\nP. Anussor nnitisar n \\nKasetsart University, Bangkok, Thailand \\nE. Balagurusamy \\nPSG Inst. of Management, Coimbatore, India \\nH. Bergkvist \\nATTEXOR S.A., Ecublens Lausanne, Switzerland \\nD.C. Berry \\nUniversity of Reading, Reading, UK \\nB.A. Bremdal \\nUniversity of Oslo, Oslo, Norway \\nF.J. Cantu \\nInst. Technolgico y de Estudios, Monterrey NL, Mexico \\nH. Carson \\nGeorge Washington University, Washington, District of Columbia, USA \\nS. Conlon \\nUniversity of Mississippi, USA \\nK. Dalkir \\nMcGill University, Montreal, Quebec, Canada \\nR. Davidrajuh \\nUniversity of Stavanger, Stavanger, Norway \\nR. Davis \\nWeizmann Institute of Science, Rehovot, Israel \\nMr. L.B. Eliot \\nUniversity of Southern California, Long Beach, California, USA \\nE. Feigenbaum \\nStanford University, Stanford, USA \\nR. Fjellheim \\nComputas A.S., Sandvika, Norway \\nK. Fordyce \\nIBM Thomas J. Watson Research Center, Hurley, New York, USA \\nM. Fox \\nUniversity of Toronto, Toronto, Ontario, Canada \\nO.-P. Hilmola \\nLappeenranta University of Technology (LUT), Kouvola, Finland \\nJ.K. Lee \\nKAIST Business School, Seoul, The Republic of Korea \\nD. Lesjak \\nInternational School for Social and Business Studies, Celje, Slovenia \\nC. Lin \\nNational Cheng Kung University, Tainan, Taiwan, ROC \\nP. Love \\nCurtin University, Perth, Western Australia, Australia \\nA.G. Maguitman \\nUniversidad Nacional del Sur, Baha Blanca, Buenos Aires, Argentina \\n\\nS. Mankad \\nCornell University, USA \\nV. Milacic \\nUniversity of Belgrade, Belgrade, Serbia \\nY. Mohsenzadeh \\nMassachusetts Institute of Technology (MIT), USA \\nA.D. Narasimhalu \\nSingapore Management University, Singapore \\nD. OLeary \\nUniversity of Southern California, Los Angeles, California, USA \\nK.B. Ooi \\nUCSI University, Kuala Lumpur, Malaysia \\nJ. Paliszkiewicz \\nWarsaw University of Life Sciences-SGGW, Warsaw, Poland \\nZ. Pastuszak \\nMaria Curie-Sklodowska University, Poland \\nC. Scarlat \\nPolitehnica University of Bucharest, Bucharest, Romania \\nMr. D. Schutzer \\nCity Corp. Investment Bank, New York, New York, USA \\nR. Shumaker \\nUniversity of Central Florida, Orlando, Florida, USA \\nR. Slagle \\nD. Specht \\nBrandenburgische Technische Universitt (BTU), Cottbus, Germany \\nC.Y. Suen \\nConcordia University, Montral, Quebec, Canada \\nJ. Tang \\nTsinghua University, Beijing, China \\nE. Turban \\nUniversity of Hawaii at Mnoa, Kiehi, Hawaii, USA \\nI.B. Turksen \\nUniversity of Toronto, Toronto, Ontario, Canada \\nJ. Vanthienen \\nKU Leuven, Leuven, Belgium \\nMr. R.G. Vedder \\nUniversity of North Texas, Denton, Texas, USA \\nS. Wang \\nUniversity of Massachusetts Dartmouth, North Dartmouth, Massachusetts, \\n\\nUSA \\nJ.R. Wright \\nAT&T Research, Florham Park, New Jersey, USA \\nM.R. Zielinski \\nHarvard Medical School, USA \\n\\nR. Alizadehsani\\nInstitute for Intelligent Systems Research and Innovation (IISRI), Deakin University, \\nAustralia\\nA. Ahmadzadeh\\nDepartment of Computer Science, Georgia State University, USA\\nD.R. Amancio\\nUniversity of So Paulo, Brazil\\nK. Andersson\\nLule University of Technology\\nJ.G. Avina-Cervantes\\nElectronics Engineering Department, University of Guanajuato, Mexico\\nA. Azab\\nDepartment of Mechanical, Automotive, and Materials Engineering, University of \\nWindsor, Canada\\nS. Bakshi\\nDepartment of Computer Science & Engineering, National Institute of Technology \\nRourkela, India\\nS.J. Barnes\\nKings College London, London, UK\\nD. Borenstein\\nManagement School, Federal University of Rio Grande do Sul, Brazil\\nD.D. Caprio\\nUniversity of Trento, Trento, Italy\\nF.J.G. Castao\\nTelematics Engineering Department, University of Vigo, Spain\\nM.E. Celebi\\nDepartment of Computer Science and Engineering, University of Central Arkansas, USA\\nB.R. Chakravarthi\\nSchool of Computer Science, University of Galway, Ireland\\nV. Charles\\nUniversity of Bradford, Bradford, UK\\nK. Chau\\nDepartment of Civil & Environmental Engineering, Hong Kong Polytechnic University,  \\nHong Kong, China\\nC.-Y. Chen\\nSchool of Information and Electrical Engineering, Hunan University of Science and \\nTechnology, China\\nS. Cheng\\nSchool of Computer Science, Shaanxi Normal University\\nK.-S. Chin\\nCity University of Hong Kong, Hong Kong\\nL.D.S. Coelho\\nIndustrial and Systems Engineering Graduate Program (PPGEPS), Pontifical Catholic, \\nUniversity of Parana, Brazil, and Department of Electrical Engineering, Federal University \\nof Parana, Brazil\\nS. Conlon\\nUniversity of Mississippi, Mississippi, USA\\nE. Cuevas\\nUniversity of Guadalajara, Mexico\\nK. Demertzis\\nSchool of Science & Technology, Informatics Studies, Hellenic Open University,  \\nGreece\\nZ.-H. Deng\\nPeking University, Beijing, China\\nD. Delen\\nOklahoma State University, Spears School of Business, Department of Management \\nScience and Information Systems, Stillwater, Oklahoma, USA\\nIstinye University, Faculty of Engineering and Natural Sciences, Department of Industrial \\nEngineering, Istanbul Turkey\\nM. Deveci\\nThe Bartlett School of Sustainable Construction, University College London, UK, \\nand Department of Industrial Engineering, Turkish Naval Academy, National Defence \\nUniversity, Turkey\\n\\nS.B. Dias\\nUniversidade de Lisboa, Portugal\\nA. Doulamis\\nSchool of Rural, Surveying and Geoinformatics Engineering, Computer Vision and \\nPhotogrammetry Lab., National technical university of Athens\\nP. DUrso\\nSapienza University of Rome, Roma, Italy\\nU. Erra\\nDepartment of Mathematics, Computer Science and Economics, University of Basilicata, \\nItaly\\nE. Fersini\\nUniversity of Milano-Bicocca, Milan, Italy\\nM.C. Ferreira\\nDepartment of Industrial Engineering and Management, Faculty of Engineering, \\nUniversity of Porto, Porto, Portugal\\nI. Fister\\nUniversity of Maribor, Maribor, Slovenia\\nC.B. Foltz\\nUniversity of Tennessee at Martin, Martin, USA\\nA. Forestiero\\nNational Research Council of Italy\\nK. Gao\\nInstitute of Systems Engineering, Macau University of Science and Technology, Macao\\nP. Garza\\nDepartment of Control and Computer Engineering, Polytechnic of Turin, Torino, Italy\\nA. Glowacz\\nAGH University of Science and Technology, Poland\\nCracow University of Technology, Poland\\nW. Gong\\nSchool of Computer Science, China University of Geosciences, Wuhan, China \\nP. Gonzlez\\nCITIC, University of A Corua, Spain\\nY. Guo\\nDepartment of Computer Science, University of Illinois Springfield, USA\\nF. Gu\\nCUNY College of Staten Island & Graduate Center, USA\\nF. Guijarro\\nTechnical University of Valencia, Spain\\nS.-Y. Ji\\nProfessor, College of Arts and Sciences, Computer Science Dept., Bowie State University\\nH. Ma\\nNorthwest Normal University, China\\nJ.-K. Hao\\nUniversit dAngers, France\\nS. Hassanzadeh Amin\\nAssociate Professor at Department of Mechanical and Industrial Engineering, Toronto \\nMetropolitan University, Canada\\nP. Hilletofth\\nUniversity of Gvle, Finland\\nL.-A. Ho\\nTamkang University, New Taipei, Taiwan\\nA. Ishizaka\\nNEOMA Business School, France\\nD. Kocev\\nJozef Stefan Institute, Ljubljana, Slovenia\\nR. Koceva\\nDepartment of Communication Systems, Joef Stefan Institute, Slovenia\\nA.L. Koerich\\ncole de Technologie Suprieure, Universit du Qubec, Montreal, Canada\\nW. Kristjanpoller\\nUniversidad Tecnica Federico Santa Maria, Chile\\nS. Lahmiri\\nConcordia University, Quebec, Canada\\n\\nASSOCIATE EDITORS\\n\\n\\n\\nE. Lalla-Ruiz\\nDepartment of High-Business Entrepreneurship, IEBIS, University of Twente, \\nThe Netherlands\\nH.-Y. Lam\\nDepartment of Supply Chain and Information Management, The Hang Seng University of \\nHong Kong, Hong Kong\\nC. Li\\nTsinghua University, Beijing, China\\nJ. Li\\nSchool of Information Science and Engineering, Shandong Normal University, Jinan, PR. China\\nX. Li\\nSchool of Mechanical Science & Engineering, Huazhong University of Science & \\nTechnology, China\\nC. Lin\\nNational Cheng Kung University, Tainan, Taiwan\\nK.-P. Lin\\nTunghai University, Taiwan\\nW. Ling\\nTsinghua University, Beijing, China\\nC. Luca\\nPolitecnico di Torino, Italy\\nT. Madjid\\nDistinguished Chair, Business Systems and Analytics, La Salle University, USA\\nS. Mancini\\nDepartment of Engineering, University of Palermo, Italy\\nDepartment of Production and Logistics Management, University of Klagenfurt, Austria\\nV. C. Mariani\\nDepartment of Mechanical Engineering, PUCPR, Brazil\\nDepartment of Electrical Engineering, UFPR, Brazil\\nM. J. Martin-Bautista\\nDepartment of Computer Science and Artificial Intelligence, University of Granada, Spain\\nJ. Martinez-Gil\\nSoftware Compentece Center Hagenberg GmbH, Austria\\nM. Martins da Silva\\nSo Carlos School of Engineering, University of So Paulo, Brazil\\nL. Martnez\\nDepartment of Computer Science, University of Jan, Spain\\nH. Mndez-Vzquez\\nAdvanced Technologies Application \\nCenter (CENATAV), Cuba\\nW. Meng\\nDepartment of Applied Mathematics and Computer Science, Technical University of \\nDenmark, Denmark\\nY. Mohsenzadeh\\nThe University of Western Ontario, Canada\\nV. Moscato\\nDepartment of Information Electrical Engineering and Information Technology of \\nUniversity of Naples Federico II, Italy\\nM. NAPPI\\nComputer Science Dept. at University of Salerno, Italy\\nM. C. V. Nascimento\\nFederal University of So Paulo, Brazil\\nP. Neto\\nUniversity of Coimbra, Portugal\\nR.F.M.F. Neves\\nUniversity of Lisbon, Lisboa, Portugal\\nG.M.D. Nunzio\\nUniversity of Padua, Padova, Italy\\nK.-B. Ooi\\nUCSI University, Kuala Lumpur, Malaysia\\nA. C. Olivera\\nResearcher at Interdisciplinary Institute of Basic Sciences, National University of Cuyo \\nand National Council of Scientific and Technical Research, Professor at Faculty of \\nEngineering, National University of Cuyo, Argentina.\\nL.E.S. Oliveira\\nFederal University of Parana, Brazil\\nE. Osaba\\nTecnalia Research & Innovation, Spain\\nS. Palaiahnakote\\nUniversity of Malaya (UM), Kuala Lumpur-50603, Malaysia\\nJ. Paliszkiewicz\\nWarsaw University of Life Science - SGGW, Warsaw, Poland\\nD. Pamucar\\nUniversity of Belgrade, Faculty of Organizational Sciences, Department of Operations \\nResearch and Statistics, Belgrade, Serbia\\nC. Panagiotakis\\nDepartment of Management Science and Technology, Hellenic Mediterranean University, \\nGreece\\nZ. Pastuszak\\nMaria Curie-Sklodowska University, Lublin, Poland\\n\\nG. Pio\\nDepartment of Computer Science, University of Bari Aldo Moro, Italy\\nD. Poap\\nFaculty of Applied Mathematics, Silesian University of Technology, Poland\\nN. Polatidis\\nUniversity of Brighton, United Kingdom\\nP. Pongcharoen\\nFaculty of Engineering, Naresuan University, Phitsanulok, Thailand\\nR.-E. Precup\\nDepartment of Automation and Applied Informatics,\\nPolitehnica University of Timisoara, Romania\\nG. Qi\\nComputer Information Systems Department, State University of New York at Buffalo \\nState, United States\\nI. Ribas\\nUniversitat Politcnica de Catalunya, spain\\nR. Rios\\nFederal University of Bahia, Brazil\\nF. Ros\\nUniversity of Orleans /Laboratory PRISME/FRANCE\\nE.M. Ruiz\\nUniversidad Politecnica de Madrid. Computer Science School\\nS. Saha\\nIndian Institute of Technology Patna, Bihar, India\\nS. Schiaffino\\nISISTAN Research Institute (CONICET) - National University of the Centre of Buenos \\nAires Province (UNCPBA) - Argentina\\nS. Senatore\\nDepartment of Computer Engineering, Electrical Engineering and Applied Mathematics \\n(DIEM) University of Salerno, Italy\\nL. Shen\\nSchool of Computer Science & Software Engineering, Shenzhen University, China\\nN. Simidjievski\\nDepartment of Computer Science and Technology, University of Cambridge, UK\\nS. Song\\nTsinghua University, China\\nG. Song\\nPeking University, Beijing, China\\nJ.M.R.S. Tavares\\nUniversidade do Porto, Portugal\\nE.B. Tirkolaee\\nFaculty of Engineering and Natural Sciences, Department of Industrial Engineering, \\nIstinye University, Istanbul, Turkey\\nM.K. Tiwari\\nJ. Torres-Sospedra\\nUBIK Geospatial Solutions S.L., Spain\\nUniversitat Jaume I, Spain\\nG. Tortora (aka Genny)\\nDepartment of Computer Science, Universit di Salerno, Italy\\nE. Triantaphyllou\\nSchool of Electrical Engineering and Computer Science\\nDivision of Computer Science and Engineering 3272C Patrick F. Taylor Hall,Louisiana \\nState University, Baton Rouge, LA 70803, USA\\nM. Trovati\\nDepartment of Computer Science, Edge Hill University, UK\\nC. Tucker\\nCarnegie Mellon University, Pittsburgh, USA\\nP. Wang\\nJames Madison University, Harrisonburg, USA\\nR. Wang \\nCollege of System Engineering, National University of Defense Technology,  \\nP.R. China\\nJ. Watrbski\\nUniversity of Szczecin, Insitute of Management, Poland\\nX. Wu\\nSchool of Mechanical Engineering/Department of Logistics,University of Science and \\nTechnology Beijing, China\\nP. Xanthopoulos\\nStetson University, Florida, USA\\nH. Xu\\nTsinghua University, Beijing, China\\nS. Yang\\nStevens Institute of Technology, Hoboken, USA\\nH.-J. Yang\\nDept. Artificial Intelligence Convergence, Chonnam National University, South Korea\\nY. Yu\\nSchool of Computer Science, Shaanxi Normal University, China\\nH. Yuan\\nSchool of Automation Science and Electrical Engineering, Beihang University, Beijing, \\nChina\\n\\n\\n\\nP. Anussornnitisarn\\nKasetsart University, Bangkok, Thailand\\nE. Balagurusamy\\nPSG Inst. of Management, Coimbatore, India\\nH. Bergkvist\\nATTEXOR S.A., Ecublens Lausanne, Switzerland\\nD.C. Berry\\nUniversity of Reading, Reading, UK\\nB.A. Bremdal\\nUniversity of Oslo, Oslo, Norway\\nF.J. Cantu\\nInst. Technolgico y de Estudios, Monterrey NL, MexicoH. Carson\\nGeorge Washington University, Washington, District of Columbia,  \\nUSA\\nK. Dalkir\\nMcGill University, Montreal, Quebec, Canada\\nR. Davis\\nWeizmann Institute of Science, Rehovot, Israel\\nMr. L.B. Eliot\\nUniversity of Southern California, Long Beach, California, USA\\nE. Feigenbaum\\nStanford University, Stanford, USA\\nR. Fjellheim\\nComputas A.S., Sandvika, Norway\\nK. Fordyce\\nIBM Thomas J. Watson Research Center, Hurley, New York, USA\\nM. Fox\\nUniversity of Toronto, Toronto, Ontario, Canada\\nO.-P. Hilmola\\nLappeenranta University of Technology (LUT), Kouvola, Finland\\nJ.K. Lee\\nKAIST Business School, Seoul, The Republic of Korea\\nD. Lesjak\\nInternational School for Social and Business Studies, Celje, Slovenia\\nA.G. Maguitman\\nUniversidad Nacional del Sur, Baha Blanca, Buenos Aires, Argentina\\nS. Mankad\\nCornell University, USA\\nV. Milacic\\nUniversity of Belgrade, Belgrade, Serbia\\n\\nA.D. Narasimhalu\\nSingapore Management University, Singapore\\nD. OLeary\\nUniversity of Southern California, Los Angeles, California, USA\\nK.B. Ooi\\nUCSI University, Kuala Lumpur, Malaysia\\nZ. Pastuszak\\nMaria Curie-Sklodowska University, Poland\\nC. Scarlat\\nPolitehnica University of Bucharest, Bucharest, Romania\\nMr. D. Schutzer\\nCity Corp. Investment Bank, New York, New York, USA\\nR. Shumaker\\nUniversity of Central Florida, Orlando, Florida, USA\\nR. Slagle\\nD. Specht\\nBrandenburgische Technische Universitt (BTU),\\nCottbus, Germany\\nC.Y. Suen\\nConcordia University, Montral, Quebec, Canada\\nJ. Tang\\nTsinghua University, Beijing, China\\nE. Turban\\nUniversity of Hawaii at Mnoa, Kiehi, Hawaii, USA\\nI.B. Turksen\\nUniversity of Toronto, Toronto, Ontario, Canada\\nJ. Vanthienen\\nKU Leuven, Leuven, Belgium\\nMr. R.G. Vedder\\nUniversity of North Texas, Denton, Texas, USA\\nS. Wang\\nUniversity of Massachusetts Dartmouth, North Dartmouth,\\nMassachusetts, USA\\nJ.R. Wright\\nAT&T Research, Florham Park, New Jersey, USA\\nM.R. Zielinski\\nHarvard Medical School, USA\\n\\nEDITORIAL ADVISORY BOARD\\n\\nT. Ying\\nPeking University, Beijing, China\\nG. Yong San Lim\\nSingapore National Eye Centre, Singapore\\nZ. Zhang \\nSchool of Computer Science and Technology, Harbin Insitute of Technology, Shenzhen, \\nChina\\nF. Zhang\\nVictoria University of Wellington, New Zealand\\n\\nW. Zhang\\nCollege of Engineering, Department of Mechanical Engineering, University of \\nSaskatchewan, Canada\\nH. Zhuge\\nDepartment of Computer Science, School of Informatics and Digital Engineering, Aston \\nUniversity, UK.\\n\\n\\n', 'status': 200}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Indexed Editorial-Board_2023_Expert-Systems-with-Applications.pdf with CID: QmZBwBxATjd85MZK9q6eSaX3tztcYbJzT34obDZmFKNE8K\n",
      "INFO:root:Document Editorial-Board_2023_Expert-Systems-with-Applications.pdf indexed successfully.\n",
      "INFO:root:updated project entry\n",
      "ERROR:root:Error processing file 'Editorial-Board_2023_Expert-Systems-with-Applications.pdf': sequence item 0: expected a bytes-like object, str found\n",
      "INFO:root:Processing file: COVID19-MLSF--A-multi-task-learning-based-stock-market_2023_Expert-Systems-w.pdf\n",
      "INFO:root:File COVID19-MLSF--A-multi-task-learning-based-stock-market_2023_Expert-Systems-w.pdf uploaded to IPFS with CID: QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW\n",
      "INFO:root:Indexed COVID19-MLSF--A-multi-task-learning-based-stock-market_2023_Expert-Systems-w.pdf with CID: QmY1iBM4gc3quCmVWbjjmFSoUwxqji9ff3gkX3MyVqypmj\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dublin Core Metadata:\n",
      "{\n",
      "    \"dcterms:created\": \"2023-02-07T10:24:44Z\",\n",
      "    \"dcterms:modified\": \"2023-02-07T10:25:02Z\",\n",
      "    \"dc:format\": \"application/pdf; version=1.7\"\n",
      "}\n",
      "Loaded project data successfully.\n",
      "Current project_data: {\n",
      "    \"@context\": {\n",
      "        \"schema\": \"http://schema.org/\",\n",
      "        \"dc\": \"http://purl.org/dc/terms/\"\n",
      "    },\n",
      "    \"@graph\": [\n",
      "        {\n",
      "            \"@type\": \"schema:ResearchProject\",\n",
      "            \"schema:identifier\": \"06535@test\",\n",
      "            \"schema:publicKey\": \"7851c382158dc0349df2136ae8821753b98b65be412387181764005baf9bff20\",\n",
      "            \"schema:description\": {\n",
      "                \"@context\": {\n",
      "                    \"schema\": \"http://schema.org/\",\n",
      "                    \"dc\": \"http://purl.org/dc/terms/\"\n",
      "                },\n",
      "                \"@type\": \"schema:ResearchProject\",\n",
      "                \"schema:name\": \"Investigating the Role of quantum computing in supply chain management\",\n",
      "                \"dc:abstract\": \"This study explores the impact of quantum computing in supply chain management, focusing on biodiversity.\",\n",
      "                \"schema:keywords\": [\n",
      "                    \"quantum computing\",\n",
      "                    \"supply chain management\",\n",
      "                    \"biodiversity\"\n",
      "                ],\n",
      "                \"schema:startDate\": \"2023-07-03\",\n",
      "                \"schema:endDate\": \"2026-07-23\",\n",
      "                \"schema:funding\": {\n",
      "                    \"@type\": \"schema:Organization\",\n",
      "                    \"schema:name\": \"National Science Foundation\"\n",
      "                },\n",
      "                \"schema:location\": {\n",
      "                    \"@type\": \"schema:Place\",\n",
      "                    \"schema:name\": \"Lagos, Nigeria\"\n",
      "                }\n",
      "            },\n",
      "            \"schema:metadataCID\": \"QmbmyecKUbwCDFPt6Uddx411bCvefLiRXPxHs5vnYz4XZm\",\n",
      "            \"schema:linked_user\": \"crazy_nash@test\",\n",
      "            \"schema:files\": [\n",
      "                {\n",
      "                    \"file_index\": 1,\n",
      "                    \"file_cid\": \"QmVk8gxENq6PThSGZTuk7RtbufR2XeN7LtXBj2LVTUoAdN\",\n",
      "                    \"metadata_cid\": \"QmWuj7Rr8PjwGzGW5otvAVTDUywUt8BHh7uvawFqEreMJo\",\n",
      "                    \"metadata\": {}\n",
      "                },\n",
      "                {\n",
      "                    \"file_index\": 2,\n",
      "                    \"file_cid\": \"QmT7ximApXtExAedhzUHGHDwRismRzuKykpH4dgTvGrNZs\",\n",
      "                    \"metadata_cid\": \"QmcqzQsw6F8w5vYV49gQYmzMM1WuQcrXFVASqwThDgyb14\",\n",
      "                    \"metadata\": {\n",
      "                        \"dc:format\": \"application/pdf; version=1.7\",\n",
      "                        \"dc:title\": \"Diabetic retinopathy identification using parallel convolutional neural network based feature extractor and ELM classifier\",\n",
      "                        \"dc:description\": \"Expert Systems With Applications, 217 (2023) 119557. doi:10.1016/j.eswa.2023.119557\",\n",
      "                        \"dc:creator\": [\n",
      "                            \"Md. Nahiduzzaman\",\n",
      "                            \"Md. Robiul Islam\",\n",
      "                            \"Md. Omaer Faruq Goni\",\n",
      "                            \"Md. Shamim Anower\",\n",
      "                            \"Mominul Ahsan\",\n",
      "                            \"Julfikar Haider\",\n",
      "                            \"Marcin Kowalski\"\n",
      "                        ],\n",
      "                        \"dcterms:created\": \"2023-02-04T09:40:15Z\",\n",
      "                        \"dcterms:modified\": \"2023-02-07T17:54:35Z\",\n",
      "                        \"dc:language\": \"en\",\n",
      "                        \"dc:subject\": [\n",
      "                            \"Contrast limited adaptive histogram equalization (CLAHE),Diabetic retinopathy (DR),Parallel convolutional neural network (PCNN),Extreme LEARNING MACHine (ELM)\",\n",
      "                            \"Expert Systems With Applications, 217 (2023) 119557. doi:10.1016/j.eswa.2023.119557\"\n",
      "                        ]\n",
      "                    }\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"@type\": \"schema:ResearchProject\",\n",
      "            \"schema:identifier\": \"96858@test\",\n",
      "            \"schema:publicKey\": \"964dbc74f346b43a17060e1c451b5fd50873d0a2fe69188f32b2f8dbab052cfa\",\n",
      "            \"schema:description\": {\n",
      "                \"@context\": {\n",
      "                    \"schema\": \"http://schema.org/\",\n",
      "                    \"dc\": \"http://purl.org/dc/terms/\"\n",
      "                },\n",
      "                \"@type\": \"schema:ResearchProject\",\n",
      "                \"schema:name\": \"Analyzing the Influence of gene therapy on urban resilience\",\n",
      "                \"dc:abstract\": \"This paper analyzes how gene therapy influences urban resilience, providing insights into how to maximize its climate resilience.\",\n",
      "                \"schema:keywords\": [\n",
      "                    \"gene therapy\",\n",
      "                    \"urban resilience\",\n",
      "                    \"climate resilience\"\n",
      "                ],\n",
      "                \"schema:startDate\": \"2018-04-08\",\n",
      "                \"schema:endDate\": \"2026-06-05\",\n",
      "                \"schema:funding\": {\n",
      "                    \"@type\": \"schema:Organization\",\n",
      "                    \"schema:name\": \"National Science Foundation\"\n",
      "                },\n",
      "                \"schema:location\": {\n",
      "                    \"@type\": \"schema:Place\",\n",
      "                    \"schema:name\": \"Phuket, Thailand\"\n",
      "                }\n",
      "            },\n",
      "            \"schema:metadataCID\": \"QmRgbWW7QFgTWTRQqmjDv7fX6YypV8absEUSXwiw8f1Pn6\"\n",
      "        },\n",
      "        {\n",
      "            \"@type\": \"schema:ResearchProject\",\n",
      "            \"schema:identifier\": \"37887@test\",\n",
      "            \"schema:publicKey\": \"64593fc6dc0eb621cc258ffb3b180a171bcccb225bfea253084600c768776432\",\n",
      "            \"schema:description\": {\n",
      "                \"@context\": {\n",
      "                    \"schema\": \"http://schema.org/\",\n",
      "                    \"dc\": \"http://purl.org/dc/terms/\"\n",
      "                },\n",
      "                \"@type\": \"schema:ResearchProject\",\n",
      "                \"schema:name\": \"Analyzing the Influence of bioinformatics on climate adaptation\",\n",
      "                \"dc:abstract\": \"This paper analyzes how bioinformatics influences climate adaptation, providing insights into how to maximize its scientific discovery.\",\n",
      "                \"schema:keywords\": [\n",
      "                    \"bioinformatics\",\n",
      "                    \"climate adaptation\",\n",
      "                    \"scientific discovery\"\n",
      "                ],\n",
      "                \"schema:startDate\": \"2021-01-20\",\n",
      "                \"schema:endDate\": \"2028-06-16\",\n",
      "                \"schema:funding\": {\n",
      "                    \"@type\": \"schema:Organization\",\n",
      "                    \"schema:name\": \"World Wildlife Fund\"\n",
      "                },\n",
      "                \"schema:location\": {\n",
      "                    \"@type\": \"schema:Place\",\n",
      "                    \"schema:name\": \"Tokyo, Japan\"\n",
      "                }\n",
      "            },\n",
      "            \"schema:metadataCID\": \"QmT1cPcYNcGntxCc2goVmkJuQG9EdVthjvG6SVNs7WCXc8\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "Checking project with ID: '06535@test' against '06535@test'\n",
      "Match found for project ID: 06535@test\n",
      "Updated project 06535@test with new file entry: {'file_index': 3, 'file_cid': 'QmZnh5Uuo7moZKMESFHpRjQFbbND5e3nArCzZg8uLARAgg', 'metadata_cid': 'QmZBwBxATjd85MZK9q6eSaX3tztcYbJzT34obDZmFKNE8K', 'metadata': {'dcterms:created': '2023-02-07T10:24:44Z', 'dcterms:modified': '2023-02-07T10:25:02Z', 'dc:format': 'application/pdf; version=1.7'}}\n",
      "Successfully wrote updated data to datasets/projects.json\n",
      "----------------------------------------\n",
      "{'pdf:unmappedUnicodeCharsPerPage': ['0', '0', '0'], 'pdf:PDFVersion': '1.7', 'xmp:CreatorTool': 'Elsevier', 'pdf:hasXFA': 'false', 'access_permission:modify_annotations': 'true', 'access_permission:can_print_degraded': 'true', 'X-TIKA:Parsed-By-Full-Set': ['org.apache.tika.parser.DefaultParser', 'org.apache.tika.parser.pdf.PDFParser'], 'X-TIKA:content_handler': 'ToTextContentHandler', 'pdf:num3DAnnotations': '0', 'dcterms:created': '2023-02-07T10:24:44Z', 'dcterms:modified': '2023-02-07T10:25:02Z', 'dc:format': 'application/pdf; version=1.7', 'xmpMM:DocumentID': 'xmp.id:88483799D0A6ED118966FC0221C82C06', 'pdf:docinfo:creator_tool': 'Elsevier', 'pdf:overallPercentageUnmappedUnicodeChars': '0.0', 'access_permission:fill_in_form': 'true', 'pdf:docinfo:modified': '2023-02-07T10:25:02Z', 'pdf:hasCollection': 'false', 'pdf:encrypted': 'false', 'pdf:containsNonEmbeddedFont': 'false', 'Content-Length': '142113', 'pdf:hasMarkedContent': 'true', 'Content-Type': 'application/pdf', 'pdf:producer': 'Adobe PDF Library 10.0.1', 'pdf:totalUnmappedUnicodeChars': '0', 'access_permission:extract_for_accessibility': 'true', 'access_permission:assemble_document': 'true', 'xmpTPg:NPages': '3', 'resourceName': \"b'Editorial-Board_2023_Expert-Systems-with-Applications.pdf'\", 'pdf:hasXMP': 'true', 'pdf:charsPerPage': ['7393', '5386', '2644'], 'access_permission:extract_content': 'true', 'access_permission:can_print': 'true', 'pdf:docinfo:trapped': 'False', 'X-TIKA:Parsed-By': ['org.apache.tika.parser.DefaultParser', 'org.apache.tika.parser.pdf.PDFParser'], 'X-TIKA:parse_time_millis': '51', 'X-TIKA:embedded_depth': '0', 'access_permission:can_modify': 'true', 'pdf:docinfo:producer': 'Adobe PDF Library 10.0.1', 'pdf:docinfo:created': '2023-02-07T10:24:44Z', 'pdf:containsDamagedFont': 'false'}\n",
      "{'metadata': {'pdf:PDFVersion': '1.7', 'xmp:CreatorTool': 'Elsevier', 'pdf:docinfo:title': 'COVID19-MLSF: A multi-task learning-based stock market forecasting framework during the COVID-19 pandemic', 'pdf:hasXFA': 'false', 'access_permission:can_print_degraded': 'true', 'X-TIKA:Parsed-By-Full-Set': ['org.apache.tika.parser.DefaultParser', 'org.apache.tika.parser.pdf.PDFParser'], 'X-TIKA:content_handler': 'ToTextContentHandler', 'pdf:num3DAnnotations': '0', 'dc:format': 'application/pdf; version=1.7', 'pdf:docinfo:custom:robots': 'noindex', 'pdf:docinfo:creator_tool': 'Elsevier', 'access_permission:fill_in_form': 'true', 'pdf:docinfo:custom:CreationDate--Text': '7th February 2023', 'pdf:hasCollection': 'false', 'pdf:encrypted': 'false', 'dc:title': 'COVID19-MLSF: A multi-task learning-based stock market forecasting framework during the COVID-19 pandemic', 'pdf:containsNonEmbeddedFont': 'false', 'xmp:CreateDate': '2023-02-04T09:40:15Z', 'pdf:docinfo:custom:CrossMarkDomains[1]': 'elsevier.com', 'robots': 'noindex', 'pdf:docinfo:subject': 'Expert Systems With Applications, 217 (2023) 119549. doi:10.1016/j.eswa.2023.119549', 'pdf:hasMarkedContent': 'false', 'xmp:ModifyDate': '2023-02-07T16:52:03Z', 'pdf:docinfo:creator': 'Chenxun Yuan', 'pdf:docinfo:custom:CrossmarkMajorVersionDate': '2010-04-23', 'access_permission:extract_for_accessibility': 'true', 'resourceName': \"b'COVID19-MLSF--A-multi-task-learning-based-stock-market_2023_Expert-Systems-w.pdf'\", 'pdf:docinfo:custom:CrossMarkDomains[2]': 'sciencedirect.com', 'X-TIKA:Parsed-By': ['org.apache.tika.parser.DefaultParser', 'org.apache.tika.parser.pdf.PDFParser'], 'ElsevierWebPDFSpecifications': '7.0', 'pdf:docinfo:custom:doi': '10.1016/j.eswa.2023.119549', 'pdf:docinfo:custom:CrossmarkDomainExclusive': 'true', 'X-TIKA:embedded_depth': '0', 'CrossmarkDomainExclusive': 'true', 'pdf:annotationTypes': 'null', 'pdf:docinfo:producer': 'Acrobat Distiller 8.1.0 (Windows)', 'pdf:annotationSubtypes': 'Link', 'CreationDate--Text': '7th February 2023', 'doi': '10.1016/j.eswa.2023.119549', 'pdf:containsDamagedFont': 'false', 'pdf:unmappedUnicodeCharsPerPage': ['0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0'], 'dc:description': 'Expert Systems With Applications, 217 (2023) 119549. doi:10.1016/j.eswa.2023.119549', 'access_permission:modify_annotations': 'true', 'dc:creator': ['Chenxun Yuan', 'Xiang Ma', 'Hua Wang', 'Caiming Zhang', 'Xuemei Li'], 'dcterms:created': '2023-02-04T09:40:15Z', 'dcterms:modified': '2023-02-07T16:52:03Z', 'xmpMM:DocumentID': 'uuid:1b499bed-4ce8-4c0c-b682-0d58baae1cbe', 'CrossMarkDomains[1]': 'elsevier.com', 'pdf:overallPercentageUnmappedUnicodeChars': '0.0', 'pdf:docinfo:keywords': 'Stock market forecasting,COVID-19 pandemic,Multi-task learning,Feature fusion,K-nearest neighbor classifier', 'pdf:docinfo:modified': '2023-02-07T16:52:03Z', 'Content-Length': '4016043', 'Content-Type': 'application/pdf', 'xmp:MetadataDate': '2023-02-07T16:52:03Z', 'dc:language': 'en-US', 'pdf:producer': 'Acrobat Distiller 8.1.0 (Windows)', 'dc:subject': ['Stock market forecasting,COVID-19 pandemic,Multi-task learning,Feature fusion,K-nearest neighbor classifier', 'Expert Systems With Applications, 217 (2023) 119549. doi:10.1016/j.eswa.2023.119549'], 'pdf:docinfo:custom:ElsevierWebPDFSpecifications': '7.0', 'pdf:totalUnmappedUnicodeChars': '0', 'access_permission:assemble_document': 'true', 'xmpTPg:NPages': '16', 'pdf:hasXMP': 'true', 'pdf:charsPerPage': ['4308', '4046', '7115', '4551', '3567', '6426', '1218', '6119', '1896', '4055', '3517', '5861', '730', '833', '5274', '6307'], 'access_permission:extract_content': 'true', 'access_permission:can_print': 'true', 'CrossMarkDomains[2]': 'sciencedirect.com', 'meta:keyword': 'Stock market forecasting,COVID-19 pandemic,Multi-task learning,Feature fusion,K-nearest neighbor classifier', 'X-TIKA:parse_time_millis': '95', 'access_permission:can_modify': 'true', 'pdf:docinfo:created': '2023-02-04T09:40:15Z', 'CrossmarkMajorVersionDate': '2010-04-23'}, 'content': '\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nCOVID19-MLSF: A multi-task learning-based stock market forecasting framework during the COVID-19 pandemic\\n\\n\\nExpert Systems With Applications 217 (2023) 119549\\n\\nA\\n0\\n\\nContents lists available at ScienceDirect\\n\\nExpert Systems With Applications\\n\\njournal homepage: www.elsevier.com/locate/eswa\\n\\nCOVID19-MLSF: A multi-task learning-based stock market forecasting\\nframework during the COVID-19 pandemic\\nChenxun Yuan a, Xiang Ma a, Hua Wang c, Caiming Zhang a,b, Xuemei Li a,\\n\\na School of Software, Shandong University, Jinan 250101, China\\nb Shandong Provincial Laboratory of Future Intelligence and Financial Engineering, Yantai 264005, China\\nc School of Information and Electrical Engineering, Ludong University, Yantai 264025, China\\n\\nA R T I C L E I N F O\\n\\nKeywords:\\nStock market forecasting\\nCOVID-19 pandemic\\nMulti-task learning\\nFeature fusion\\nK-nearest neighbor classifier\\n\\nA B S T R A C T\\n\\nThe sudden outbreak of COVID-19 has dramatically altered the state of the global economy, and the stock\\nmarket has become more volatile and even fallen sharply as a result of its negative impact, heightening\\ninvestors apprehension regarding the correlation between unexpected events and stock market volatility.\\nAdditionally, internal and external characteristics coexist in the stock market. Existing research has struggled\\nto extract more effective stock market features during the COVID-19 outbreak using a single time-series neural\\nnetwork model. This paper presents a framework for multitasking learning-based stock market forecasting\\n(COVID-19-MLSF), which can extract the internal and external features of the stock market and their\\nrelationships effectively during COVID-19.The innovation comprises three components: designing a new market\\nsentiment index (NMSI) and COVID-19 index to represent the external characteristics of the stock market\\nduring the COVID-19 pandemic. Besides, it introduces a multi-task learning framework to extract global and\\nlocal features of the stock market. Moreover, a temporal convolutional neural network with a multi-scale\\nattention mechanism is designed (MA-TCN) alongside a Multi-View Convolutional-Bidirectional Recurrent\\nNeural Network with Temporal Attention (MVCNN-BiLSTM-Att), adjusting the model to account for the\\nchanging status of COVID-19 and its impact on the stock market. Experiments indicate that our model achieves\\nsuperior performance both in terms of predicting the accuracy of the China CSI 300 Index during the COVID-19\\nperiod and in terms of sing market trading.\\n1. Introduction\\n\\nAs the stock market and artificial intelligence technology develop\\nrapidly, a new generation of quantitative trading tools on the basis of\\nmachine learning has performed well in stock prediction tasks (Giudici,\\nPolinesi, & Spelta, 2022; Ma, Zhao, Guo, Li, & Zhang, 2022; Shah,\\nBhatt, & Shah, 2022; Yan et al., 2020), and numerous quantitative stock\\ntrading researchers have gained huge profits from the stock market,\\nwhich is prospering. Besides, COVID-19 has had a huge impact on\\nthe stock market, and Fig. 1 demonstrates a time series chart of the\\nclosing prices of the five major global stock indexes from January 2019\\nto May 2020. Consequently, the global stock market has experienced\\na significant decline, as is evident. The poor handling mechanism of\\nmost stock market forecasting models for unforeseen events limits the\\npredictive power of the models during this period, which has prompted\\nthe investigation of stock market forecasting models that can handle\\nCOVID-19 pandemic events (Ronaghi, Salimibeni, Naderkhani, & Mo-\\nhammadi, 2022; tifani et al., 2020). Based on this, we conducted\\n\\n Corresponding author.\\nE-mail addresses: yuanchenxun@mail.sdu.edu.cn (C. Yuan), xiangma@mail.sdu.edu.cn (X. Ma), hua.wang@ldu.edu.cn (H. Wang), czhang@sdu.edu.cn\\n\\n(C. Zhang), xmli@sdu.edu.cn (X. Li).\\n\\nin-depth investigation on two major aspects, namely, finding more data\\nthat could reflect external stock market features and further enhancing\\nthe performance of the time-series forecasting model.\\n\\nIn accordance to the efficient market hypothesis theory (Fama,\\n1970), the stock prices have fully reflected all valuable and pertinent\\ninformation. And yet more research confirms the equal significance of\\ninformation external to the stock market, including national economic\\npolicies, investors investment sentiment, and the positive or negative\\neffect of news, which can have a lasting or temporary effect on stock\\nprices. Using stock prices and their derived technical indicators, and\\nincorporating sentiment analysis of news and stock reviews for fore-\\ncasting (Chen, Ma, Wang, Li, & Zhang, 2022; Jing, Wu, & Wang, 2021;\\nZhang et al., 2018), methods have been developed to quantify investor\\nsentiment or news information.Despite being effective for stock market\\nforecasting, these methods are not satisfactory due to the relatively\\nhomogeneous stock price information, the vast amount of information\\nvailable online 16 January 2023\\n957-4174/ 2023 Elsevier Ltd. All rights reserved.\\n\\nhttps://doi.org/10.1016/j.eswa.2023.119549\\nReceived 29 July 2022; Received in revised form 24 December 2022; Accepted 11\\n January 2023\\n\\nhttps://www.elsevier.com/locate/eswa\\nhttp://www.elsevier.com/locate/eswa\\nmailto:yuanchenxun@mail.sdu.edu.cn\\nmailto:xiangma@mail.sdu.edu.cn\\nmailto:hua.wang@ldu.edu.cn\\nmailto:czhang@sdu.edu.cn\\nmailto:xmli@sdu.edu.cn\\nhttps://doi.org/10.1016/j.eswa.2023.119549\\nhttps://doi.org/10.1016/j.eswa.2023.119549\\nhttp://crossmark.crossref.org/dialog/?doi=10.1016/j.eswa.2023.119549&domain=pdf\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 1. Time-series chart of the closing prices of the five major global stock indexes between 2019.01 and 2020.05 (The closing price is normalized to the maximum and minimum).\\navailable in textual information, and the fact that most of the textual\\ninformation contains personal subjective opinions and with varying\\nquality. This is particularly true during unpredictable occurrences such\\nas the COVID-19 pandemic. Ahelegbey, Cerchiello, and Scaramozzino\\n(2022) have confirmed in recent literature that COVID-19 can sig-\\nnificantly affect financial markets, and using multi-characteristic data\\n(such as market and sentiment data) to study the impact of COVID-19\\non different industries, provides more effective evidence for studying\\nthe impact of COVID-19 on the stock market. In some studies, Twitter\\ncomments during COVID-19 (Ronaghi et al., 2022) and confirmed\\nCOVID-19 cases (tifani et al., 2020) have been employed to predict\\nthe stock market with positive results. Nonetheless, the polarity of\\nthe sentiment of Twitter comments is challenging to determine, either\\nthrough manual annotation or natural language processing models.\\nFurthermore, since different textual data, namely, news and stock re-\\nviews are intermingled with the stock markets short-term or long-term\\neffects, it is difficult to classify and analyze the text data information.\\nConsequently, we must identify other predictability-enhancing charac-\\nteristics that are more efficient. It has been confirmed in some literature\\nthat Chinese stock market has features such as fast response to national\\npolicy regulations and parallel socioeconomic development with stock\\nmarket (Los & Yu, 2008; Wang, 2010), therefore, macroeconomic data\\ndoes have a longer-term impact on the stock market and can reflect\\nthe long-term market trend in advance, in comparison with stock\\ncommentaries or textual information. Additionally, due to the decrease\\nin COVID-19 lethality, the growing number of cured cases, as well\\nas the gradual development of new foreign trade policies in distinct\\ncountries, which have substantially aided the economic recovery it has\\nbecome tough to reflect the development status of COVID-19 and the\\nimpact on the stock market employing only COVID-19 confirmed cases.\\nIn accordance to our study, the number of cured COVID-19 cases, the\\nsearch volume of the epidemic in Baidus index, and the media informa-\\ntion statistics all reflect COVID-19s changing status to distinct degrees.\\n2\\n\\nThus, we can utilize principal component analysis to downscale the\\naforementioned indicators and investigate the mechanism and mode of\\ninfluence of an unexpected event including such COVID-19 on stock\\nprice fluctuations.\\n\\nOn the other hand, time-series prediction models including re-\\ncurrent neural networks represented by long and short-term mem-\\nory neural networks (Hochreiter & Schmidhuber, 1997), gated re-\\ncurrent units (Cho et al., 2014), and temporal convolutional neural\\nnetworks (Bai, Kolter, & Koltun, 2018) have become acknowledged as\\nsuperior deep learning models in time-series analysis (Yan et al., 2020).\\nNonetheless, Recent studies have indicated that it has been challenging\\nto extract more effective data with the aid of RNNs (Rezaei, Faaljou, &\\nMansourfar, 2021; Yan et al., 2020). Although the causal convolution\\nstructure proposed by TCN alleviates the issue arising from RNN, the\\ntraditional TCN is insensitive to the essential information in long time\\nseries. Additionally, this class of single-task prediction models lacks\\nhigh-quality feature learning capabilities when dealing with nonlinear,\\nhighly noisy stock price series, particularly on the condition that there\\nare multiple input sources and they may overlap more noise in the\\ndata, increasing the highly noisy nature of the data (Ko et al., 2021).\\nThe framework for multitask learning is an effective solution. Multi-\\ntask learning refers to learning multiple related tasks at the same\\ntime, allowing these tasks to share knowledge in the learning process,\\nand applying the correlation between multiple tasks to enhance the\\nperformance and generalization ability of the model in the task, which\\ncan serve a limited data enhancement function, and has been widely\\nadopted and demonstrated excellent results in natural language pro-\\ncessing (Collobert & Weston, 2008), computer vision (Girshick, 2015).\\nExisting applications of multi-task learning in the stock market (Li,\\nSong, & Tao, 2019; Ma & Tan, 2020, 2022; Zhang, Wu, & Li, 2022)\\nhave also largely enhanced the feature extraction capability of the\\nmodels, and yet some current work (Li et al., 2019; Ma & Tan, 2020;\\nMootha, Sridhar, Seetharaman, & Chitrakala, 2020; Zhang et al., 2022)\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nonly learns the stock price series to varying degrees. Consequently,\\nthe extracted individual features cannot adequately describe the state\\nof the stock market. Many factors affect the rise and fall of stocks,\\nand these factors usually do not exist in isolation, and stock prices\\nare formed in such intertwined effects, which causes the multi-source\\nnature of stock data, and the predominant advantage of multi-task\\nlearning, especially multi-task learning framework on the basis of soft\\nsharing mechanism (Ma & Tan, 2022) is the capacity to learn diverse\\ndata sources by completing a variety of subtasks.\\n\\nFor the purpose of coping with the impact of stock price fluctuations\\ncaused by emergencies such as COVID-19 on stock market forecasting\\nmodels. This paper uses the principal component analysis method to\\nconstruct a New Market Sentiment Index (NMSI) owing to macroeco-\\nnomic data and a COVID-19 index reflecting the development status\\nof COVID-19 in China to characterize the external feature of the stock\\nmarket in times of emergencies. We subsequently propose a multi-\\ntask learning-based forecasting model for COVID-19-MLSF, and the\\nmodel framework is indicated in Fig. 2. In this model, we introduced\\nthe framework of multi-task learning and establish two forecasting\\nsubtasks whilst also combining the constructed external features of\\nthe stock market (NMSI and COVID-19 Index) with the low-frequency\\nand high-frequency signals decomposed by stock price correspondingly.\\nBesides, the subtasks extract global and local features of the stock\\nprice series, thereby effectively solving the problem of tough feature\\nextraction and miscellaneous internal features of the stock price series.\\nDue to the fact that multi-task learning reduces the impact of local\\nparameters on the global and reduces overfitting of the main task, the\\nmain tasks predictive ability is significantly enhanced. In addition, this\\npaper adds attention mechanisms to dissimilar causal convolutional\\nlayers of TCNs, and the newly designed temporal convolutional neural\\nnetwork (MA-TCN) with multi-scale attention mechanism makes TCNs\\nmore sensitive to important features. Moreover, to address the issue\\nthat recurrent neural networks have a propensity to forget sequence\\nfeatures, this paper proposes a convolutional-bi-directional recurrent\\ncombining multiview convolutional neural network and temporal at-\\ntention mechanism(MVCNN-BiLSTM-Att). In comparison with a single\\nrecurrent neural network, the feature extraction and memory capabili-\\nties of the network are improved. Experiments further reveal that our\\nmodel accomplishes superior performance in predicting the China CSI\\n300 index and high returns on the bear market state during COVID-19.\\n\\nThe following are the major contributions of this paper:\\n\\n A new market sentiment index (NMSI) and COVID-19 index are\\nconstructed to reflect the external features of the stock market,\\nintroducing a novel method for studying the effects of unforeseen\\nevents, namely, COVID-19 on stock price volatility.\\n\\n Multitask learning forecasting framework is designed to handle\\nmultiple data sources of the stock market. Moreover, the decom-\\nposed stock price series and the constructed external features of\\nthe stock market are established as separate prediction subtasks,\\nwhich alleviate the issue of complex features mingling in stock\\nprice data and likewise enhance the ability to make the neural\\nnetwork feature extraction module more capable of extracting\\neffective features.\\n\\n Design a Multi-scale attention mechanism temporal convolu-\\ntional neural network (MA-TCN), which effectively solves the\\ntraditional TCNs insensitivity to long sequences of significant\\ninformation and thus calculates the weight parameters of distinct\\nfeature information better. Furthermore, design a multi-view\\nconvolutional-bi-directional recurrent neural network (MVCNN-\\nBiLSTM-Att) to model how the COVID-19 state affects stock\\nmarket volatility.\\n\\nThe remaining sections are organized as follows: Section 2 reviews\\nsome literature and novel methods related to this paper. Subsequently,\\nSection 3 describes how the Market Sentiment Index (NMSI) and the\\n3\\n\\nCOVID-19 Index are constructed. Section 4 presents the three task\\nmodules of the COVID-19-MLSF. Except for that, Section 5 presents ex-\\nperimental demonstrations, including comparison and ablation experi-\\nments as well as hyperparametric sensitivity tests. Ultimately, Section 6\\nconcludes the entire paper and suggests future works.\\n\\n2. Review of literature\\n\\nIn the last decade, stock market forecasting has gained a great deal\\nof attention from financiers and computer scientists due to its unique\\nfeatures and wide range of potential applications.\\n\\n2.1. Prediction based on machine learning and multi-task learning\\n\\nRecurrent neural networks (RNNs) and their derivatives, long and\\nshort-term memory neural networks (LSTMs) and memory recurrent\\nunits (GRUs), have been proposed as alternative methods for extracting\\nnonlinearity from stock price series in traditional time series mod-\\nels (Fu, Zhang, & Li, 2016; Hochreiter & Schmidhuber, 1997). In spite of\\nthis, these mentioned networks has serious problems, such as gradient\\ndisappearance and explosion, which adversely affect stock predictions\\nfor long time series. Bi-directional recurrent neural networks (Bi-RNN),\\nsuch as the bi-directional long-term memory networks (Bi-LSTM), are\\nbetter suited to predicting long- and short-term trends in stock data\\nsince they can capture information about both the past and future of the\\ndata (Althelaya, El-Alfy, & Mohammed, 2018; Siami-Namini, Tavakoli,\\n& Namin, 2019; Yang & Wang, 2022). In addition to recurrent neural\\nnetworks, temporal convolutional neural networks (TCNs) have been\\nshown to outperform RNNs in a number of tasks (Bai et al., 2018;\\nCheng et al., 2021; Dai, An, & Long, 2022). However, TCNs are neither\\nsensitive to the important information contained in the sequences nor\\nto effectively extract it. The attention mechanism give new solution\\nof the problem of feature attention in long-term sequences. Base on\\nthis process, recurrent neural networks incorporating the attention\\nmechanism are widely used to predict stock prices. An example would\\nbe the two-stage attention recurrent neural network model (DA-RNN)\\nproposed by Qin et al. (2017). This model through input attention\\nmechanism to capture spatial features, while temporal features, and get\\nbetter results of NASDAQ prediction.\\n\\nIt is common for researchers to resolve the time series data before\\ninputting the model using the signal decomposition method (Lah-\\nmiri, 2016a; Lin, Lin, & Cao, 2021; Ma, Li, Zhou, & Zhang, 2021;\\nRezaei et al., 2021; Yan et al., 2020), with representative methods\\nincluding Fourier transform (FT), wavelet transform (WT), empirical\\nmode decomposition (EMD), ensemble empirical mode decomposition\\n(EEMD), variable mode decomposition (VMD), etc. By decomposing\\nthe complex and high-noise financial time series into semaphores of\\ndifferent frequencies, it is possible to achieve a faster convergence\\nduring deep neural network learning and avoid overfitting. What is\\nmore, it is possible to separate the different valid information in the\\nstock sequence. Nevertheless, the decomposition methods used in the\\naforementioned literatures need to decompose all data once, which\\nmeans there may be leakage of future data, so that the prediction\\nresults will be prospectively biased. Liu, Ma, Li, Li, and Zhang (2022)\\ndecomposed the data selected through the sliding window in order to\\nsolve the problem of future data leaks, and stock price data used in this\\npaper were also decomposed in this manner.\\n\\nWith the development of deep learning, deep multitasking learning\\nhas become one of the important subfields. Multi-task learning is to\\nshare the features extracted from different tasks by performing multiple\\nprediction tasks at the same time. Multi-task learning not only has bet-\\nter feature extraction ability than a single model, but also has stronger\\ngeneralization ability, and has been widely used in the prediction of\\nstock data (Li et al., 2019; Ma & Tan, 2020, 2022; Zhang et al., 2022).\\nMa and Tan (2020) added attention mechanism to multitask learning\\n\\nto learn shared and private features from different tasks, and Zhang\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 2. COVID19-MLSF Framework.\\net al. (2022) proposed an online multitask learning method with OMTL-\\nLSSVR, which innovatively introduced online learning into multitask\\nlearning and significantly improved the prediction accuracy of the\\ncurrent task with continuously updated data. Nevertheless, entering\\nthe sequence of stock price into different neural network models and\\nextracting features is the essence of the work. Then we complete the\\nprediction after exchange these features. Because the use of stock\\nprice series only may result in similar features being extracted across\\ndifferent tasks, does not fully utilize the advantages of the multitask\\nlearning framework in handling multi-source data.\\n\\n2.2. Prediction based on multiple features of the stock market\\n\\nAs the stock market becomes more prosperous, researchers are\\nlooking for more features to assist in market forecasting. It is easiest\\nto use technical indicators, such as MA, MACD, RSI, etc., derived\\nfrom stock prices, to assist in stock forecasting. These indicators are\\nwidely used because they can reflect long and short-term trends as well\\nas phenomena such as overbought and oversold conditions (Agrawal,\\nKhan, & Shukla, 2019; Gao & Chai, 2018). To alleviate the delaying\\nprediction causing by single stock data, Baker and Wurgler (2006,\\n2007) used other data, such as macroeconomic data, to construct the\\nBW sentiment indicators which reflect external information about the\\nstock market. Additionally, multi-feature fusion forecasting is primarily\\nbased on news and investor sentiment; Jing et al. (2021) used stock\\nforum text data from Oriental Fortune for sentiment analysis and CNN\\nmodel for classification through Chinese sentiment corpus (ChnSen-\\ntiCorp), combined with stock technical indicator information, then\\nfinally predicted by LSTM network, and obtained a low mean absolute\\npercentage error; Zhang et al. (2018) performed a detailed analysis of\\nthe historical comments of experts in stock reviews and proposed a\\nstrategy to find a good stock reviewer by combining the trend of stock\\nprice changes and the opinion polarity (i.e., bullish or bearish) of stock\\nreviewers to obtain high return returns in a backtest experiment. Hu,\\nLiu, Bian, Liu, and Liu (2018) used economic news data to link specific\\nstocks to news constructed a daily stock news corpus by linking it\\nwith stock price information, and then added stock price information\\nto design a HAN hybrid network (a two-way GRU network incorpo-\\nrating Attention), which significantly improved annualized returns in\\nreal stock market simulations; with the negative impact of COVID-\\n19 globally, some researchers have combined different perspectives\\non the COVID-19 and stock market linkages (Ronaghi et al., 2022;\\ntifani et al., 2020). Ronaghi et al. (2022) extracted relevant data\\n4\\n\\nabout COVID-19 from Twitter comments to build a COVID19-PRIMO\\nTwitter dataset and then had stock prices for prediction, achieving a\\nhigh accuracy rate. In order to effectively avoid the problem of data\\ndimensional disaster, principal component analysis, as an important\\ndimensionality reduction method in the data preprocessing stage, has\\nshown good effectiveness in stock market prediction (Chen & Hao,\\n2018; Yan et al., 2020; Yue, Zhou, & Yuan, 2021; Zheng & He, 2021).\\n\\n3. Prepare work\\n\\nThis section describes how Chinas Market Sentiment Index (NMSI)\\nand COVID-19 Index are constructed, showing their relationship with\\nthe CSI 300 Index. The variational modal sliding window decomposi-\\ntion method used in the data pre-processing stage is also introduced.\\n\\n3.1. New market sentiment index\\n\\nAs for choosing the original data used to construct the market\\nsentiment index, in order to make the index highly similar(Pearson\\ncorrelation coefficient)to CSI 300 (Gong, Zhang, Wang, & Wang, 2022;\\nYi & Mao, 2009), by continuously updating different basic data and\\ncalculating the similarity, 11 groups of basic data are selected as the\\nbasic data to create the index. Using neural networks to deal with\\nthem directly will result in redundancy of information. Therefore, we\\nreduced dimensionality using principal component analysis. There is no\\nneed to denoise the raw data and remove outliers before doing so. This\\nis due to the fact that these data are actual daily changes in market\\nconditions and COVID-19. Noise reduction, particularly removing out-\\nliers, will decrease the correlation between the constructed index and\\nthe CSI 300 Index. Below is a brief description of what they mean.\\n\\nFund Discount Rate (DCEF): The extent to which the market price\\nof a closed-end fund is below the net asset value.\\n\\nNumber of Initial Public Offerings (NIPO): The first time a com-\\npany sells its shares to the public.\\n\\nRevenue on the first day of IPO (RIPO): The yield on the first day\\na company sells its shares to the public for the first time.\\n\\nNumber of New Accounts (NA): The number of new natural\\npersons investing, i.e. the number of new stockholders per month.\\n\\nNumber of New Investors (NewInvestors): The number of in-\\nvestors at the end of the current period minus the number of investors\\nat the end of the previous period (the number of investors at the end\\nof the period refers to the number of one-code accounts holding un-\\ncancelled, dormant A shares, B shares, credit accounts, and derivative\\ncontract accounts)\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 3. NMSI and CSI 300 Trends.\\nConsumer Confidence Index (CCI): An indicator of the strength\\nof consumer confidence, a comprehensive reflection and quantification\\nof consumers evaluation of the current economic situation and their\\nsubjective feelings about the economic outlook, income levels, income\\nexpectations and the psychological state of consumption, and a leading\\nindicator for forecasting economic trends and consumption tendencies.\\n\\nConsumer Price Index (CPI): It is a relative number reflecting the\\ntrend and degree of price changes of consumer goods and services\\npurchased by urban and rural residents during a certain period of time.\\n\\nInvestor Confidence Index (ICI): The change in investment psy-\\nchology and expectations of investors in the securities market under\\nthe current economic and market environment.\\n\\nSocial Financing Scale (AFRE): Social financing scale refers to\\nthe total amount of all funds obtained by the real economy from the\\nfinancial system in a certain period of time. It reflects the relationship\\nbetween finance and economy, as well as the aggregate indicator of\\nfinancial support to the real economy.\\n\\nTurnover Rate: It refers to the frequency of stocks changing hands\\nin the market within a certain period of time, and is one of the\\nindicators reflecting the strength of stock liquidity.\\n\\nPE ratio: PE ratio is the ratio of stock price divided by earnings per\\nshare, and can be used as one of the indicators to assess whether the\\nstock price level is reasonable.\\n\\nFor the above 11 indicators, most of them only provide monthly\\ndata because macroeconomic data indicators such as consumer confi-\\ndence index and social financing scale are a level value to reflect a\\ncertain aspect of society in the current period, and their daily data have\\nno specific reference significance. For a better correspondence with\\nother daily data such as turnover rate and P/E ratio, and to facilitate the\\ndimensionality reduction process, we first transform the monthly data\\ninto daily data using linear interpolation and eliminate non-trading\\ndays data to ensure the overall trend of data distribution remained\\nunchanged and achieve the data dimensionality correspondence. Here,\\nwe obtain the raw data matrix  of the market sentiment index (where\\n,  ...  represent the 11 raw data and m denotes the number of rows),\\nas shown in Eq. (1).\\n\\n =\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nX1 Y1 Z1\\nX2 Y2  Z2\\n\\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n(1)\\n5\\n\\n\\n\\nX Y  Z \\nAmong the many indicators mentioned above, there are many mi-\\ncro and macro factors that affect the stock market, which are not\\nindependent of each other. The use of neural network directly will\\ncause information redundancy, so we use principal component analysis\\nto reduce the dimensions. The specific steps are as follows. First,\\nthe original data matrix  is normalized using Eq. (2) to obtain the\\nnormalization matrix .\\n\\n =\\n  \\n\\n\\n,  = 1, 2, , ;  = 1, 2, ,  (2)\\n\\nwhere  denotes the number of columns,  denotes the data matrix\\n values, and  ,  denote the mean and standard deviation of each\\ncomponent .\\n\\nThen the initial eigenvalues of the matrix Z were extracted using\\nEq. (3).\\n|\\n\\n|\\n\\n|\\n\\n  \\n|\\n\\n|\\n\\n|\\n\\n= 0 (3)\\n\\nwhere  denotes the correlation coefficient matrix of matrix , and \\neigenvalues  are obtained. The principal components with eigenval-\\nues greater than 1 are selected, and the score coefficient matrix A (\\nis the number of principal components with eigenvalues greater than 1)\\nand each principal component value  are calculated for the original\\ndata, and then the final new market sentiment index (NMSI)  is\\ncalculated.\\n\\nA = U \\n\\n\\n (4)\\n\\n =\\n\\n\\n(\\n\\nA  \\n)\\n\\n(5)\\n\\n =\\n\\n\\n(\\n\\n  \\n)\\n\\n(6)\\n\\nwhere U is the loading of the principal component,  represents\\nthe eigenvalue corresponding to each principal component,  repre-\\nsents the th principal component, and  represents the eigenvalue\\ncorresponding to the th principal component.\\n\\nFig. 3 illustrates the relationship between our constructed New\\nMarket Sentiment Index (NMSI) and the CSI 300 Index, and it can be\\nobserved that the trend of the constructed Market Sentiment Index is\\nbasically in line with the trend of the CSI 300 Index. In particular, the\\nNMSI can reflect the trend of the CSI 300 index in advance, such as at\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\n\\nd\\ns\\nc\\nw\\nb\\nb\\ne\\n\\n3\\n\\no\\nw\\n1\\nc\\nw\\no\\nc\\na\\na\\no\\ns\\nt\\ni\\nm\\nS\\ng\\no\\nt\\n1\\nt\\nt\\nd\\nt\\n5\\ni\\n4\\nt\\nm\\n\\nc\\nF\\nt\\nc\\n2\\ns\\nt\\nm\\n\\na\\nh\\nt\\nt\\nt\\ns\\n3\\nC\\n\\n(\\n\\ns\\nf\\n\\nthe beginning of March 2019, after the market sentiment index made a\\nsignificant decline, while the CSI 300 index made a decline only in early\\nApril; between AprilJuly 2020, the market sentiment index also rises\\nahead of the broad market index. We calculated the Pearson correlation\\ncoefficient of NMSI with CSI 300 using Eq. (7).\\n\\n =\\n\\n\\n=1\\n(\\n\\n  \\n) (\\n\\n  \\n)\\n\\n\\n\\n\\n=1\\n\\n(\\n\\n  \\n)2\\n\\n\\n\\n=1\\n\\n(\\n\\n  \\n)2\\n\\n(7)\\n\\nwhere  and  denote the series values of NMSI and CSI 300, , \\nenote the mean values of NMSI and CSI 300 series data, and  is the\\neries length of both. the calculation results are in Table 1, and the\\norrelation coefficients of both reach the value of strong correlation,\\nhich confirms that the constructed NMSI can reflect the trend of the\\nroad stock market index well. NMSI does not use the stock price data,\\nut can reflect the overall market trend, so NMSI is an important global\\nxternal feature of the stock market.\\n\\n.2. COVID-19 index\\n\\nAlthough the COVID-19 confirmed case data can reflect the changes\\nf COVID-19, it still reflects the status of COVID-19 in an incomplete\\nay. The data used to construct the COVID-19 Index are daily COVID-\\n9 confirmed cases, new deaths, new cures, cumulative confirmed\\nases, cumulative deaths, cumulative cures, and the number of key-\\nords epidemic in Baidu search and Baidu information in China. By\\nbserving the changes of COVID-19 and stock market related data and\\nombining with news reports, we further summarize the mechanism\\nnd influence of COVID-19 on the stock market. According to our\\nnalysis, when the number of confirmed cases and deaths and the topic\\nf COVID-19 in online information increases, investors investment\\nentiment is pessimistic, and the stock market will decline; When\\nhe topic of COVID-19 decreases and the number of cured cases\\nncreases, investors investment sentiment is optimistic, and the stock\\narket will rise. Data also supports the above viewpoint, such as the\\n\\nhanghai and Shenzhen 300 index rose nearly 5.8% after the Chinese\\novernment announced the free universal and widespread vaccination\\nf the new crown vaccine on December 31, 2020. Another example is\\nhe World Health Organization (WHO) named the Omicron COVID-\\n9 variant in November 2021 and confirmed a significant increase in\\nhe transmissibility of COVID-19, major stock markets in Europe and\\nhe US fell across the board, with all three major US stock indexes\\nown more than 2%. Among them, the Dow Jones (DJI) fell 2.53%,\\nhe biggest drop of the year, while the Nasdaq (IXIC) and the S&P\\n00 (S&P500) fell 2.23% and 2.27%, respectively. In Europe, the major\\nndexes also suffered heavy losses, with Germanys DAX closing down\\n.15%, the largest one-day drop since 2021, and Frances CAC 40 and\\nhe UKs FTSE 100 down 4.75% and 3.64%, respectively; in the Chinese\\narket, the CSI 300 index fell 1.41% and the SSE index fell 1.47%.\\n\\nFurther, we use data on stock price volatility to more visually\\nonfirm the impact of COVID-19 on the stock market. As shown in\\nig. 4, the relationship between monthly volatility and COVID-19 for\\nhe CSI 300 index for 20192021 is demonstrated. When there are\\noncentrated outbreaks of COVID-19, such as between FebruaryMarch\\n020, February 2021 and JulyAugust 2021, stock market volatility is\\nignificantly high in that month or adjacent months, indicating that\\nhe occurrence of COVID-19 exacerbates the volatile state of the stock\\narket.\\n\\nThe method and procedure for constructing the COVID-19 Index\\nre consistent with Section 3.1, and we omit the construction process\\nere. For subsequent integration with the stock price series features,\\nhe COVID-19 Index for the period when COVID-19 did not occur is set\\no 0. In this way, the COVID-19 Index is expanded to a sequence  of\\nhe same length as the original stock price series. Fig. 5 shows the time\\neries relationship plot of the constructed COVID-19 Index with the CSI\\n00 Index, and Table 1 shows the Pearson correlation coefficients of\\n6\\n\\nOVID-19 Index and CSI 300 Index.\\nTable 1\\nCorrelation coefficients of NMSI, COVID-19 Index and CSI 300.\\n\\nPearson correlation coefficient\\n\\nNMSI-CSI 300 0.864\\nCOVID-19 Index-CSI 300 0.560\\n\\nIn Fig. 5, we observe that the trend of the whole epidemic changes\\nfrom high to low, from a large national epidemic to a local epidemic,\\nsuch as the epidemic in Shijiazhuang, Hebei Province in January 2021\\nand the epidemic in Nanjing Lukou International Airport in August\\n2021 are clearly reflected in the COVID-19 Index, indicating that\\nthe constructed COVID-19 Index can accurately describe the changes\\nof the epidemic in China. In addition, the correlation coefficients in\\nTable 1 also show that the COVID-19 Index has a significant negative\\ncorrelation with the CSI 300 Index, indicating that the COVID-19 plays\\na certain inhibitory role on the development of the stock market.\\nchanges in the COVID-19 Index can cause short-term fluctuations in the\\nstock market and can be used as a local feature external to the stock\\nmarket, so we can use the COVID-19 19 Indexs valid information for\\nthe study of short-term stock market volatility and reduce the impact\\nof COVID-19 on stock market forecasting models.\\n\\n3.3. Sliding window-VMD\\n\\nVariational modal sliding window decomposition is used to de-\\ncompose the stock price series with different frequency components.\\nNumerous studies (Lahmiri, 2016b; Wu & Lin, 2019) have shown that\\nvariational modal decomposition (VMD) solves the serious endpoint\\neffects and modal component mixing problems that occur in empirical\\nmodal decomposition, and has been widely used in biomedical signal\\nprocessing (Lahmiri, 2014), time series prediction (Lahmiri, 2016b),\\nmechanical fault diagnosis (Li, Liu, Wu, & Chen, 2020), and other\\nfields. Due to the non-recursive signal processing method, VMD can\\ndetermine the number of mode decompositions according to the actual\\nsituation. Therefore, VMD is used to decompose the stock series into\\nlow-frequency and high-frequency signal sequences by adjusting to the\\nmost appropriate number of decompositions.\\n\\nFor the VMD decomposition algorithm, the essence of the decompo-\\nsition process is the variational problem. The existing VMD decompo-\\nsition method decomposes the stock sequence () =\\n\\n[\\n\\n1, 2, 3  \\n]\\n\\n.\\n\\nmin\\n ,)\\n\\n{ \\n\\n\\n=1\\n\\n\\n\\n\\n\\n\\n\\n\\n[\\n\\n(() + )  ()\\n]\\n\\n\\n\\n\\n\\n\\n2\\n\\n2\\n\\n}\\n\\n\\n\\n\\n=1\\n = ()\\n\\n(8)\\n\\nwhere  denotes each moment of the sequence, () is the original\\nequence of stock prices,  is the number of modes, () is the Dirichlet\\nunction,  denotes the convolution,  =\\n\\n\\n\\n1, and  is the partial\\nderivative. After decomposition,  discrete modes are obtained, and\\nthe component of each mode  is , and each  is concentrated\\naround the center frequency  of each eigenmodal function compo-\\nnent. The components thus decomposed are a set of vector values;\\nfor example, the decomposition yields a low-frequency sequence that\\ncan be expressed as =1 =\\n\\n[\\n\\n1, 2, 3 \\n]\\n\\n. To better illustrate this,\\nthe first three values 1, 2, 3 of the stock price series X are now\\ndecomposed to obtain the low-frequency series  1\\n\\n=1 =\\n[\\n\\n1\\n1, \\n\\n1\\n2, \\n\\n1\\n3\\n]\\n\\n,\\nand obviously, the first three values of =1 and  1\\n\\n=1 are not equal,\\nindicating that =1 This set of components is obtained based on the\\ndecomposition of the whole sequence of . The local values of =1 still\\ncontain some information of the whole sequence. Therefore, using =1\\ndirectly in the subsequent input to the neural network for prediction\\nwill result in future data leakage, causing the model to use the future\\ndata within the sliding window, resulting in forward-looking bias in the\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 4. CSI 300 20192021 Monthly Share Price Volatility and COVID-19 Relationship.\\nFig. 5. COVID-19 Index and CSI 300 Trends.\\nmodel prediction, which cannot be decomposed in this way in practical\\napplications.\\n\\nThe input stock price series is first sliding-window chunked, and\\nthen the series 1, 2, 3, ,  is obtained after decomposing the\\ndata in each window of () using Eq. (8).\\n\\nAfter the variational modal sliding window decomposition method,\\nthe low-frequency and high-frequency signal series are obtained.\\nAmong them, the high-frequency signal series reflect the short-term\\nfluctuation features within the stock market due to the extraction of\\nthe sudden upward and downward trend of the stock price series; the\\n7\\n\\nlow-frequency signal series reflect the long-term trend features within\\nthe stock market due to the extraction of the overall trend of the stock\\nprice series.\\n\\nStock price technical indicators are obtained from historical stock\\nprice series based on certain statistical methods, using certain math-\\nematical formulas or quantitative models. They are a review of the\\nhistorical market and can help us to a certain extent to make certain\\npredictions about the future market. Since technical indicators such as\\nMA, MACD, etc., are calculated based on historical stock prices over\\nmany consecutive days, they are essentially a smoothing of multi-day\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\n\\nt\\nt\\n\\n3\\n\\nm\\ne\\nt\\nf\\nm\\nh\\nc\\nt\\nt\\nc\\nl\\na\\nc\\nM\\ng\\nc\\np\\ns\\nc\\na\\ns\\n\\nTable 2\\nCorrelation show among technical indicators.\\n\\nMA MACD RSI\\n\\nMA 1  \\nMACD 0.11 1 \\nRSI 0.00 0.51 1\\n\\nstock price data, reflecting the medium and long-term trend features\\nwithin the stock market. In Table 2, we show the Pearson correlation\\ncoefficients for the three types of technical indicators included in\\nformula (9). These three indicators have low correlations, or even no\\ncorrelations at all, such as MA and RSI, etc.\\n\\n =\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nMA5 1 MA15 1 RSI 1\\nMA5 2 MA15 2  RSI 2\\n\\n  \\n5 MA15   RSI \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n(9)\\n\\nAmong them, the details of the indicators used are follow:\\nMoving Average(MA):The moving averages of different time win-\\n\\ndows can reflect the medium and long-term trend features of stock\\nprices.\\n\\nKDJ:Stochastic indicator. By calculating the proportional relation-\\nship between the highest price, the lowest price and the closing price of\\nthe last trading day that have occurred in a cycle, and then calculate the\\nK value, D value and J value respectively, and draw a curve to reflect\\nstock movement.\\n\\nConvergence and Difference Moving Average(MACD): The dis-\\npersion and aggregation of the fast and slow moving averages represent\\nthe current market state and stock price trend.\\n\\nRelative Strength Indicator(RSI): It is calculated based on the\\nratio of the rise and fall in a cycle, and reflects the degree of prosperity\\nof the market in a certain period.\\n\\nUp to this point, we have obtained multiple dimensional feature\\nsequences for a stock, which are the low and high frequency sequences\\n1, 2, 3, ,  of the decomposition of the stock price series, the\\nmarket sentiment indicator sequence , the COVID-19 Index  and\\nhe stock price technical indicator sequence , as input data for the\\nwo subtask modules in the multi-task learning.\\n\\n.4. Summary\\n\\nThe non-stationary signal is decomposed using the decomposition\\nethod, and the relevant frequency signal is selected for analysis to\\n\\nxtract the corresponding features. This paper uses the VMD method\\no decompose stock price series into low-frequency signals and high-\\nrequency signals. According to the theory of VMD decomposition\\nethod, the low-frequency signal reflects the long-term trend, and the\\nigh-frequency signal reflects the short-term fluctuations. From the\\nalculation methods of the market sentiment index(Section 3.1) and\\nechnical indicators, we can see that these two types of data are similar\\no low-frequency signals, reflecting the medium and long-term trend\\nharacteristics of stock price changes. We calculated the correlation of\\now-frequency signals, market sentiment index and technical indicators,\\ns shown in Table 3. The low-frequency signal has a large correlation\\noefficient with the market sentiment index and the technical indicator\\nA. It can be seen that it is feasible to combine the three to extract\\n\\nlobal features. In the same way, the daily COVID-19 index has a\\norresponding impact on the stock market, as the variables that com-\\nose it change daily. As an example, when COVID-19 cases increased\\nignificantly, the stock market fell significantly. Therefore, COVID-19\\nan be used as a data feature supplement for high-frequency signals,\\nnd the designed neural network can be used to extract the features of\\n8\\n\\ntock price and COVID-19 index.\\nTable 3\\nDemonstration of correlation.\\n\\nNMSI MA\\n\\nLow frequency signal 0.85 0.94\\n\\n4. Methodology\\n\\nThe COVID19-MLSF framework in this paper mainly consists of a\\nglobal feature extraction module (subtask 1), a local feature extraction\\nmodule (subtask 2), and a prediction result output module (main task).\\nThe global feature extraction module combines low-frequency signals,\\ntechnical indicators, and NMSI to produce a feature matrix that reflects\\nthe long-term trends in the stock market, and the long-term trend\\nfeatures of the stock market are extracted using a newly designed\\nmulti-scale attention mechanism of the temporal convolutional neural\\nnetwork (MA-TCN); The MA-TCN uses a multi-layered attention mech-\\nanism that makes the TCN more responsive to important features. In\\nthe local feature extraction module, the high-frequency signals that\\nreflect the short-term fluctuations of stock series and the constructed\\nCOVID-19 Index are jointly modeled to build a feature matrix that\\nreflects the short-term fluctuations of the stock market, and the short-\\nterm fluctuations in the stock market, and these short-term fluctuation\\nare extracted by our designed, multi-view convolutional-bidirectional\\nrecurrent neural network with temporal attention (MVCNN-BiLSTM-\\nAtt). The MVCNN-BiLSTM-Att employs multiple convolutional neural\\nnetworks with different sensory fields, and incorporates a temporal\\nattention mechanism in the recurrent neural network, which not only\\nenhances the local feature extraction capability of the model, but also\\nfocuses on capturing the impact of the changing COVID-19 state on\\nstock market volatility. In the above two modules, both TCN and\\nBiLSTM structures are non-parametric machine learning models, which\\nallow to combine continuous data (such as market data) with categor-\\nical ones(such as COVID-19 data). Finally, the features extracted from\\nthe two subtask modules and stock price sequences are fed into a KNN\\nmodel for stock market trend prediction.\\n\\n4.1. Subtasks1:Global feature extraction module\\n\\nIn the subtask 1 module, the low-frequency sequence 1, the\\nmarket sentiment indicator sequence  and the stock price technical\\nindicator sequence  3-dimensional feature sequence obtained by\\ndecomposing the stock price sequence, their combination forms a multi-\\ndimensional feature matrix \\n\\n[\\n\\n1,, \\n]\\n\\n, and because the feature\\nsequences of the three dimensions in  all reflect the long-term trend\\nof stock prices,  can also be seen as a global feature matrix. This\\nmultidimensional global feature matrix is input to the global feature ex-\\ntraction module (structure shown in Fig. 6) for feature extraction. TCN\\ncan effectively alleviate the gradient disappearance problem of long\\ntime series prediction by causal convolution; its powerful multi-layer\\nconvolution kernel can efficiently extract some important information\\nof the series. Based on these two advantages of TCN, we optimize\\nthe traditional temporal convolutional neural network and propose\\nthe multi-scale attention mechanism of temporal convolutional neural\\nnetwork (MA-TCN). The traditional temporal convolutional neural net-\\nwork performs the same level of convolution for the entire sequence,\\nso it cannot extract the influence of different features. The MA-TCN\\nintroduces self-attention and attention mechanisms into different parts\\nof the temporal convolutional neural network, which can dynamically\\nadjust the weight parameter of each feature attribute, resulting in a\\nmodel that is better suited to meet the actual situation and that fully\\nexplains the influence of the different attributes on the long-term trend.\\n\\nHere the feature matrix  is input, and the objective is to extract\\nthe long-term trend features of the stock price changes.  with self-\\nattention mechanism, assigning different weights to the information\\ninside the feature matrix, and subsequently using the neural network\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 6. Global feature extraction module structure.\\nfor feature extraction and distance learning to improve the efficiency\\nof feature extraction. The formula is:\\n\\n1 = Attention (,,  ) = sof tmax\\n\\n(\\n\\n\\n\\n\\n\\n\\n)\\n\\n (10)\\n\\nWhere , ,  are the same tensor as  as shown in Eq. (11), \\ndenotes the feature dimension of , and  denotes the activation\\nfunction.\\n =  \\n\\n =  \\n\\n =  \\n\\n(11)\\n\\nWhere   , ,  denote the parameter matrix. Then the obtained\\n1 feature matrix is input to the temporal convolutional neural net-\\nwork with the attention mechanism. Attention mechanism is added\\nto each dilated convolutional layer, the purpose of which is to assign\\nweights to the results of convolution operations in the process of feature\\nextraction, which improves the previous traditional temporal convo-\\nlutional neural network for single feature extraction from sequences.\\nWhich significantly improves the feature extraction capability and\\neffectiveness. The feature extraction process of temporal convolutional\\nneural network is as follows:\\n\\n\\ue232 () =\\n\\n\\n\\n\\n1\\n (12)\\n9\\n\\n=1\\nwhere  =\\n(\\n\\n1, 2, , \\n)\\n\\ndenotes the convolutional kernel,  is the\\nsize of convolutional kernels,  is the expansion coefficient, and 1\\n\\n\\nrepresents the feature matrix before moment . Where each residual\\nmodule is subjected to two \\ue232 () transformations and the activation\\nfunction Activation uses the ReLU activation function,\\n\\nResidual block = Activation\\n(\\n\\n1 + \\ue232\\n(\\n\\n1)) (13)\\n\\nUsing the temporal attention mechanism to get the final feature\\nresults,\\n\\n =\\n\\n\\n\\n\\n=1\\n\\nexp\\n(\\n\\nT tanh\\n(\\n\\n\\ue232 () + \\n))\\n\\n\\n=1 exp\\n\\n(\\n\\nT tanh\\n(\\n\\n\\ue232 () + \\n))\\ue232 () (14)\\n\\nWhere T,  are the parameter matrices,  denotes the bias vector,\\n is the activation function, and  is the training data length.\\n\\nThe features are extracted by a temporal convolutional neural\\nnetwork with a multiscale attention mechanism and then changed\\nto one dimension by a decoding layer, and finally output by two\\nfully connected layers. Using this module, extract the global features\\n\\n\\n[\\n\\n1, 2 \\n]\\n\\n.\\n\\n4.2. Subtasks2:Local feature extraction module\\n\\nThis subsection details the modules of subtask 2. At this point we\\nhave obtained k-1 high frequency signal sequences  ,  , ,  in\\n2 3 \\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 7. COVID-19 feature extraction module structure.\\n\\naddition to the first low frequency signal sequence, followed by feature\\nfusion with the constructed COVID-19 Index to form local feature\\nmatrices\\n\\n1\\n[\\n\\n2, \\n]\\n\\n, 2\\n[\\n\\n3, \\n]\\n\\n, , of number   1 and length  The\\nCOVID-19 feature extraction module is used for feature extraction, and\\nthe specific structure of the COVID-19 feature extraction module is\\nshown in Fig. 7.\\n\\nIn Fig. 7, we input the feature matrix  into the MVCNN-BiLSTM-\\nAtt, and first design two layers of one-dimensional convolutional neural\\nnetwork with different perceptual fields. Multiple parallel convolu-\\ntional neural networks can extract more complete local information\\nthan a single one-dimensional convolutional neural network. CNN ex-\\ntracts features from the feature matrix for input into Bi-LSTM. By com-\\nbining future and past information, Bi-LSTMs are capable of more effec-\\ntively memorizing data features;and the constant change of COVID-19\\nhas different degrees of influence on the stock market, we added\\nthe Time-attention mechanism to extract the degree of the effect of\\nthe changing COVID-19 status on the stock market. The structure of\\nBiLSTM-Att is shown in Fig. 8. In Bi-LSTM, it is updated according to\\nEqs. (15)(21).\\n\\n = \\n(\\n\\n\\n[\\n\\n1, \\n]\\n\\n+ \\n)\\n\\n(15)\\n\\n = \\n(\\n\\n\\n[\\n\\n1, \\n]\\n\\n+ \\n)\\n\\n(16)\\n\\n = tanh\\n(\\n\\n\\n[\\n\\n1, \\n]\\n\\n+ \\n)\\n\\n(17)\\n\\n = \\n(\\n\\n\\n[\\n\\n1, \\n]\\n\\n+ \\n)\\n\\n(18)\\n\\n = 1 +  (19)\\n\\n =  tanh\\n(\\n\\n\\n)\\n\\n(20)\\n\\n = [\\n\\n ,  \\n]\\n\\n(21)\\n10\\n\\n  \\nWhere Eq. (15)Eq. (20) are the steps of LSTM and Eq. (21) is the\\nstep of Bi-LSTM. ,  denote the activation function, , , ,\\ndenote the parameter matrix, ,  ,  ,  denote the bias vectors, where\\n denotes the Hadamard product (element-wise multiplication), 1\\ndenotes the hidden state value at the previous moment,  denotes the\\ninput at the current moment,  denotes the temporary hidden variable\\nat the current moment,  denotes the cell forward structural state,  \\ndenotes the cell backward structural state, and  is the output of the\\nBi-LSTM.\\n\\nThe formula for Time-Attention is as follows:\\n\\n = T tanh\\n(\\n\\n + \\n)\\n\\n(22)\\n\\n =\\nexp\\n\\n(\\n\\n\\n)\\n\\n\\n=1 exp\\n\\n(\\n\\n\\n) (23)\\n\\n =\\n\\n\\n\\n=1\\n (24)\\n\\nwhere ,  denote the parameter matrix,  calculates the attention\\nweights for . Finally, after calculating the probability  of the\\nattention weight, perform a weighted summation,calculate output \\n\\nAfter the features are extracted in BiLSTM-Att, they are then output\\nafter two fully connected layers. Using this module,extracted 1 local\\nfeatures \\n\\n[\\n\\n1, 2, , \\n]\\n\\n.\\n\\n4.3. Maintasks:Prediction result output module\\n\\nThis section describes the main task module. In most of the lit-\\nerature (Rezaei et al., 2021; Ronaghi et al., 2022; Yan et al., 2020),\\nafter the neural network extracts the sequence features, the resultant\\noutput is performed using the Fully Connected Layer (FCL). The output\\nof the fully connected layer depends heavily on the parameter settings\\nof the anterior neural network, one parameter often has an important\\ninfluence on the whole models results, but our model separates the\\ntasks of different modules, reducing the global impact of parameters in\\ndifferent tasks.\\n\\nThe output model of the main task is the K-nearest neighbor model.\\nKNN is a simple algorithm with good classification effects and has been\\nwidely used in stock prediction (Chen & Hao, 2017; Nayak, Mishra, &\\nRath, 2015), and it does not require training sample data nor estimation\\nof parameters, which makes it very suitable for further prediction based\\non the extracted features. The ablation experiment in Section 5.3.2\\nshows that the accuracy of the prediction result is about 13% higher\\nthan FCL when the features extracted from the network are used.\\n\\nIn implementing the KNN algorithm, the hyperparameter K and the\\ndistance measure have a great impact on performance. Regarding the\\ndistance measure, we calculate it by the reciprocal of the Euclidean\\ndistance,\\n\\n\\n(\\n\\n , \\n)\\n\\n= 1\\n\\n\\n\\n=1\\n\\n(\\n\\n  \\n)2\\n\\n,  = 1, 2, ,  (25)\\n\\nwhere  ( = 1, 2, , ) is the data to be classified in the test set and\\n( = 1, 2, , ) is the training set of known data. When the point to\\nbe predicted is closer to the sample point, the weight occupied will be\\nlarger, and vice versa, the weight will be smaller. Then we continue\\nto fuse the stock price series  and the global features  (feature 1)\\nand local features  (feature 2) obtained in Sections 4.1 and 4.2 into\\na feature matrix  =\\n\\n[\\n\\n ,  , \\n]\\n\\n, and set the stock price series  up\\nor down coding using Eq. (26) as the label values for classification.\\n\\n =\\n\\n{\\n\\n1 +1  \\n\\n0 +1 < \\n(26)\\n\\nAt this point, the stock forecasting problem is described:\\n\\n(+1) = \\n(\\n\\n \\n , +1\\n\\n , , \\n\\n)\\n\\n(27)\\n\\nwhere (+1) is the prediction result,  () is the set KNN classification\\nmodel, and  is the number of days of input data.\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 8. BiLSTM-Att structure.\\n4.4. Network optimization and loss function\\n\\nIn COVID19-MLSF, the losses of both subtask modules are optimized\\nusing MSE:\\n\\nloss = 1\\n\\n\\n\\n\\n\\n=1\\n\\n(\\n\\n  \\n)2 (28)\\n\\nwhere  denotes the predicted value of the network,  denotes the true\\nvalue, and the optimizer is Adam.\\n\\n5. Analysis of experiments\\n\\nExperimental results and comparisons are presented in this section\\nto evaluate the proposed hybrid COVID19-MLSF framework for the\\ntask of stock market forecasting. Specifically, it includes the data\\nintroduction part, the evaluation index introduction part, the compara-\\ntive experiment part, the ablation experiment part, and the parameter\\nsensitivity test part.\\n\\n5.1. Data and data preprocessing\\n\\nThis section describes the numerous data sources and data pre-\\nprocessing methods used in this paper. The NMSI and COVID-19 Index\\nconstructed in Section 3 uses the DCEF, NIPO, RIPO, NA, NewInvestors,\\nCCI, CPI, China daily COVID-19 new confirmed, new death, new cure,\\ncumulative confirmed, cumulative death and cumulative cure cases\\nfrom CSMAR database (https://www.gtarsc.com); Baidu search and\\ninformation data from Baidu index (https://index.baidu.com); ICI data\\nfrom (http://www.sipf.com.cn); AFRE data from (http://www.pbc.gov.\\ncn), Turnover Rate, P/E Ratio, and CSI 300 Index data from Tushare\\n(https://www.tushare.pro). The time period for all the above data is\\nJanuary 2019 to November 2021. Among them, stock price data, new\\nconfirmed cases of COVID-19, death cases, cured cases, cumulative\\nconfirmed cases, death cases, cured cases and Baidu Index data are all\\ndaily frequency data.\\n\\nThe stock data predicted by our model is China CSI 300 Index, and\\nwe divide 70% of the data as the training set and 30% as the test set.\\nSince we construct the NMSI and COVID-19 index to reflect the Chinese\\nstock market, we need to select an index that reflect the overall trend\\nof the Chinese stock market, and the CSI 300 is the best choice.\\n\\nThis paper normalize the stock data and the feature date in the\\nrange [0,1],\\n\\n =\\n  min\\n\\nmax  min\\n(29)\\n\\nAmong of them,  is the original data,  is the normalized data.\\n11\\n\\n\\n\\n5.2. Performance evaluation metric\\n\\nIn order to show the COVID19-MLSF performance, we use some\\nclassification metrics and stock return metrics for the presentation\\nof the results. Among the evaluation indicators for classification are\\nAccuracy (ACC), Mathews Correlation Coefficient (MCC), and F-score\\n(F-score). The return indicators are Profit, Maximum Drawdown, the\\ncalculation formula of the classification evaluation index is as follows:\\n\\nAccuracy =  + \\n +  +  + \\n\\n(30)\\n\\n =       \\n\\n\\n( +  )  ( + )  ( +  )  ( + )\\n(31)\\n\\n  score = 2  Precision  Recall\\nPrecision + Recall (32)\\n\\nwhere  denotes the number of positive examples predicted by the\\nclassifier, which means are positive value,  denotes the number of\\nnegative examples predicted by the classifier, which means are positive\\nvalue,  denotes the number of true positive examples predicted\\nby the classifier as, which means are negative value,  denotes the\\nnumber of negative examples predicted by the classifier, which means\\nare negative value.  is the net value of the product in a certain day,\\nand  is the net value of the product in a certain day after ,  is the\\nlength of time. During the calculation of the profit, we simulate a real\\nmarket transaction by setting the principal amount to RMB 1,000,000,\\nbut disregarding the transaction fees, which is incurred for buying and\\nselling, etc. (Zhang et al., 2018). Since we predict the CSI 300 index,\\nwe consider the transaction as making a stock index futures.\\n\\nProfit =\\n\\n\\n\\n 1 (33)\\n\\nMaximum Drawdown =\\nMax\\n\\n(\\n\\n  \\n)\\n\\n\\n(34)\\n\\nwhere  denotes the recall rate,  denotes the precision\\nrate,The calculation formula is:\\n\\nRecall = \\n + \\n\\n(35)\\n\\nPrecision = \\n + \\n\\n(36)\\n\\n5.3. Experimental results and performance comparison\\n\\nThis subsection presents the results of comparative experiments,\\nablation experiments and parameter sensitivity tests are presented,\\nwhich further confirm the effectiveness of the features and models in\\nSections 3 and 4.\\n\\nhttps://www.gtarsc.com\\nhttps://index.baidu.com\\nhttp://www.sipf.com.cn\\nhttp://www.pbc.gov.cn\\nhttp://www.pbc.gov.cn\\nhttp://www.pbc.gov.cn\\nhttps://www.tushare.pro\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nTable 4\\nComparative display of experimental results.\\n\\nACC MCC F-score Profit Maximum-\\nDrawdown\\n\\nCOVID-19-MLSF 58.85% 17.81% 57.75% 8.81% 7.93%\\nBGVAR 49.01% 2.21% 52.09% 7.25% 11.74%\\nMIDAS 53.47% 7.37% 57.39% 10.84% 11.86%\\nBayesian 52.08% 4.05% 58.93% 7.97% 14.44%\\nRandom Forest 54.17% 8.43% 52.69% 2.82% 10.71%\\nLSTM 52.13% 6.17% 55.88% 6.38% 10.56%\\nAdv-LSTM 55.73% 11.44% 56.41% 2.12% 10.56%\\nSCINet 53.65% 7.22% 56.58% 2.10% 9.35%\\nBi-LSTMSeq2Seq 52.60% 5.26% 51.85% 3.76% 10.86%\\nNaive 43.23% 13.58% 44.10% 16.75% 18.59%\\nBuy and Hold    14.61% 18.10%\\n\\n5.3.1. Performance comparison experiment\\nFirst, we compared some traditional models for financial time series\\n\\nforecasting that use econometrics, including BGVAR (Ahelegbey, Billio,\\n& Casarin, 2016; Ahelegbey et al., 2022), MIDAS (Gunay, Can, & Ocak,\\n2020). Then, we use normal machine learning classification models\\nsuch as Random Forest, Bayesian, and LSTM. To further verify the\\nsuperior performance of our model, we compared two advanced single-\\ntask models, Adv-ALSTM (Feng et al., 2018), SCINet (Liu, Zeng, Xu,\\nLai, & Xu, 2021), and multi-task model Bi-LSTM Seq2Seq (Mootha\\net al., 2020). In addition, we are also compare Naive algorithm (Cui,\\nXie, & Zheng, 2021) and the buy and hold algorithm. Here are brief\\ndescriptions of them:\\n\\nBGVAR:The method Bayesian graph-based approach to identifica-\\ntion in vector autoregressive (VAR) models.\\n\\nMIDAS:The method allows different frequencies to be used in a\\nregression model.\\n\\nRandom Forest:The method is to integrate many decision trees into\\na forest and use it to predict the final result.\\n\\nBayesian:The method calculates the probability that a classification\\nobject belongs to a certain class, and selects the class with the largest\\nposterior probability as the class to which the object belongs.\\n\\nLSTM:The method trains price features constructed based on histor-\\nical sequence data, obtains sequence embeddings, and then uses a fully\\nconnected layer to predict.\\n\\nAdv-ALSTM: This method proposes the use of adversarial training\\nto train the model, which significantly improves the performance of the\\nLSTM model.\\n\\nSCINet: This method constructs the basic block SCI-Block, down-\\nsamples the input features into two subsequences, and then extracts\\neach subsequence feature using different convolutional filters to retain\\nthe information of different features, and adds the learning of convo-\\nlutional features between the two sequences in each SCI-Block, finally\\nconstructing a multilayer neural network framework for prediction.\\n\\nBi-LSTM Seq2Seq: This method constructs an encoder and decoder\\nusing Bi-LSTM to input the multidimensional price features of the stock\\nand predicts multiple price series, such as closing price and opening\\nprice using a multitask learning framework.\\n\\nNaive: This method use todays up and down as tomorrows buying\\nand selling signals.\\n\\nIn Table 4 shows the comparison results of our proposed COVID19-\\nMLSF model with some single-task and multi-task models, therefore\\nCOVID19-MLSF model achieves good results in the field of stock pre-\\ndiction.\\n\\nTable 4 compares our proposed COVID19-MLSF model with some\\nsingle-task and multi-task models, thus COVID19-MLSF model achieves\\ngood results in the field of stock prediction. The bar chart in Fig. 9\\nshows how our model fares against other models for each evaluation\\nmetric, and it is obvious that our method fares better than other\\nmodels for each evaluation metric. In Fig. 10, we show the change\\nin cumulative returns between February 2021 to November 2021 for\\n12\\nTable 5\\nAblation display of experimental results.\\n\\nACC MCC F-score Profit Maximum-\\nDrawdown\\n\\nCOVID-19-MLSF 58.85% 17.81% 57.75% 8.81% 7.93%\\nCOVID-19-MLSF1 57.29% 14.66% 56.39% 2.14% 8.50%\\nCOVID-19-MLSF2 56.25% 12.82% 52.81% 2.65% 6.89%\\nCOVID-19-MLSF3 54.27% 8.66% 52.22% 1.45% 9.33%\\nCOVID-19-MLSF4 56.77% 13.48% 53.84% 3.10% 8.54%\\nCOVID-19-MLSF5 55.43% 12.22% 51.93% 2.44% 8.76%\\nCOVID-19-MLSF6 51.22% 3.42% 48.88% 6.31% 9.54%\\nCOVID-19-MLSF7 53.48% 6.92% 49.07% 5.97% 10.67%\\nKNN 50.52% 1.38% 43.11% 5.36% 8.43%\\n\\nour model and the comparison model. This phenomenon was in a bear\\nmarket according to the buy-and-hold return. Table 4, Fig. 9 and Fig. 10\\ndemonstrate that using machine learning methods does increase the\\nstock market returns. Among many models, our model has achieved the\\nhighest ACC, MCC, profit and low fallback rate, which indicates that\\nour model not only provides benefits, but also reduces certain risks,\\nincluding those caused by external macroeconomic policy adjustments\\nin the stock market and COVID-19 factors.\\n\\n5.3.2. Ablation experiment\\nTo evaluate the construct external features of the stock market and\\n\\nthe effectiveness of the design module, we transform COVID19-MLSF\\ninto the following six models, and conduct experiments on the same\\ndataset.\\n\\n(1) COVID19-MLSF1 means using NMSI alone, COVID19-MLSF2\\nmeans using COVID-19 Index alone for prediction.\\n\\n(2) COVID19-MLSF3 shows that the variational modal sliding win-\\ndow decomposition method is not used.\\n\\n(3) COVID19-MLSF4 shows that in the COVID-19 feature extraction\\nmodule, the LSTM module is used to replace the MVCNN-BiLSTM-Att.\\n\\n(4) COVID19-MLSF5 shows that in the global feature extraction\\nmodule, the TCA module is used to replace the MA-TCN.\\n\\n(5) COVID19-MLSF6 shows that the decomposed stock price se-\\nquence and constructed features are all have into a feature matrix for\\nprediction.\\n\\n(6)COVID19-MLSF7 shows that NMSI and COVID-19 Index were\\ncombined with the opposite frequency signal.\\n\\n(7) KNN shows the prediction result of the main task module, which\\nis used to both comparison and ablation experiments here.\\n\\nIn Table 5 the specific results of the ablation experiments are shown,\\nand in Fig. 11, the bar chart shows the indicators between the model\\nand each ablation experiment part.\\n\\nBased on Table 5, we can draw the following conclusions can be\\ngot from the experimental results in Table 5. The COVID19-MLSF1\\nand COVID19-MLSF2 experiments proves that the constructed NMSI\\nand COVID-19 Index features are effective. The COVID19-MLSF3 ex-\\nperiment proves that the decomposition of stock price series is very\\neffective, and the decomposition of stock price series significantly\\nimproves the accuracy of stock forecasting. The COVID19-MLSF4 ex-\\nperiment proves that MVCNN-BiLSTM-Att is more effective than the\\ntraditional recurrent neural network model. The COVID19-MLSF5 ex-\\nperiment proves that MA-TCN is more effective than the traditional\\nTCN. Multi-task learning with multiple data sources, which improves\\nthe feature extraction capability of complex data, is demonstrated\\nby the experiments of the COVID19-MLSF6 and KNN experiments.\\nCOVID19-MLSF7 experiment proves NMSI is more effective when com-\\nbined with low-frequency signals, and COVID-19 Index is combined\\nwith high-frequency signals.\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 9. Comparison of the metrics of COVID19-MLSF model and the comparison model.\\nFig. 10. Cumulative Return Comparison.\\n5.3.3. Hyperparameter sensitivity experiment\\nIn KNN, the choice of K values is crucial for the final prediction\\n\\nresults, so we performed a hyperparametric sensitivity analysis. Table 6\\nshows the prediction results based on the main task alone for different\\ninput days , along with the results of joint prediction based on the\\n13\\nfeatures extracted from subtasks and closing prices. In Fig. 12, the\\ndata in Table 6 are presented as a line chart, allowing a more direct\\nunderstanding of the data. It can be clearly that our predictions with\\nthe addition of subtask features are higher than the single main task,\\nfurther demonstrating that our extracted features are effective when the\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\nFig. 11. Comparison of various indicators between the COVID19-MLSF model and the ablation experimental model.\\nFig. 12. The relationship between accuracy and hyperparameter K value.\\ninput days  and K values are the same. Furthermore, the multi-task\\nmodel that we designed can improve significantly.\\n\\n6. Conclusion and future work\\n\\nBy utilizing a multi-task learning framework, we propose a\\nCOVID19-MLSF stock forecasting framework that fully extracts the\\n14\\ninternal and external features of the Chinese stock market under\\nCOVID-19 pandemic. As a method of describing the external features\\nof the stock market, this paper uses the newly constructed stock\\nmarket sentiment index (NMSI) and the COVID-19 index. Two pre-\\ndiction subtask are established by combining them with decomposed\\nstock price series separately, in which one uses MA-TCN to extract\\nthe globally important stock market features, while the other uses\\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\n\\nt\\ne\\n\\nD\\n\\nc\\ni\\n\\nD\\n\\nA\\n\\nm\\nF\\n\\nTable 6\\nThe relationship between prediction accuracy and hyperparameter K value under different input days .\\n\\nEnter days =15 =20 =25\\n\\nHyperparameter K Close Close + Extract\\nfeatures\\n\\nClose Close + Extract\\nfeatures\\n\\nClose Close + Extract\\nfeatures\\n\\n1 52.60% 58.85% 50.27% 53.48% 49.45% 56.04%\\n2 50.52% 58.85% 53.48% 55.08% 48.90% 56.04%\\n3 49.48% 54.17% 44.92% 54.01% 45.60% 55.49%\\n4 49.48% 56.77% 47.59% 52.94% 43.41% 53.30%\\n5 49.48% 53.13% 48.13% 51.34% 43.41% 50.55%\\n6 47.40% 53.65% 47.59% 53.48% 44.51% 50.00%\\n7 46.35% 53.13% 46.52% 53.48% 46.70% 53.30%\\n8 49.48% 54.17% 44.92% 54.01% 46.70% 51.65%\\n9 46.35% 52.08% 47.06% 49.73% 47.25% 55.49%\\n10 47.92% 51.04% 45.45% 52.41% 46.15% 52.75%\\n11 49.48% 54.17% 45.45% 51.87% 51.10% 50.55%\\n12 49.48% 51.56% 48.13% 49.73% 48.90% 51.65%\\n13 48.96% 52.08% 43.85% 49.20% 48.35% 50.55%\\n14 47.92% 51.56% 47.06% 51.34% 50.00% 48.90%\\n15 47.40% 51.04% 43.85% 50.80% 53.85% 51.10%\\n16 48.44% 51.56% 46.52% 50.80% 51.65% 50.55%\\n17 46.88% 52.60% 46.52% 50.80% 53.30% 51.65%\\n18 48.96% 55.73% 51.87% 50.80% 52.75% 51.65%\\n19 44.27% 55.73% 49.20% 54.55% 54.40% 52.75%\\n20 47.92% 54.69% 52.94% 54.01% 51.10% 51.10%\\nAvg 48.44% 53.83% 47.57% 52.19% 48.87% 52.25%\\nR\\n\\nA\\n\\nA\\n\\nA\\n\\nA\\n\\nB\\n\\nB\\n\\nB\\n\\nC\\n\\nC\\n\\nD\\n\\nF\\n\\nF\\n\\nF\\n\\nMVCNN-BiLSTM-Att to extract other local stock market features and the\\ndegree of COVID-19 impact on the stock market. Our model achieves\\ngood results in predicting the Chinese stock market during COVID-19,\\nreduces the impact of COVID-19 on the prediction model, particularly\\nin constructing a more effective external feature of the stock market,\\nwhich provides ideas for research into the impact of emergencies on\\nthe stock market.\\n\\nWith the subsequent unpredictable development of COVID-19, we\\ncan also look for new features, further study the impact of COVID-19\\non individual stocks in different industries, and make use of machine\\nlearning and deep learning techniques to reduce the negative impact of\\nCOVID-19 on specific industries.\\n\\nCRediT authorship contribution statement\\n\\nChenxun Yuan: Software, Investigation, Writing  original draft.\\nXiang Ma: Software, Conceptualization, Visualization. Hua Wang:\\nSoftware, Writing & editing. Caiming Zhang: Visualization, Investiga-\\nion. Xuemei Li: Conceptualization, Methodology, Writing  review &\\nditing.\\n\\neclaration of competing interest\\n\\nThe authors declare that they have no known competing finan-\\nial interests or personal relationships that could have appeared to\\nnfluence the work reported in this paper.\\n\\nata availability\\n\\nThe data that has been used is confidential.\\n\\ncknowledgments\\n\\nWe thank the anonymous reviewers for their constructive com-\\nents. This work was supported in part by the National Natural Science\\n\\noundation of China (Grant No. 62072281, No. 62007017)\\n15\\neferences\\n\\ngrawal, M., Khan, A. U., & Shukla, P. K. (2019). Stock price prediction using technical\\nindicators: a predictive model using optimal deep learning. Learning, 6(2), 7.\\n\\nhelegbey, D. F., Billio, M., & Casarin, R. (2016). Bayesian graphical models for\\nstructural vector autoregressive processes. Journal of Applied Econometrics, 31(2),\\n357386.\\n\\nhelegbey, D. F., Cerchiello, P., & Scaramozzino, R. (2022). Network based evidence of\\nthe financial impact of Covid-19 pandemic. International Review of Financial Analysis,\\n81, Article 102101.\\n\\nlthelaya, K. A., El-Alfy, E.-S. M., & Mohammed, S. (2018). Evaluation of bidirectional\\nLSTM for short-and long-term stock market prediction. In 2018 9th international\\nconference on information and communication systems (pp. 151156). IEEE.\\n\\nai, S., Kolter, J. Z., & Koltun, V. (2018). An empirical evaluation of generic\\nconvolutional and recurrent networks for sequence modeling. arXiv preprint arXiv:\\n1803.01271.\\n\\naker, M., & Wurgler, J. (2006). Investor sentiment and the cross-section of stock\\nreturns. The Journal of Finance, 61(4), 16451680.\\n\\naker, M., & Wurgler, J. (2007). Investor sentiment in the stock market. Journal of\\nEconomic Perspectives, 21(2), 129152.\\n\\nhen, Y., & Hao, Y. (2017). A feature weighted support vector machine and K-\\nnearest neighbor algorithm for stock market indices prediction. Expert Systems with\\nApplications, 80, 340355.\\n\\nhen, Y., & Hao, Y. (2018). Integrating principle component analysis and weighted\\nsupport vector machine for stock trading signals prediction. Neurocomputing, 321,\\n381402.\\n\\nChen, X., Ma, X., Wang, H., Li, X., & Zhang, C. (2022). A hierarchical attention network\\nfor stock prediction based on attentive multi-view news learning. Neurocomputing,\\nhttp://dx.doi.org/10.1016/j.neucom.2022.06.106.\\n\\nCheng, W., Wang, Y., Peng, Z., Ren, X., Shuai, Y., Zang, S., et al. (2021). High-efficiency\\nchaotic time series prediction based on time convolution neural network. Chaos,\\nSolitons & Fractals, 152, Article 111304.\\n\\nCho, K., Van Merrinboer, B., Gulcehre, C., Bahdanau, D., Bougares, F., Schwenk, H.,\\net al. (2014). Learning phrase representations using RNN encoder-decoder for\\nstatistical machine translation. arXiv preprint arXiv:1406.1078.\\n\\nCollobert, R., & Weston, J. (2008). A unified architecture for natural language\\nprocessing: Deep neural networks with multitask learning. In Proceedings of the\\n25th international conference on machine learning (pp. 160167).\\n\\nCui, Y., Xie, J., & Zheng, K. (2021). Historical inertia: A neglected but powerful\\nbaseline for long sequence time-series forecasting. In Proceedings of the 30th ACM\\ninternational conference on information & knowledge management (pp. 29652969).\\n\\nai, W., An, Y., & Long, W. (2022). Price change prediction of ultra high frequency\\nfinancial data based on temporal convolutional network. Procedia Computer Science,\\n199, 11771183.\\n\\nama, E. F. (1970). Efficient capital markets: A review of theory and empirical work.\\nThe Journal of Finance, 25(2), 383417.\\n\\neng, F., Chen, H., He, X., Ding, J., Sun, M., & Chua, T.-S. (2018). Enhancing stock\\nmovement prediction with adversarial training. arXiv preprint arXiv:1810.09936.\\n\\nu, R., Zhang, Z., & Li, L. (2016). Using LSTM and GRU neural network methods for\\ntraffic flow prediction. In 2016 31st youth academic annual conference of Chinese\\nAssociation of Automation (pp. 324328). IEEE.\\n\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb1\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb1\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb1\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb2\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb2\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb2\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb2\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb2\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb3\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb3\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb3\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb3\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb3\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb4\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb4\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb4\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb4\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb4\\nhttp://arxiv.org/abs/1803.01271\\nhttp://arxiv.org/abs/1803.01271\\nhttp://arxiv.org/abs/1803.01271\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb6\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb6\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb6\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb7\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb7\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb7\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb8\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb8\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb8\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb8\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb8\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb9\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb9\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb9\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb9\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb9\\nhttp://dx.doi.org/10.1016/j.neucom.2022.06.106\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb11\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb11\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb11\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb11\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb11\\nhttp://arxiv.org/abs/1406.1078\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb13\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb13\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb13\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb13\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb13\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb14\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb14\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb14\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb14\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb14\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb15\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb15\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb15\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb15\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb15\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb16\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb16\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb16\\nhttp://arxiv.org/abs/1810.09936\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb18\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb18\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb18\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb18\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb18\\n\\n\\nExpert Systems With Applications 217 (2023) 119549C. Yuan et al.\\n\\nG\\n\\nG\\n\\nG\\n\\nG\\n\\nH\\n\\nH\\n\\nJ\\n\\nK\\n\\nL\\n\\nL\\n\\nL\\n\\nL\\n\\nL\\n\\nL\\n\\nL\\n\\nL\\n\\nL\\n\\nM\\n\\nM\\n\\nM\\n\\nM\\n\\nM\\n\\nN\\n\\nQ\\n\\nR\\n\\nR\\n\\nS\\n\\nS\\n\\n\\n\\nW\\n\\nW\\n\\nY\\n\\nY\\n\\nY\\n\\nY\\n\\nZ\\n\\nZ\\n\\nZ\\n\\nGao, T., & Chai, Y. (2018). Improving stock closing price prediction using recurrent\\nneural network and technical indicators. Neural Computation, 30(10), 28332854.\\n\\nirshick, R. (2015). Fast r-cnn. In Proceedings of the IEEE international conference on\\ncomputer vision (pp. 14401448).\\n\\niudici, P., Polinesi, G., & Spelta, A. (2022). Network models to improve robot advisory\\nportfolios. Annals of Operations Research, 313(2), 965989.\\n\\nong, X., Zhang, W., Wang, J., & Wang, C. (2022). Investor sentiment and stock\\nvolatility: New evidence. International Review of Financial Analysis, 80, Article\\n102028.\\n\\nunay, S., Can, G., & Ocak, M. (2020). Forecast of Chinas economic growth during\\nthe COVID-19 pandemic: a MIDAS regression analysis. Journal of Chinese Economic\\nand Foreign Trade Studies.\\n\\nochreiter, S., & Schmidhuber, J. (1997). Long short-term memory. Neural Computation,\\n9(8), 17351780.\\n\\nu, Z., Liu, W., Bian, J., Liu, X., & Liu, T.-Y. (2018). Listening to chaotic whispers: A\\ndeep learning framework for news-oriented stock trend prediction. In Proceedings\\nof the eleventh ACM international conference on web search and data mining (pp.\\n261269).\\n\\ning, N., Wu, Z., & Wang, H. (2021). A hybrid model integrating deep learning\\nwith investor sentiment analysis for stock price prediction. Expert Systems with\\nApplications, 178, Article 115019.\\n\\no, J. U., Jung, J. H., Kim, M., Kong, H. B., Lee, J., & Youn, B. D. (2021). Multi-\\ntask learning of classification and denoising (MLCD) for noise-robust rotor system\\ndiagnosis. Computers in Industry, 125, Article 103385.\\n\\nahmiri, S. (2014). Comparative study of ECG signal denoising by wavelet thresholding\\nin empirical and variational mode decomposition domains. Healthcare Technology\\nLetters, 1(3), 104109.\\n\\nahmiri, S. (2016a). Intraday stock price forecasting based on variational mode\\ndecomposition. Journal of Computer Science, 12, 2327.\\n\\nahmiri, S. (2016b). A variational mode decompoisition approach for analysis and\\nforecasting of economic and financial time series. Expert Systems with Applications,\\n55, 268273.\\n\\ni, H., Liu, T., Wu, X., & Chen, Q. (2020). An optimized VMD method and its\\napplications in bearing fault diagnosis. Measurement, 166, Article 108185.\\n\\ni, C., Song, D., & Tao, D. (2019). Multi-task recurrent neural networks and higher-\\norder Markov random fields for stock price movement prediction: Multi-task RNN\\nand higer-order MRFs for stock price classification. In Proceedings of the 25th\\nACM SIGKDD international conference on knowledge discovery & data mining (pp.\\n11411151).\\n\\nin, G., Lin, A., & Cao, J. (2021). Multidimensional KNN algorithm based on EEMD\\nand complexity measures in financial time series forecasting. Expert Systems with\\nApplications, 168, Article 114443.\\n\\niu, T., Ma, X., Li, S., Li, X., & Zhang, C. (2022). A stock price prediction method based\\non meta-learning and variational mode decomposition. Knowledge-Based Systems,\\nArticle 109324. http://dx.doi.org/10.1016/j.knosys.2022.109324.\\n\\niu, M., Zeng, A., Xu, Z., Lai, Q., & Xu, Q. (2021). Time series is a special sequence:\\nForecasting with sample convolution and interaction. arXiv preprint arXiv:2106.\\n09305.\\n\\nos, C. A., & Yu, B. (2008). Persistence characteristics of the Chinese stock markets.\\nInternational Review of Financial Analysis, 17(1), 6482.\\n\\na, X., Li, X., Zhou, Y., & Zhang, C. (2021). Image smoothing based on global\\nsparsity decomposition and a variable parameter. Computational Visual Media, 7(4),\\n483497.\\n\\na, T., & Tan, Y. (2020). Multiple stock time series jointly forecasting with multi-task\\nlearning. In 2020 international joint conference on neural networks (pp. 18). IEEE.\\n\\na, T., & Tan, Y. (2022). Stock ranking with multi-task learning. Expert Systems with\\nApplications, 199, Article 116886.\\n16\\na, X., Zhao, T., Guo, Q., Li, X., & Zhang, C. (2022). Fuzzy hypergraph network for\\nrecommending top-K profitable stocks. Information Sciences, 613, 239255.\\n\\nootha, S., Sridhar, S., Seetharaman, R., & Chitrakala, S. (2020). Stock price prediction\\nusing bi-directional LSTM based sequence to sequence modeling and multitask\\nlearning. In 2020 11th IEEE annual ubiquitous computing, electronics & mobile\\ncommunication conference (pp. 00780086). IEEE.\\n\\nayak, R. K., Mishra, D., & Rath, A. K. (2015). A Nave SVM-KNN based stock market\\ntrend reversal analysis for Indian benchmark indices. Applied Soft Computing, 35,\\n670680.\\n\\nin, Y., Song, D., Chen, H., Cheng, W., Jiang, G., & Cottrell, G. (2017). A dual-stage\\nattention-based recurrent neural network for time series prediction. arXiv preprint\\narXiv:1704.02971.\\n\\nezaei, H., Faaljou, H., & Mansourfar, G. (2021). Stock price prediction using deep\\nlearning and frequency decomposition. Expert Systems with Applications, 169, Article\\n114332.\\n\\nonaghi, F., Salimibeni, M., Naderkhani, F., & Mohammadi, A. (2022). COVID19-\\nHPSMP: COVID-19 adopted hybrid and parallel deep information fusion framework\\nfor stock price movement prediction. Expert Systems with Applications, 187, Article\\n115879.\\n\\nhah, H., Bhatt, V., & Shah, J. (2022). A neoteric technique using ARIMA-LSTM for time\\nseries analysis on stock market forecasting. In Mathematical modeling, computational\\nintelligence techniques and renewable energy (pp. 381392). Springer.\\n\\niami-Namini, S., Tavakoli, N., & Namin, A. S. (2019). The performance of LSTM and\\nBiLSTM in forecasting time series. In 2019 IEEE international conference on big data\\n(pp. 32853292). IEEE.\\n\\ntifani, D., Musulin, J., Mioevi, A., Baressi egota, S., ubi, R., & Car, Z. (2020).\\nImpact of COVID-19 on forecasting stock prices: an integration of stationary wavelet\\ntransform and bidirectional long short-term memory. Complexity, 2020.\\n\\nang, L. (2010). The effect of government policy on Chinas stock market (Ph.D. thesis),\\nCiteseer.\\n\\nu, Q., & Lin, H. (2019). Short-term wind speed forecasting based on hybrid variational\\nmode decomposition and least squares support vector machine optimized by bat\\nalgorithm model. Sustainability, 11(3), 652.\\n\\nan, B., Aasma, M., et al. (2020). A novel deep learning framework: Prediction and\\nanalysis of financial time series using CEEMD and LSTM. Expert Systems with\\nApplications, 159, Article 113609.\\n\\nang, M., & Wang, J. (2022). Adaptability of financial time series prediction based on\\nBiLSTM. Procedia Computer Science, 199, 1825.\\n\\ni, Z., & Mao, N. (2009). Research on investor sentiment measurement in Chinese stock\\nmarket: construction of CICSI. Financial Research, 11, 174184.\\n\\nue, X., Zhou, Y., & Yuan, C. (2021). Stock closing price prediction based on combined\\nmodel of PCA-IMKNN. International Journal of Modelling, Identification and Control,\\n39(3), 221228.\\n\\nhang, C., Wang, Y., Chen, C., Du, C., Yin, H., & Wang, H. (2018). Stockassistant: a\\nstock ai assistant for reliability modeling of stock comments. In Proceedings of the\\n24th ACM SIGKDD international conference on knowledge discovery & data mining (pp.\\n27102719).\\n\\nhang, H.-C., Wu, Q., & Li, F.-Y. (2022). Application of online multitask learning based\\non least squares support vector regression in the financial market. Applied Soft\\nComputing, 121, Article 108754.\\n\\nheng, L., & He, H. (2021). Share price prediction of aerospace relevant companies\\nwith recurrent neural networks based on pca. Expert Systems with Applications, 183,\\nArticle 115384.\\n\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb19\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb19\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb19\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb20\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb20\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb20\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb21\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb21\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb21\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb22\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb22\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb22\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb22\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb22\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb23\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb23\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb23\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb23\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb23\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb24\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb24\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb24\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb25\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb25\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb25\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb25\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb25\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb25\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb25\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb26\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb26\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb26\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb26\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb26\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb27\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb27\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb27\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb27\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb27\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb28\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb28\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb28\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb28\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb28\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb29\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb29\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb29\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb30\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb30\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb30\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb30\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb30\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb31\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb31\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb31\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb32\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb33\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb33\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb33\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb33\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb33\\nhttp://dx.doi.org/10.1016/j.knosys.2022.109324\\nhttp://arxiv.org/abs/2106.09305\\nhttp://arxiv.org/abs/2106.09305\\nhttp://arxiv.org/abs/2106.09305\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb36\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb36\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb36\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb37\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb37\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb37\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb37\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb37\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb38\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb38\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb38\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb39\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb39\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb39\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb40\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb40\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb40\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb41\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb41\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb41\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb41\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb41\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb41\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb41\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb42\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb42\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb42\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb42\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb42\\nhttp://arxiv.org/abs/1704.02971\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb44\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb44\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb44\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb44\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb44\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb45\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb45\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb45\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb45\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb45\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb45\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb45\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb46\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb46\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb46\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb46\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb46\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb47\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb47\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb47\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb47\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb47\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb48\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb48\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb48\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb48\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb48\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb49\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb49\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb49\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb50\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb50\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb50\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb50\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb50\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb51\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb51\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb51\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb51\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb51\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb52\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb52\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb52\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb53\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb53\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb53\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb54\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb54\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb54\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb54\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb54\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb55\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb55\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb55\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb55\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb55\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb55\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb55\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb56\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb56\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb56\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb56\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb56\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb57\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb57\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb57\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb57\\nhttp://refhub.elsevier.com/S0957-4174(23)00050-7/sb57\\n\\n\\tCOVID19-MLSF: A multi-task learning-based stock market forecasting framework during the COVID-19 pandemic\\n\\tIntroduction\\n\\tReview of Literature\\n\\tPrediction based on machine learning and multi-task learning\\n\\tPrediction based on multiple features of the stock market\\n\\n\\tPrepare Work\\n\\tNew Market Sentiment Index\\n\\tCOVID-19 Index\\n\\tSliding Window-VMD\\n\\tSummary\\n\\n\\tMethodology\\n\\tSubtasks1:Global Feature Extraction Module\\n\\tSubtasks2:Local Feature Extraction Module\\n\\tMaintasks:Prediction Result Output Module\\n\\tNetwork Optimization and Loss Function\\n\\n\\tAnalysis of Experiments\\n\\tData and Data Preprocessing\\n\\tPerformance Evaluation Metric\\n\\tExperimental Results and Performance Comparison\\n\\tPerformance Comparison Experiment\\n\\tAblation Experiment\\n\\tHyperparameter Sensitivity Experiment\\n\\n\\n\\tConclusion and Future Work\\n\\tCRediT authorship contribution statement\\n\\tDeclaration of Competing Interest\\n\\tData availability\\n\\tAcknowledgments\\n\\tReferences\\n\\n\\n', 'status': 200}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Document COVID19-MLSF--A-multi-task-learning-based-stock-market_2023_Expert-Systems-w.pdf indexed successfully.\n",
      "INFO:root:updated project entry\n",
      "ERROR:root:Error processing file 'COVID19-MLSF--A-multi-task-learning-based-stock-market_2023_Expert-Systems-w.pdf': sequence item 0: expected a bytes-like object, str found\n",
      "INFO:root:Processing file: Deep-learning-in-insurance--Accuracy-and-model-int_2023_Expert-Systems-with-.pdf\n",
      "INFO:root:File Deep-learning-in-insurance--Accuracy-and-model-int_2023_Expert-Systems-with-.pdf uploaded to IPFS with CID: QmV1vYkuiwKGPA5Tyi4ECNFfWYocyTtQ3E5j7CSvPBX49Q\n",
      "INFO:root:Indexed Deep-learning-in-insurance--Accuracy-and-model-int_2023_Expert-Systems-with-.pdf with CID: QmY7xwK4beVPQLbeKxEAeStqxY69f7GzRhqTukXXsLMkMh\n",
      "INFO:root:Document Deep-learning-in-insurance--Accuracy-and-model-int_2023_Expert-Systems-with-.pdf indexed successfully.\n",
      "INFO:root:updated project entry\n",
      "ERROR:root:Error processing file 'Deep-learning-in-insurance--Accuracy-and-model-int_2023_Expert-Systems-with-.pdf': sequence item 0: expected a bytes-like object, str found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dublin Core Metadata:\n",
      "{\n",
      "    \"dc:format\": \"application/pdf; version=1.7\",\n",
      "    \"dc:title\": \"COVID19-MLSF: A multi-task learning-based stock market forecasting framework during the COVID-19 pandemic\",\n",
      "    \"dc:description\": \"Expert Systems With Applications, 217 (2023) 119549. doi:10.1016/j.eswa.2023.119549\",\n",
      "    \"dc:creator\": [\n",
      "        \"Chenxun Yuan\",\n",
      "        \"Xiang Ma\",\n",
      "        \"Hua Wang\",\n",
      "        \"Caiming Zhang\",\n",
      "        \"Xuemei Li\"\n",
      "    ],\n",
      "    \"dcterms:created\": \"2023-02-04T09:40:15Z\",\n",
      "    \"dcterms:modified\": \"2023-02-07T16:52:03Z\",\n",
      "    \"dc:language\": \"en-US\",\n",
      "    \"dc:subject\": [\n",
      "        \"Stock market forecasting,COVID-19 pandemic,Multi-task learning,Feature fusion,K-nearest neighbor classifier\",\n",
      "        \"Expert Systems With Applications, 217 (2023) 119549. doi:10.1016/j.eswa.2023.119549\"\n",
      "    ]\n",
      "}\n",
      "Loaded project data successfully.\n",
      "Current project_data: {\n",
      "    \"@context\": {\n",
      "        \"schema\": \"http://schema.org/\",\n",
      "        \"dc\": \"http://purl.org/dc/terms/\"\n",
      "    },\n",
      "    \"@graph\": [\n",
      "        {\n",
      "            \"@type\": \"schema:ResearchProject\",\n",
      "            \"schema:identifier\": \"06535@test\",\n",
      "            \"schema:publicKey\": \"7851c382158dc0349df2136ae8821753b98b65be412387181764005baf9bff20\",\n",
      "            \"schema:description\": {\n",
      "                \"@context\": {\n",
      "                    \"schema\": \"http://schema.org/\",\n",
      "                    \"dc\": \"http://purl.org/dc/terms/\"\n",
      "                },\n",
      "                \"@type\": \"schema:ResearchProject\",\n",
      "                \"schema:name\": \"Investigating the Role of quantum computing in supply chain management\",\n",
      "                \"dc:abstract\": \"This study explores the impact of quantum computing in supply chain management, focusing on biodiversity.\",\n",
      "                \"schema:keywords\": [\n",
      "                    \"quantum computing\",\n",
      "                    \"supply chain management\",\n",
      "                    \"biodiversity\"\n",
      "                ],\n",
      "                \"schema:startDate\": \"2023-07-03\",\n",
      "                \"schema:endDate\": \"2026-07-23\",\n",
      "                \"schema:funding\": {\n",
      "                    \"@type\": \"schema:Organization\",\n",
      "                    \"schema:name\": \"National Science Foundation\"\n",
      "                },\n",
      "                \"schema:location\": {\n",
      "                    \"@type\": \"schema:Place\",\n",
      "                    \"schema:name\": \"Lagos, Nigeria\"\n",
      "                }\n",
      "            },\n",
      "            \"schema:metadataCID\": \"QmbmyecKUbwCDFPt6Uddx411bCvefLiRXPxHs5vnYz4XZm\",\n",
      "            \"schema:linked_user\": \"crazy_nash@test\",\n",
      "            \"schema:files\": [\n",
      "                {\n",
      "                    \"file_index\": 1,\n",
      "                    \"file_cid\": \"QmVk8gxENq6PThSGZTuk7RtbufR2XeN7LtXBj2LVTUoAdN\",\n",
      "                    \"metadata_cid\": \"QmWuj7Rr8PjwGzGW5otvAVTDUywUt8BHh7uvawFqEreMJo\",\n",
      "                    \"metadata\": {}\n",
      "                },\n",
      "                {\n",
      "                    \"file_index\": 2,\n",
      "                    \"file_cid\": \"QmT7ximApXtExAedhzUHGHDwRismRzuKykpH4dgTvGrNZs\",\n",
      "                    \"metadata_cid\": \"QmcqzQsw6F8w5vYV49gQYmzMM1WuQcrXFVASqwThDgyb14\",\n",
      "                    \"metadata\": {\n",
      "                        \"dc:format\": \"application/pdf; version=1.7\",\n",
      "                        \"dc:title\": \"Diabetic retinopathy identification using parallel convolutional neural network based feature extractor and ELM classifier\",\n",
      "                        \"dc:description\": \"Expert Systems With Applications, 217 (2023) 119557. doi:10.1016/j.eswa.2023.119557\",\n",
      "                        \"dc:creator\": [\n",
      "                            \"Md. Nahiduzzaman\",\n",
      "                            \"Md. Robiul Islam\",\n",
      "                            \"Md. Omaer Faruq Goni\",\n",
      "                            \"Md. Shamim Anower\",\n",
      "                            \"Mominul Ahsan\",\n",
      "                            \"Julfikar Haider\",\n",
      "                            \"Marcin Kowalski\"\n",
      "                        ],\n",
      "                        \"dcterms:created\": \"2023-02-04T09:40:15Z\",\n",
      "                        \"dcterms:modified\": \"2023-02-07T17:54:35Z\",\n",
      "                        \"dc:language\": \"en\",\n",
      "                        \"dc:subject\": [\n",
      "                            \"Contrast limited adaptive histogram equalization (CLAHE),Diabetic retinopathy (DR),Parallel convolutional neural network (PCNN),Extreme LEARNING MACHine (ELM)\",\n",
      "                            \"Expert Systems With Applications, 217 (2023) 119557. doi:10.1016/j.eswa.2023.119557\"\n",
      "                        ]\n",
      "                    }\n",
      "                },\n",
      "                {\n",
      "                    \"file_index\": 3,\n",
      "                    \"file_cid\": \"QmZnh5Uuo7moZKMESFHpRjQFbbND5e3nArCzZg8uLARAgg\",\n",
      "                    \"metadata_cid\": \"QmZBwBxATjd85MZK9q6eSaX3tztcYbJzT34obDZmFKNE8K\",\n",
      "                    \"metadata\": {\n",
      "                        \"dcterms:created\": \"2023-02-07T10:24:44Z\",\n",
      "                        \"dcterms:modified\": \"2023-02-07T10:25:02Z\",\n",
      "                        \"dc:format\": \"application/pdf; version=1.7\"\n",
      "                    }\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"@type\": \"schema:ResearchProject\",\n",
      "            \"schema:identifier\": \"96858@test\",\n",
      "            \"schema:publicKey\": \"964dbc74f346b43a17060e1c451b5fd50873d0a2fe69188f32b2f8dbab052cfa\",\n",
      "            \"schema:description\": {\n",
      "                \"@context\": {\n",
      "                    \"schema\": \"http://schema.org/\",\n",
      "                    \"dc\": \"http://purl.org/dc/terms/\"\n",
      "                },\n",
      "                \"@type\": \"schema:ResearchProject\",\n",
      "                \"schema:name\": \"Analyzing the Influence of gene therapy on urban resilience\",\n",
      "                \"dc:abstract\": \"This paper analyzes how gene therapy influences urban resilience, providing insights into how to maximize its climate resilience.\",\n",
      "                \"schema:keywords\": [\n",
      "                    \"gene therapy\",\n",
      "                    \"urban resilience\",\n",
      "                    \"climate resilience\"\n",
      "                ],\n",
      "                \"schema:startDate\": \"2018-04-08\",\n",
      "                \"schema:endDate\": \"2026-06-05\",\n",
      "                \"schema:funding\": {\n",
      "                    \"@type\": \"schema:Organization\",\n",
      "                    \"schema:name\": \"National Science Foundation\"\n",
      "                },\n",
      "                \"schema:location\": {\n",
      "                    \"@type\": \"schema:Place\",\n",
      "                    \"schema:name\": \"Phuket, Thailand\"\n",
      "                }\n",
      "            },\n",
      "            \"schema:metadataCID\": \"QmRgbWW7QFgTWTRQqmjDv7fX6YypV8absEUSXwiw8f1Pn6\"\n",
      "        },\n",
      "        {\n",
      "            \"@type\": \"schema:ResearchProject\",\n",
      "            \"schema:identifier\": \"37887@test\",\n",
      "            \"schema:publicKey\": \"64593fc6dc0eb621cc258ffb3b180a171bcccb225bfea253084600c768776432\",\n",
      "            \"schema:description\": {\n",
      "                \"@context\": {\n",
      "                    \"schema\": \"http://schema.org/\",\n",
      "                    \"dc\": \"http://purl.org/dc/terms/\"\n",
      "                },\n",
      "                \"@type\": \"schema:ResearchProject\",\n",
      "                \"schema:name\": \"Analyzing the Influence of bioinformatics on climate adaptation\",\n",
      "                \"dc:abstract\": \"This paper analyzes how bioinformatics influences climate adaptation, providing insights into how to maximize its scientific discovery.\",\n",
      "                \"schema:keywords\": [\n",
      "                    \"bioinformatics\",\n",
      "                    \"climate adaptation\",\n",
      "                    \"scientific discovery\"\n",
      "                ],\n",
      "                \"schema:startDate\": \"2021-01-20\",\n",
      "                \"schema:endDate\": \"2028-06-16\",\n",
      "                \"schema:funding\": {\n",
      "                    \"@type\": \"schema:Organization\",\n",
      "                    \"schema:name\": \"World Wildlife Fund\"\n",
      "                },\n",
      "                \"schema:location\": {\n",
      "                    \"@type\": \"schema:Place\",\n",
      "                    \"schema:name\": \"Tokyo, Japan\"\n",
      "                }\n",
      "            },\n",
      "            \"schema:metadataCID\": \"QmT1cPcYNcGntxCc2goVmkJuQG9EdVthjvG6SVNs7WCXc8\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "Checking project with ID: '06535@test' against '06535@test'\n",
      "Match found for project ID: 06535@test\n",
      "Updated project 06535@test with new file entry: {'file_index': 4, 'file_cid': 'QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW', 'metadata_cid': 'QmY1iBM4gc3quCmVWbjjmFSoUwxqji9ff3gkX3MyVqypmj', 'metadata': {'dc:format': 'application/pdf; version=1.7', 'dc:title': 'COVID19-MLSF: A multi-task learning-based stock market forecasting framework during the COVID-19 pandemic', 'dc:description': 'Expert Systems With Applications, 217 (2023) 119549. doi:10.1016/j.eswa.2023.119549', 'dc:creator': ['Chenxun Yuan', 'Xiang Ma', 'Hua Wang', 'Caiming Zhang', 'Xuemei Li'], 'dcterms:created': '2023-02-04T09:40:15Z', 'dcterms:modified': '2023-02-07T16:52:03Z', 'dc:language': 'en-US', 'dc:subject': ['Stock market forecasting,COVID-19 pandemic,Multi-task learning,Feature fusion,K-nearest neighbor classifier', 'Expert Systems With Applications, 217 (2023) 119549. doi:10.1016/j.eswa.2023.119549']}}\n",
      "Successfully wrote updated data to datasets/projects.json\n",
      "----------------------------------------\n",
      "{'pdf:PDFVersion': '1.7', 'xmp:CreatorTool': 'Elsevier', 'pdf:docinfo:title': 'COVID19-MLSF: A multi-task learning-based stock market forecasting framework during the COVID-19 pandemic', 'pdf:hasXFA': 'false', 'access_permission:can_print_degraded': 'true', 'X-TIKA:Parsed-By-Full-Set': ['org.apache.tika.parser.DefaultParser', 'org.apache.tika.parser.pdf.PDFParser'], 'X-TIKA:content_handler': 'ToTextContentHandler', 'pdf:num3DAnnotations': '0', 'dc:format': 'application/pdf; version=1.7', 'pdf:docinfo:custom:robots': 'noindex', 'pdf:docinfo:creator_tool': 'Elsevier', 'access_permission:fill_in_form': 'true', 'pdf:docinfo:custom:CreationDate--Text': '7th February 2023', 'pdf:hasCollection': 'false', 'pdf:encrypted': 'false', 'dc:title': 'COVID19-MLSF: A multi-task learning-based stock market forecasting framework during the COVID-19 pandemic', 'pdf:containsNonEmbeddedFont': 'false', 'xmp:CreateDate': '2023-02-04T09:40:15Z', 'pdf:docinfo:custom:CrossMarkDomains[1]': 'elsevier.com', 'robots': 'noindex', 'pdf:docinfo:subject': 'Expert Systems With Applications, 217 (2023) 119549. doi:10.1016/j.eswa.2023.119549', 'pdf:hasMarkedContent': 'false', 'xmp:ModifyDate': '2023-02-07T16:52:03Z', 'pdf:docinfo:creator': 'Chenxun Yuan', 'pdf:docinfo:custom:CrossmarkMajorVersionDate': '2010-04-23', 'access_permission:extract_for_accessibility': 'true', 'resourceName': \"b'COVID19-MLSF--A-multi-task-learning-based-stock-market_2023_Expert-Systems-w.pdf'\", 'pdf:docinfo:custom:CrossMarkDomains[2]': 'sciencedirect.com', 'X-TIKA:Parsed-By': ['org.apache.tika.parser.DefaultParser', 'org.apache.tika.parser.pdf.PDFParser'], 'ElsevierWebPDFSpecifications': '7.0', 'pdf:docinfo:custom:doi': '10.1016/j.eswa.2023.119549', 'pdf:docinfo:custom:CrossmarkDomainExclusive': 'true', 'X-TIKA:embedded_depth': '0', 'CrossmarkDomainExclusive': 'true', 'pdf:annotationTypes': 'null', 'pdf:docinfo:producer': 'Acrobat Distiller 8.1.0 (Windows)', 'pdf:annotationSubtypes': 'Link', 'CreationDate--Text': '7th February 2023', 'doi': '10.1016/j.eswa.2023.119549', 'pdf:containsDamagedFont': 'false', 'pdf:unmappedUnicodeCharsPerPage': ['0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0'], 'dc:description': 'Expert Systems With Applications, 217 (2023) 119549. doi:10.1016/j.eswa.2023.119549', 'access_permission:modify_annotations': 'true', 'dc:creator': ['Chenxun Yuan', 'Xiang Ma', 'Hua Wang', 'Caiming Zhang', 'Xuemei Li'], 'dcterms:created': '2023-02-04T09:40:15Z', 'dcterms:modified': '2023-02-07T16:52:03Z', 'xmpMM:DocumentID': 'uuid:1b499bed-4ce8-4c0c-b682-0d58baae1cbe', 'CrossMarkDomains[1]': 'elsevier.com', 'pdf:overallPercentageUnmappedUnicodeChars': '0.0', 'pdf:docinfo:keywords': 'Stock market forecasting,COVID-19 pandemic,Multi-task learning,Feature fusion,K-nearest neighbor classifier', 'pdf:docinfo:modified': '2023-02-07T16:52:03Z', 'Content-Length': '4016043', 'Content-Type': 'application/pdf', 'xmp:MetadataDate': '2023-02-07T16:52:03Z', 'dc:language': 'en-US', 'pdf:producer': 'Acrobat Distiller 8.1.0 (Windows)', 'dc:subject': ['Stock market forecasting,COVID-19 pandemic,Multi-task learning,Feature fusion,K-nearest neighbor classifier', 'Expert Systems With Applications, 217 (2023) 119549. doi:10.1016/j.eswa.2023.119549'], 'pdf:docinfo:custom:ElsevierWebPDFSpecifications': '7.0', 'pdf:totalUnmappedUnicodeChars': '0', 'access_permission:assemble_document': 'true', 'xmpTPg:NPages': '16', 'pdf:hasXMP': 'true', 'pdf:charsPerPage': ['4308', '4046', '7115', '4551', '3567', '6426', '1218', '6119', '1896', '4055', '3517', '5861', '730', '833', '5274', '6307'], 'access_permission:extract_content': 'true', 'access_permission:can_print': 'true', 'CrossMarkDomains[2]': 'sciencedirect.com', 'meta:keyword': 'Stock market forecasting,COVID-19 pandemic,Multi-task learning,Feature fusion,K-nearest neighbor classifier', 'X-TIKA:parse_time_millis': '95', 'access_permission:can_modify': 'true', 'pdf:docinfo:created': '2023-02-04T09:40:15Z', 'CrossmarkMajorVersionDate': '2010-04-23'}\n",
      "{'metadata': {'pdf:PDFVersion': '1.7', 'xmp:CreatorTool': 'Elsevier', 'pdf:docinfo:title': 'Deep learning in insurance: Accuracy and model interpretability using TabNet', 'pdf:hasXFA': 'false', 'access_permission:can_print_degraded': 'true', 'X-TIKA:Parsed-By-Full-Set': ['org.apache.tika.parser.DefaultParser', 'org.apache.tika.parser.pdf.PDFParser'], 'X-TIKA:content_handler': 'ToTextContentHandler', 'pdf:num3DAnnotations': '0', 'dc:format': 'application/pdf; version=1.7', 'pdf:docinfo:custom:robots': 'noindex', 'pdf:docinfo:creator_tool': 'Elsevier', 'access_permission:fill_in_form': 'true', 'pdf:docinfo:custom:CreationDate--Text': '7th February 2023', 'pdf:hasCollection': 'false', 'pdf:encrypted': 'false', 'dc:title': 'Deep learning in insurance: Accuracy and model interpretability using TabNet', 'pdf:containsNonEmbeddedFont': 'false', 'xmp:CreateDate': '2023-02-04T09:40:15Z', 'pdf:docinfo:custom:CrossMarkDomains[1]': 'elsevier.com', 'robots': 'noindex', 'pdf:docinfo:subject': 'Expert Systems With Applications, 217 (2023) 119543. doi:10.1016/j.eswa.2023.119543', 'pdf:hasMarkedContent': 'true', 'xmp:ModifyDate': '2023-02-07T17:36:19Z', 'pdf:docinfo:creator': 'Kevin McDonnell', 'pdf:docinfo:custom:CrossmarkMajorVersionDate': '2010-04-23', 'access_permission:extract_for_accessibility': 'true', 'resourceName': \"b'Deep-learning-in-insurance--Accuracy-and-model-int_2023_Expert-Systems-with-.pdf'\", 'pdf:docinfo:custom:CrossMarkDomains[2]': 'sciencedirect.com', 'X-TIKA:Parsed-By': ['org.apache.tika.parser.DefaultParser', 'org.apache.tika.parser.pdf.PDFParser'], 'ElsevierWebPDFSpecifications': '7.0', 'pdf:docinfo:custom:doi': '10.1016/j.eswa.2023.119543', 'pdf:docinfo:custom:CrossmarkDomainExclusive': 'true', 'X-TIKA:embedded_depth': '0', 'CrossmarkDomainExclusive': 'true', 'pdf:annotationTypes': 'null', 'pdf:docinfo:producer': 'Acrobat Distiller 8.1.0 (Windows)', 'pdf:annotationSubtypes': 'Link', 'CreationDate--Text': '7th February 2023', 'doi': '10.1016/j.eswa.2023.119543', 'pdf:containsDamagedFont': 'false', 'pdf:unmappedUnicodeCharsPerPage': ['0', '0', '0', '0', '0', '0', '0', '0', '0', '0'], 'dc:description': 'Expert Systems With Applications, 217 (2023) 119543. doi:10.1016/j.eswa.2023.119543', 'access_permission:modify_annotations': 'true', 'dc:creator': ['Kevin McDonnell', 'Finbarr Murphy', 'Barry Sheehan', 'Leandro Masello', 'German Castignani'], 'dcterms:created': '2023-02-04T09:40:15Z', 'dcterms:modified': '2023-02-07T17:36:19Z', 'xmpMM:DocumentID': 'uuid:1b499bed-4ce8-4c0c-b682-0d58baae1cbe', 'CrossMarkDomains[1]': 'elsevier.com', 'pdf:overallPercentageUnmappedUnicodeChars': '0.0', 'pdf:docinfo:keywords': 'Deep Learning,Telematics,Connected Vehicles,Insurance,General Linear Model,XGBoost,Machine Learning,Explainable AI', 'pdf:docinfo:modified': '2023-02-07T17:36:19Z', 'Content-Length': '1697865', 'Content-Type': 'application/pdf', 'xmp:MetadataDate': '2023-02-07T17:36:19Z', 'dc:language': 'en', 'pdf:producer': 'Acrobat Distiller 8.1.0 (Windows)', 'dc:subject': ['Deep Learning,Telematics,Connected Vehicles,Insurance,General Linear Model,XGBoost,Machine Learning,Explainable AI', 'Expert Systems With Applications, 217 (2023) 119543. doi:10.1016/j.eswa.2023.119543'], 'pdf:docinfo:custom:ElsevierWebPDFSpecifications': '7.0', 'pdf:totalUnmappedUnicodeChars': '0', 'access_permission:assemble_document': 'true', 'xmpTPg:NPages': '10', 'pdf:hasXMP': 'true', 'pdf:charsPerPage': ['4694', '9144', '7582', '7133', '5283', '4337', '8096', '3645', '8070', '6797'], 'access_permission:extract_content': 'true', 'access_permission:can_print': 'true', 'CrossMarkDomains[2]': 'sciencedirect.com', 'meta:keyword': 'Deep Learning,Telematics,Connected Vehicles,Insurance,General Linear Model,XGBoost,Machine Learning,Explainable AI', 'X-TIKA:parse_time_millis': '91', 'access_permission:can_modify': 'true', 'pdf:docinfo:created': '2023-02-04T09:40:15Z', 'CrossmarkMajorVersionDate': '2010-04-23'}, 'content': '\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nDeep learning in insurance: Accuracy and model interpretability using TabNet\\n\\n\\nExpert Systems With Applications 217 (2023) 119543\\n\\nAvailable online 13 January 2023\\n0957-4174/ 2023 The Authors. Published by Elsevier Ltd. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).\\n\\nDeep learning in insurance: Accuracy and model interpretability \\nusing TabNet \\n\\nKevin McDonnell a,*, Finbarr Murphy a, Barry Sheehan a, Leandro Masello a,b, \\nGerman Castignani b,c \\n\\na KB3-040, Kemmy Business School, University of Limerick, Limerick V94 PH93, Ireland \\nb Motion-S S.A., Mondorf-les-Bains L-5610, Luxembourg \\nc University of Luxembourg, Esch-sur-Alzette L-4365, Luxembourg   \\n\\nA R T I C L E  I N F O   \\n\\nKeywords: \\nDeep Learning \\nTelematics \\nConnected Vehicles \\nInsurance \\nGeneral Linear Model \\nXGBoost \\nMachine Learning \\nExplainable AI \\n\\nA B S T R A C T   \\n\\nGeneralized Linear Models (GLMs) and XGBoost are widely used in insurance risk pricing and claims prediction, \\nwith GLMs dominant in the insurance industry. The increasing prevalence of connected car data usage in in-\\nsurance requires highly accurate and interpretable models. Deep learning (DL) models have outperformed \\ntraditional Machine Learning (ML) models in multiple domains; despite this, they are underutilized in insurance \\nrisk pricing. This study introduces an alternative DL architecture, TabNet, suitable for insurance telematics \\ndatasets and claim prediction. This approach compares the TabNet DL model against XGBoost and Logistic \\nRegression on the task of claim prediction on a synthetic telematics dataset. TabNet outperformed these models, \\nproviding highly interpretable results and capturing the sparsity of the claims data with high accuracy. However, \\nTabNet requires considerable running time and effort in hyperparameter tuning to achieve these results. Despite \\nthese limitations, TabNet provides better pricing models for interpretable models in insurance when compared to \\nXGBoost and Logistic Regression models.   \\n\\n1. Introduction \\n\\nThe increasing prevalence of connected car data and advancements \\nin Deep Learning (DL) has enhanced the ability to model driving \\nbehavior accurately. Profiling driver risk (e.g., aggressive driving \\nbehavior, context-related risk), in particular, has a societal benefit, \\nreducing accidents and emissions. Safer driving behavior can be \\nencouraged by using bespoke insurance products (i.e., dynamically \\npriced insurance based on driver competency) or feedback to the driver. \\nThese bespoke insurance products such as pay-as/how-you-drive are \\nbecoming more prevalent in the motor insurance industry as insurers use \\na combination of telematics and Machine Learning (ML) methods for \\nrisk pricing. Traditional risk pricing models, such as the Generalized \\nLinear Models (GLM), still dominate the insurance industry, particularly \\nwithin non-life lines of business. However, in order to truly capture the \\nrelationships between the ever-expanding universe of non-traditional \\ndata (e.g. telematics, satellite, machine vision) and actuarial pricing \\nresponses (e.g., claims frequency and severity), innovative pricing \\n\\nmechanisms must be used. The DL methods capacity to model complex, \\nnon-linear data overcomes many of the limitations of traditional pricing \\nmodels. Although, despite the increase in computational capabilities \\nafforded by DL and the availability of highly detailed telematics data, DL \\nis underutilized in insurance risk pricing and accident prediction. This \\nresearch demonstrates the usage of an alternative DL architecture, \\nTabNet, in insurance risk classification. \\n\\nDeep Learning is an ML model architecture that combines or con-\\nnects multiple layers to learn from data. This multi-layered approach \\nallows each layer to learn specific traits of the presented data (Good-\\nfellow, Bengio, & Courville, 2016). Advancements in DL have led to \\nhighly accurate models, outperforming traditional ML methods in \\nnumerous domains, such as autonomous driving, natural language \\nprocessing, and marketing (Goodfellow et al., 2016). In addition, these \\nDL models can learn complex data structures with minimal effort in pre- \\nprocessing and feature engineering (LeCun, Bengio, & Hinton, 2015). \\nHowever, insurance risk prediction models underutilize DL due to their \\nblack-box theoretical design/framework. As a result, the explainability \\n\\n* Corresponding author. \\nE-mail addresses: Kevin.McDonnell@ul.ie (K. McDonnell), Finbarr.Murphy@ul.ie (F. Murphy), Barry.Sheehan@ul.ie (B. Sheehan), Leandro.Masello@ul.ie \\n\\n(L. Masello), German.Castignani@motion-s.com (G. Castignani).  \\n\\nContents lists available at ScienceDirect \\n\\nExpert Systems With Applications \\n\\njournal homepage: www.elsevier.com/locate/eswa \\n\\nhttps://doi.org/10.1016/j.eswa.2023.119543 \\nReceived 26 January 2022; Received in revised form 8 July 2022; Accepted 9 January 2023   \\n\\nmailto:Kevin.McDonnell@ul.ie\\nmailto:Finbarr.Murphy@ul.ie\\nmailto:Barry.Sheehan@ul.ie\\nmailto:Leandro.Masello@ul.ie\\nmailto:German.Castignani@motion-s.com\\nwww.sciencedirect.com/science/journal/09574174\\nhttps://www.elsevier.com/locate/eswa\\nhttps://doi.org/10.1016/j.eswa.2023.119543\\nhttps://doi.org/10.1016/j.eswa.2023.119543\\nhttps://doi.org/10.1016/j.eswa.2023.119543\\nhttp://crossmark.crossref.org/dialog/?doi=10.1016/j.eswa.2023.119543&domain=pdf\\nhttp://creativecommons.org/licenses/by/4.0/\\n\\n\\nExpert Systems With Applications 217 (2023) 119543\\n\\n2\\n\\nor interpretability of DL insurance models is difficult to obtain (Baecke & \\nBocca, 2017; Paefgen, Staake, & Thiesse, 2013), which implies a chal-\\nlenge in terms of regulatory issues. Despite the ability of DL models to \\nlearn complex data structures, Deep Networks generalize poorly on \\ntabular datasets compared with other Classical ML models such as \\nSupport Vector Machines, Logistic Regression and naive Bayes classifier \\n(Arik & Pfister, 2021). Restrictions applied to granular telematics \\ndatasets cause further complications for using DL in insurance, as \\nnascent regulation requires the anonymization and processing of raw \\ntelematics data, ensuing that tabular datasets are commonplace in in-\\nsurance (Masello et al., 2022; McDonnell et al., 2021; Sheehan, Murphy, \\nRyan, Mullins, & Liu, 2017). Another significant limitation to their \\nadoption in insurance is their complex overparameterized configura-\\ntions (Wthrich, 2020). \\n\\nModels used for risk pricing need to be interpretable in insurance to \\nbe accepted by financial authorities (Bibal, Lognoul, de Streel, & Frenay, \\n2021). GLMs and Ensemble methods have proven effective in deter-\\nmining and quantifying risk for certain driving profiles and are regularly \\nused in insurance risk pricing (Ayuso, Guillen, & Nielsen, 2019; Shan-\\nnon, Murphy, Mullins, & Eggert, 2018; Wang & Xi, 2016; Wu, Zhang, & \\nDong, 2016). Additionally, GLMs are interpretable, a fundamental \\nproperty required to create premium pricing models for insurance \\n(Guelman, 2012). However, the performance of GLM can be constrained \\nby highly complex or high dimensional data, as the linear predictor \\ncannot accurately model high-dimensional covariate effects (Klein, \\nDenuit, Lang, & Kneib, 2014). Ensemble methods such as Random Forest \\nor XGBoost can learn complex data structures while also returning high \\nlevels of accuracy. However, these ensemble learning methods have \\ndrawbacks as complicated processes for both model-tuning and model \\ninterpretability can lead them to be unattractive for insurers (Pesantez- \\nNarvaez, Guillen, & Alcaniz, 2019). For this reason, black-box models \\nare unfavorable. \\n\\nThe limitations of GLM, XGBoost and DL can have varying implica-\\ntions for an insurers effectiveness in providing accurate pricing models \\nfor motor insurance. Additionally, both XGBoost and DL differ from GLM \\nin their ability to provide fully explainable and interpretable pricing \\nmodels, further limiting their usage. TabNet, a state-of-the-art DL ar-\\nchitecture, addresses the limitations of DL models. Arik and Pfister \\n(2021) introduced TabNet in their paper, citing comparative accuracy to \\nXGBoost. TabNet utilizes single deep learning, multi-step processing, \\nsequential attention, and gradient descent, creating an architecture that \\ndiffers from traditional DL while maintaining high accuracy and \\nproviding model interpretability. The combination of these design \\nchoices makes TabNet a suitable DL model for insurance risk pricing and \\naddresses the limitations of the other models. \\n\\nTo the best of our knowledge, this paper provides the first adoption \\nof TabNet (Arik & Pfister, 2021) for insurance risk classification via \\nclaims prediction. In this article, TabNet is compared against GLM and \\nXGBoost to demonstrate its effectiveness in accuracy, interpretability, \\nand minimizing effort in feature training. For completeness, an addi-\\ntional experiment introduces a LightGBM and Neural Network to test \\nTabNets predictive qualities. This state-of-the-art DL architecture pro-\\nvides highly efficient policyholder risk prediction for insurers, using a \\ncombination of connected car data and traditional policyholder data. \\nThe implications of using this novel approach allow insurers to price \\nindividual drivers on their driving performances better when compared \\nto traditional pricing models. \\n\\nGLMs have widespread adoption in insurance risk classification and \\npricing due to their ability to capture the parameterized relationship \\nbetween variables in driver risk classification and their response or ef-\\nfects (McCullagh & Nelder, 2019; Renshaw, 1994). The occurrence of \\nclaims or accidents is infrequent; therefore, distributions such as the \\nnormal distribution inadequately model these sparsely distributed ac-\\ncidents and claims. The GLM can vary its assumptions about the distri-\\nbutions of its response variables, allowing for the usage of distributions, \\nsuch as Poisson regression (Ma, Zhu, Hu, & Chiu, 2018), that can better \\n\\napproximate relationships between risk factors and accidents. Addi-\\ntionally, GLMs are highly interpretable due to the generalized form of \\ndistribution and link-function selection. Due to these generalized terms, \\ninteractions between weights and variables of the GLM on a dataset can \\nbe easily interpreted (Molnar, 2020). \\n\\nCombining classical policyholder data with telematics data has \\nincreased an insurers ability to price policies accurately. Verbelen, \\nAntonio, and Claeskens (2018) demonstrate the effectiveness of this \\napproach by combining these traditional factors with telematics data to \\npredict claims. The authors utilized a variant of the GLM, a Generalized \\nAdditive Model, to model risk effectively through telematics data. The \\nGLM model highlighted exposure or mileage as a primary contributing \\nfactor to a policyholders risk. Another variant of GLM, Poisson \\nRegression, also provided accurate risk profile predictions for Ma et al. \\n(2018). When combining traditional and telematics data, their GLM \\nmodel identified mileage, traveling at peak times, and driving behaviors \\nsuch as harsh braking as highly correlated with driver accidents. Addi-\\ntionally, their model identified speeding and relative speed as risk fac-\\ntors. Thus, GLM models can provide premium pricing models for \\ninsurers while also providing interpretable results, exposing significant \\nfeatures contributing to a policyholders risk. \\n\\nAlthough GLMs have proven effective at driver risk identification \\nand premium pricing, there are limitations to using these models. Linear \\npredictors find difficulty obtaining optimal solutions when learning \\nfrom complex or high-dimensional data; this results in a GLM ineffi-\\nciently capturing the correlations in the dataset leading to poor gener-\\nalization (Klein et al., 2014). This limitation implies that models, which \\nuse linear predictors, may be unsuitable for predicting risky behaviors \\nfrom high-dimensional telematics data. GLMs also require tedious \\nmanual pre-processing, feature engineering and model building pro-\\ncesses to extract the relevant correlations and covariate effects on crash \\ndata or claims data (Henckaerts, Antonio, Clijsters, & Verbelen, 2018). \\n\\nEnsemble ML algorithms have risen in popularity in the insurance \\ndomain. These machine learners can learn complex data structures, \\nreducing the need for extensive feature engineering and provide inter-\\npretable results for insurers (Guelman, 2012). Ensemble methods \\ncombine base classifiers to produce one optimal predictive model. For \\nexample, a decision tree is a tree-based structure algorithm used to \\npredict a class or value by learning simple decision rules. Singular de-\\ncision trees, however, are prone to overfitting and variable selection bias \\n(Quan & Valdez, 2018). Combining decision trees in an ensemble \\nmethod such as Random Forest or Gradient Boosting improves the \\nperformance of these base classifiers, reducing overfitting tendencies \\nand significantly improving the accuracy of these models. \\n\\nEnsemble methods used in driver behavior risk scoring have greatly \\nimproved risk pricing models prediction accuracy, outperforming GLMs \\non the same task. An important waypoint in advocating the value of \\nensemble methods in risk pricing is Guelman (2012), who compared \\nGLM and Gradient Boosted Trees (GBT) on driver risk classification. The \\nGBT model could outperform the GLM on risk pricing based on tradi-\\ntional risk factors and accident data. A comprehensive study by Noll, \\nSalzmann, and Wuthrich (2018) compared variants of ensemble \\nmethods against Neural Networks and GLM. The study showed that \\nensemble methods performed better than GLM when predicting claims \\non traditional pricing features. In particular, GBT outperformed Random \\nForest on the same dataset. Recent studies by Pesantez-Narvaez et al. \\n(2019) and Maillart (2021) combine the predictive power of ensemble \\nmethods with driver behavioral data. In Mailarts paper, ensemble \\nmethods were compared against a GLM, providing accurate and \\nexplainable results while reducing the need for extensive preprocessing \\nand feature engineering. \\n\\nThere are limitations to using ensemble methods for insurance risk \\npricing. Ensemble methods have basic levels of interpretability; for an \\ninsurer, gaining sufficient levels of model interpretability for auditing or \\nfinancial regulatory purposes from these models is a complex task \\n(Henckaerts, Cote, Antonio, & Verbelen, 2021; Noll et al., 2018). \\n\\nK. McDonnell et al.                                                                                                                                                                                                                             \\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119543\\n\\n3\\n\\nEnsemble methods can also be challenging to train. The fine-tuning of \\nthe hyper-parameters can be a difficult task and, when compared to \\nsimpler models such as Logistic Regression, the reward for the additional \\neffort can sometimes be negligible (Pesantez-Narvaez et al., 2019). \\n\\nDL has drastically changed the landscape of natural language pro-\\ncessing, image recognition, and autonomous driving. However, these \\npowerful models have limited usage in insurance pricing and risk clas-\\nsifications tasks. DL is a multi-layered approach to learning, where each \\nlayer extracts latent features and updates connected nodes and weights \\naccording to their relevance to scoring (Goodfellow et al., 2016). A \\nmixture of feed-forward and backpropagation steps ensures that each \\nweight is adjusted accordingly between the hidden layers of the \\nnetwork, where each layer outputs a vector of learned salient features, \\nfeeding this output vector to the next layer. \\n\\nStudies employing DL models in insurance risk classification and \\npricing are limited. However, there is growing adoption of these highly \\naccurate models. Before the growth of DL models, numerous studies \\ntested the feasibility of DL in insurance risk pricing. Paefgen et al. (2013) \\ndemonstrated the effectiveness of DL in predicting accident risk from \\ntelematics data. The authors compare a DL model with Logistic \\nRegression and Decision Tree models. Although the DL model out-\\nperformed the other models in various metrics, Paefgen et al. (2013) \\nchose Logistic Regression as their favored choice due to the low inter-\\npretability of the DL model. In a similar study, Baecke and Bocca (2017) \\ncompared a DL model with a Random Forest and Logistic Regression \\nmodel on driver risk classification using telematics data. Like Paefgen \\net al. (2013), Baecke and Bocca (2017) also decided that the Logistic \\nRegression model was the best choice, although the DL outperformed \\nthe other models on various categories. In addition to the above studies, \\nnumerous authors introduced specially tailored DL models for insur-\\nance. For instance, in their comparative model study, (Noll et al., 2018) \\nintroduced a shallow, deep Neural Network (NN) architecture for DL on \\na telematics dataset for intended insurance use. (Noll et al., 2018) made \\nsignificant changes to the NN model, with the highest performance \\nachieved by introducing an exposure feature layer to the network, out-\\nperforming GLM and Ensemble methods on the task of claim prediction. \\nAn alternative DL architecture by (Siami, Naderpour, & Lu, 2021) cre-\\nates a three-step approach to driver behavior extraction for subsequent \\nrisk analysis. In their paper, (Siami et al., 2021) reduce the complexity of \\ntelematics data processing the data using a self-organizing map (SOM). \\nA 9-layer deep autoencoder extracts relevant features before a k-means \\nalgorithm clusters the dataset in the final two steps. The resulting \\nclusters identify specific risky driver behaviors or patterns contributing \\nto a drivers overall risk. \\n\\nLearning from tabular data can be challenging for DL models to find \\nan optimal solution, as the sparse and heterogeneous tabular datasets \\nlimit the DL models ability to find an appropriate inductive bias (Arik & \\nPfister, 2021; Shavitt & Segal, 2018; Xu, Skoularidou, Cuesta-Infante, & \\nVeeramachaneni, 2019). Additionally, due to regulation, the limitation \\nof access to granular telematics data combined with low interpretability \\nis a crucial obstacle to the widespread adoption of DL models in insur-\\nance risk pricing (Baecke & Bocca, 2017; McDonnell et al., 2021; Paef-\\ngen et al., 2013). \\n\\nThis research extends on the works of Arik and Pfister (2021), \\nPaefgen et al. (2013), and Pesantez-Narvaez et al. (2019) by using a DL \\nmodel, TabNet, for insurance risk pricing. Furthermore, this research \\nprovides the first comparison of TabNet, ML and traditional insurance \\npricing models. TabNet for insurance pricing offers accuracy with high \\nmodel interpretability and reduced effort in data pre-processing. In \\naddition, this model is capable of predicting accidents by combining \\ntelematics data and insurance claims. The rest of this paper is organized \\nas follows: Section 2 describes the dataset and pre-processing steps, \\nSection 3 outlines the methodology, Section 4 and Section 5 discusses \\nthe results in detail; finally, Section 6 provides a conclusion and future \\nwork. \\n\\n2. Data \\n\\nThe dataset used in this study is a synthetic telematics dataset pro-\\nvided by So et al. (2021). This synthetic data is modeled on a real dataset \\nprovided by a Canadian insurer and generated using Synthetic Minority \\nOversampling Tech (SMOTE) and a feedforward Neural Network (NN) \\nfor data simulation. For evaluation purposes, the usage of Poisson and \\nGamma Regression ensures that the distribution of claims data links to \\nthe sparsity of actual data claims. \\n\\nThe dataset contains 100,000 data samples and 52 variables divided \\ninto three categories: Traditional data (Car age, Insured Age, gender), \\nTelematic data (total miles driven, harsh acceleration, harsh braking), \\nand Response Data (number of claims and aggregate number of claims). \\nThe breakdown of features per category is 11 Traditional Features, 39 \\ntelematics features, and 2 response variables. Table 1 contains a sum-\\nmary of the features and datatypes. \\n\\nThe response column within this dataset contains two variables, \\nNB_Claim and AMT_claim. As per Table 1, AMT_Claim is the aggregated \\nsum of claims paid out from the insurance company, and NB_Claim is the \\nnumber of claims made by a policyholder account. A driver with \\nNB_Claim = 1 and AMT_Claim<1,000 may indicate first-party damage \\nrather than a high-risk driver with third-party damages. Therefore, \\ndistinguishing between risky and non-risky drivers requires the creation \\nof a new response column. The definition of this new response variable \\nClaimYN is as follows: where NB_Claim > 1 & AMT_Claim >1,000, \\n\\nTable 1 \\nSummary and descriptions of Traditional and Telematic variables in synthetic \\ndataset (So et al., 2021).  \\n\\nCategory Feature Names Description Datatype \\n\\nTraditional Marital \\nInsured.sex \\nCar.use \\nRegion \\nTerritory \\n\\nMarital Status  \\n\\nGender: Male/Female \\nPrivate/Commute/Farmer/ \\nCommercial \\nRural/Urban \\nLocation of Vehicle \\n\\nCategorical \\n\\nDuration \\nInsured.age \\nCar.age \\nCredit.score \\nAnnual.miles. \\ndrive \\nYears.noclaims \\n\\nPolicy in days  \\n\\nAge in years \\nVehicle age in years \\nCredit score of Policyholder \\nExpected miles of driver \\nYears without claims \\n\\nNumerical \\n\\nTelematic Total.miles.driven \\nAvgdays.week \\nAccel.xxmiles* \\nBrake.xxmiles* \\nLeft.turn. \\nintensityxx* \\nRight.turn. \\nintensityxx* \\n\\nTotal Miles \\nMean aggregated days per week \\nHarsh Acc in mph (xx) per 1000 \\nmiles \\nHarsh Brake in mph (xx) per \\n1000 miles \\nLeft turn per 1000 miles with \\nintensity xx  \\n\\nRight turn per 1000 miles with \\nintensity xx \\n\\nNumerical  \\n\\nAnnual.pct.driven \\nPct.drive.(day) \\nPct.drive.xhrs \\nPct.drive.wkxxx*  \\n\\nPct.drive.rushxx* \\n\\nAnnual percentage for time on \\nroad  \\n\\nDriving percentage for a given \\nday of week \\nHours of driving percentage for \\nhourly period \\nDriving percentage for a given \\nwk(end/day)  \\n\\nDriving percentage during rush \\nhour (am/pm) \\n\\nPercentage \\n\\nResponse NB_Claim \\nAMT_Claim \\nClaimYN** \\n\\nNum of policy claims \\nTotal claims amount \\nRisky drivers \\n\\nNumerical \\n\\n*xx values pre-defined buckets of values rather than random variables. \\n**Newly created variables, not in original dataset. \\n\\nK. McDonnell et al.                                                                                                                                                                                                                             \\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119543\\n\\n4\\n\\nClaimYN = 1 (driver is a risk) else ClaimYn = 0 (driver is not a risk). \\nCreating the response variables as per the above definition yields 97,302 \\nClaimYN = 0 and 2698 ClaimYN = 1 values. \\n\\n3. Methodology \\n\\nThe following section describes the approach of classifying driver \\nrisk using driver behavioral data from telematics and comparing the \\nperformance of TabNet against GLM and XGBoost. Driver features are \\ndefined as x0, x1,, xn, where x is a drivers feature (e.g. harsh accel-\\neration event, harsh braking event, distance traveled) and n is the total \\nnumber of features in the dataset. The target variable ClaimYN, for risk \\nclassification, is defined in section 2. \\n\\nTo demonstrate the intrinsic benefits of TabNet as a suitable risk \\npricing model, TabNet needs to achieve comparable or better perfor-\\nmance than traditional risk insurance models GLM & XGBoost. This \\nstudys evaluation of TabNet compares TabNets accuracy, model \\ninterpretability, and the reduced need for involved feature engineering \\nprocesses. Comparing the accuracy of each model will use additional \\nscoring metrics to gain further insights into each models predictive \\nprowess. These scoring metrics are: F1-Score, Precision, Recall, Area \\nUnder the Curve (AUC), Receiver Operating Characteristic (ROC), ac-\\ncuracy and Matthews Correlation Coefficient. Evaluation of model \\ninterpretability requires each model to provide clear and insightful de-\\nscriptions of data trends and identify reasonable significant risk factors. \\nAdditionally, three levels of pre-processing requirements evaluate each \\nmodels ability to provide accurate results with different levels of pre- \\nprocessing effort. Models, which require less effort to provide accurate \\nresults, indicate to insurers the models suitability for usage. Table 2 \\ncontains a summary of the evaluation methods used in this study. \\n\\n3.1. TabNet \\n\\nTabNet is a single deep learning model based on sequential multistep \\nprocessing (Arik & Pfister, 2021). This single deep architecture assists in \\nfeature selection and improves the capacity to learn high-dimensional \\nfeatures. Each nth step processes a D-dimensional feature vector, \\nwhere each step outputs to a Feature Transformer block. This Feature \\nTransformer block contains multiple layers, either shared across deci-\\nsion steps or unique to a decision step. Each block contains fully- \\nconnected layers, a batch normalization layer, and a Gated Liner Unit \\n(GLU) activation. Additionally, the GLU connects to a normalization \\n\\nresidual connection; this helps stabilize the variance throughout the \\nnetwork. This multi-layered block assists in feature selection and in-\\ncreases the parameter efficiency of the network. Fig. 1 provides a \\ndetailed description of TabNet architecture. \\n\\nThe Feature Transformer connects to the Attentive Transformer and \\nMask; these processes ensure robust feature selection per step. The \\nAttentive Transformer is a multi-layered block with fully connected and \\nbatch normalization layers. The Attentive Transformer and masking \\nprocedure is formulated by \\n\\na[i  1] : M[i] = sparsemax(P[i  1].hi([a  1])) (1)  \\n\\nwhere a[i  1] is the previous step, P[i] is the priori scale and hi some \\ntrainable function. Two key elements of the Attentive Transformer are \\nthe sparsemax activation function and the prior. Sparsemax reduces \\ndimensionality by introducing sparsity into feature vectors; and then \\nprojecting these features onto a probability map in Euclidean space. \\nEach projected feature vector now has an associated probability, \\nassisting in model interpretability. The prior scale term, P[i], denotes the \\nsaliency of a feature throughout the previous steps and is defined as \\n\\nP[i] = i\\nj=1(  M[j]) (2)  \\n\\nwhere  defines the relationship between enforcement of a feature at one \\ndecision step or multiple steps. When  = 1 the feature is enforced at the \\ngiven step and multiple steps when  = 0. The Attentive Transformer \\nselects the most salient features to form the transformed feature vector \\nand passes these features to the learnable Mask, M[j]. The Mask enables \\ninterpretability and further improves upon feature selection from the \\nAttentive Transformer. Mbj[i] defines the jth feature of the bth sample; \\nwhen Mbj[i] = 0, there is no contribution from the feature at that step. \\nAggregating these Masks at each step creates a coefficient that weights \\nthe importance of each step in a final decision. \\n\\nTabNet can provide both local and global model interpretability, \\nwith local interpretability an intrinsic element in TabNets design. \\nGlobal interpretability is obtained through the Python library Scikit- \\nlearn (Pedregosa et al., 2011), while local interpretability is obtained \\nby accessing TabNets decision masks. Each mask scores features, which \\ncontributed to the model decision at that step, and each step produces a \\nmask. TabNet is available through PyTorch version 3.1.1 (Pytorch- \\nTabnet, 2021). \\n\\n3.2. XGBoost \\n\\nExtreme Gradient Boosting (XGBoost) is an ensemble boosting tree \\nalgorithm. This fast and efficient ML algorithm can outperform other ML \\nmodels in accuracy, speed, and efficiency (Chen & Guestrin, 2016). \\nBoosting is an inherent feature of XGBoost, where previous weak \\nlearners are boosted by creating new models. These models are com-\\nbined to make a final prediction. Gradient descent is used during the \\nnew model creation process to minimize the loss. XGBoost deviates from \\nboost or gradient boosting through the incorporation of regularization \\n(Lasso & Ridge Regression), tree creation parallelization, and tree \\npruning (after the tree has grown to max depth, start from the bottom \\nand traverse up pruning invalid decisions). This approach uses featur-\\ne_importances to return global model interpretability in XGBoost. \\n\\n3.3. GLm \\n\\nThe GLM model is a generic form of the linear model. Unlike the \\nLinear Regression model, GLM does not make assumptions on the dis-\\ntribution of the trainable data. For example, a normal distribution does \\nnot accurately represent sparsity in claims data. The correct choice of \\ndistribution and link-function is necessary to provide accurate pre-\\ndictions of risk. The GLM model can be formally defined as follows \\n\\ng(EY(y  x)) = 0 + 1x1 ++ pxp (3) \\n\\nTable 2 \\nSummary of the evaluation methods used in this study. Model \\nevaluation is divided into three categories, Scoring, Interpret-\\nability and Pre-processing. Scoring refers to model performance \\nmetrics such as F1-score or accuracy. Using the pre-processing \\nmethods listed, a high-scoring model with minimal user involve-\\nment indicates a good choice for an insurer. A model is highly \\ninterpretable if it can provide global and local interpretability and \\ninsights into telematics data using the interpretability methods.  \\n\\nCategory Method \\n\\nScoring F1-Score  \\n\\nPrecision \\nRecall \\nAccuracy \\nAUC \\nROC \\n\\nInterpretability Feature Importance  \\n\\nExplain Matrix \\nPre-Processing Data Normalization \\n\\nData Standardization  \\n\\nHyper-parameter tuning \\nFeature Engineering  \\n\\nK. McDonnell et al.                                                                                                                                                                                                                             \\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119543\\n\\n5\\n\\nwhere g defines the link function and EY the probability distribution. The \\nchoice of GLM for this study is the Logistic Regression model. Scikit- \\nlearns implementation of Logistic Regression does not contain the \\nfeature_importances attribute; instead, the regression coefficients were \\nused which reflect whether a feature contributed to the negative case (e. \\ng., ClaimYN = 0, if coefficient < 0); conversely, positive values indicate \\nthe positive case (e.g., ClaimYN = 1, if coefficient > 0). \\n\\n3.4. Pre-processing level 13 \\n\\nTo demonstrate how using a DL model such as TabNet reduces the \\nneed for involved model building and feature engineering, TabNet is \\ncompared against XGBoost and GLM testing various degrees of pre- \\nprocessing. The initial test restricts the capabilities of the GLM, \\nXGBoost, and TabNet models by passing raw data to each model and \\nrunning with the default hyperparameters. The only pre-processing that \\noccurs in this step is simply encoding categorical columns. The purpose \\nof this restricted test run is to document each models performance with \\nlimited effort in pre-processing. Subsequent levels of testing require \\nmore involved pre-processing, feature engineering, and model building \\nsteps. The second level of pre-processing involves scaling and data \\nnormalization, along with minor model hyperparameter tuning. Data \\nnormalization for this step is simply StandardScaler and MinMaxScaler. \\n\\nThe final level requires more involved feature engineering and model \\nbuilding steps. Standardization and normalization steps continue from \\nthe previous level. The features Accel.xxmiles, Brake.xxmiles, Left.turn. \\nintensityxx and Right.turn.intensityxx, signifies harsh driving events. \\nThese values are highly correlated and will benefit from being aggre-\\ngated. Therefore, aggregating related harsh driving events to assist in \\nthis steps feature engineering requirement. The optimal hyper-\\nparameters for each model were extracted using RandomizedSearchCV \\nwith 10-fold-cross validation. \\n\\nThis study introduces a state-of-the-art model, LightGBM, and a \\nNeural Network (NN) in a final test to determine the robustness of \\nTabNets ability to predict claims. The LightGBM and NN undergo the \\nsame training and testing processes described in 3.4. In addition, the \\nLightGBM model requires a similar setup to the XGBoost in hyper-\\nparameter tuning. The NN, however, requires more involved tuning due \\n\\nto configuration requirements for hidden and dropout layers and nodes. \\nThis final test for completeness provides an additional endorsement for \\ndetermining TabNets suitability for real-life insurance uses. \\n\\n4. Results \\n\\nThe following section describes the performance of TabNet \\ncompared with GLMs and XGBoost for both Classification and Regres-\\nsion tasks. For each round of model fitting and evaluation, an 80/20 split \\nof training and test dataset combined with 10-fold cross-validation \\nensure the integrity of each models performance metrics. \\n\\nTable 3 illustrates each models returned accuracy per level. Each \\nmodel scores high accuracy for each level; however, due to the sparsity \\nof driver claims, i.e., relatively few claims in the data, this metric can be \\n\\nFig. 1. Architecture of TabNet. Each step contains an attentive transformer, mask, feature transformer, split node and ReLu activation. Steps are sequential, \\nincreasing up to N steps before connecting to a fully connected layer and the output. Attentive Transformer contains a fully connected layer, batch normalization, \\nprior scale and sparsemax dimensionality reduction. The mask function outputs significant feature contributions for aggregation. When Mb,j[i] = 0, there is no feature \\ncontribution. \\n\\nTable 3 \\nReturned results for each model per level of preprocessing. Compared to \\nXGBoost and Logistic Regression, TabNet scores highest in F1-Score in three out \\nof two levels. Additionally, the model returns the highest Recall values overall. \\nXGBoost scores highest in precision and AUC in all three rounds of testing. Lo-\\ngistic Regression is the worst performing model of the three. Each model returns \\na high accuracy value. However, high accuracy does not sufficiently represent \\nthe performance of each model in predicting claims, as demonstrated by the \\nvarying F1, Precision, Recall and AUC values. Therefore, Matthews Correlation \\nCoefficient can assist in determining model performance on an unbalanced \\ndataset. XGBoost and TabNet score relatively closely using this metric, although \\nXGBoost edges TabNet in two out of three rounds.  \\n\\nModel Performance \\n\\nLevel Model Precision Recall F1- \\nScore \\n\\nAUC Accuracy M \\nCorr \\n\\n1 TabNet  0.55  0.20  0.30  0.86  0.97  0.32 \\nLR  0.11  0.00  0.00  0.73  0.97  0.01 \\nXGB  0.85  0.19  0.31  0.90  0.98  0.34 \\n\\n2 TabNet  0.66  0.53  0.59  0.88  0.98  0.58 \\nLR  0.25  0.00  0.00  0.81  0.97  0.01 \\nXGB  0.85  0.37  0.51  0.91  0.98  0.54 \\n\\n3 TabNet  0.66  0.55  0.60  0.87  0.98  0.59 \\nLR  0.33  0.00  0.01  0.80  0.97  0.03 \\nXGB  0.88  0.42  0.57  0.91  0.98  0.6 \\n\\nM Corr = Matthews Correlation, LR = Logistic Regression, XGB = XGBoost. \\n\\nK. McDonnell et al.                                                                                                                                                                                                                             \\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119543\\n\\n6\\n\\nmisleading if a simple model only predicts no crash events. For this \\nreason, f1-score, precision, recall, AUC, ROC and Matthews Correlation \\nCoefficient are considered valuable metrics for model assessment. When \\ncomparing the three models scores, TabNet returns the highest F1-Score \\nfor all three levels of testing, also having the highest recall scores for two \\nout of three levels. Additionally, TabNet provides the most balanced set \\nof results compared to the two other models. In contrast, XGBoost has \\nreturned the highest Precision and AUC score. Both TabNet and XGBoost \\nhave comparable performance with Matthews Correlation, with \\nXGBoost scoring higher in the first round. Logistic Regression performs \\npoorly throughout the testing, failing to predict potential claims or ac-\\ncidents accurately. Fig. 2 summarizes each models performance for \\nAUC and ROC. \\n\\nAs per the methodology, each round of testing requires minimal to \\ninvolved preprocessing steps. For the second round of testing, XGBoost \\nrequired only two changes to its hyperparameters to improve its per-\\nformance, while TabNet required three, including an increase in epochs. \\nAs a result, the running time for TabNet doubled. Tuning the hyper-\\nparameters of Logistic Regression had little impact on the model per-\\nformance, with a marginal increase in precision recorded for the model. \\nFinally, RandomizedSearchCV was used to improve each models score \\nby selecting hyperparameters randomly in a given range, and the best \\nscore for a set of hyperparameters was retained. The optimal parameter \\nselection had minimal impact on TabNets and Logistic Regressions \\nmodel performance, although XGBoost improved from the parameter \\ntuning. Tuning TabNets scores via RandomizedSearchCV was difficult \\n\\ndue to a substantial increase in model running time, and the scope of the \\nrandom search was severely limited. Despite the attempts to improve the \\nLogistic Regression score, the model still fails to identify driver risk from \\nthe dataset. In a final test for completeness, TabNet underwent addi-\\ntional analysis against a LightGBM and NN. The LightGBM and NN \\nprovided disappointing results despite the increased efforts required for \\ntraining. The LightGBM and NN failed to score higher than 0.2 in f1- \\nscore and Matthews Correlation coefficient, respectively. \\n\\nModel interpretability is a core component in analyzing and evalu-\\nating each models performance in this study. Comparing each models \\nfeature importance and model coefficients gives insight into model de-\\ncisions. Table 4 contains a detailed breakdown of each models returned \\nfeature importances. The NN and LightGBM tests did not introduce \\nsignificant insights into model decisions not already captured by Tab-\\nNet, XGBoost or Logistic Regression. As expected, extracting informa-\\ntion from the NN, in particular, proved a difficult challenge. \\n\\nTabNet can return the decision mask used internally for decision- \\nmaking, enabling further insight into local model interpretability. For \\nexample, the first mask returned from the model shows that both \\ntraditional and telematics variables contribute to model decisions at a \\nlocal level, with Right.turn.intensity11 scoring highly. Subsequent \\nmasks signify that Total.miles.driven, Accel.09miles and Duration have \\ncontributed to the model decision at a particular step. The internal mask \\nis an inherent property of TabNet; therefore, accessing and using this \\nproperty is easy. Comparing similar functionality with XGBoost and \\nother ML models, TabNet excels at providing in-depth model analytics \\n\\nFig. 2. AUC and ROC curves for each model per level of testing. XGBoost consistently returns the highest AUC values. However, as per the Precision-Recall Curve, \\nTabNet returns the most balanced recall/precision values, while XGBoost scores low in recall and high in precision consistently. Additionally, TabNet scores highest \\nin f1-score for levels two and three despite decreasing precision. Logistic Regression performs slightly better than no skill for Precision and Recall but still maintains a \\nhigh AUC score. \\n\\nK. McDonnell et al.                                                                                                                                                                                                                             \\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119543\\n\\n7\\n\\nwithout additional software. In this study, only Logistic Regressions \\nmodel coefficients match the ease of providing these interpretable re-\\nsults. Fig. 3 presents each mask per level of testing. \\n\\nTable 5 contains a summation of each models key attributes and \\nfeature interpretability capabilities. \\n\\n5. Discussion \\n\\nAs per the results presented in Section 4 TabNet provides high levels \\nof model interpretability and accuracy. TabNet was able to detect and \\nclassify driver risk using a combination of both traditional and tele-\\nmatics variables. When compared to XGBoost, TabNet can outperform \\nthis model on some classification metrics. However, XGBoost requires \\nless intensive processing and hyperparameter tuning to achieve high \\nlevels of accuracy. When comparing each models ability to provide \\ninterpretable results, TabNet exceeds XGBoost and GLM by returning \\nboth global and local interpretability. \\n\\n5.1. Model performance \\n\\nTabNet is a robust DL algorithm that has shown promising results for \\nthe task of Risk classification. However, training the TabNet model \\nposed some challenges, which prevented the model from demonstrating \\nthe same learning capabilities as other DL models. The TabNet model \\ntends to overfit the data and despite adjusting the available regulari-\\nzation parameters (the decision prediction and attention embedding \\nlayers); this had a marginal effect on the model performance. This form \\nof regularization is not as sophisticated as DL equivalents such as \\ndropout or weight constraint (Goodfellow et al., 2016). Additionally, \\ncriticisms of DL being over-parameterized and difficult to train also \\napply to TabNet. With limited hardware resources, training TabNet can \\ntake a considerable amount of time. XGBoost in comparison excels in \\nmost fields, with less extensive model building or effort required for \\ngood generalization. \\n\\nThe performance of Logistic Regression compared to both TabNet \\nand XGBoost demonstrates the limitations of GLM in classifying risk on a \\nhighly dimensional dataset, including both traditional and telematics \\nvariables. Logistic Regression performed poorly on the f1-score in \\nparticular and could not provide accurate estimates of precision and \\nrecall. PCA was used to reduce the dimensionality and complexity of the \\n\\ndataset for the final phase of testing, although the improvement to \\nmodel performance was insignificant. Logistic Regression still per-\\nformed well in AUC and ROC but never surpassed the performance of \\nTabNet or XGBoost. The poor model performance demonstrates that the \\nmodel found difficulty in correctly distinguishing between risky and \\nnon-risky drivers from the telematics data. \\n\\nDespite the aforementioned limitations of TabNet, the results are \\npromising for the usage of this model in detecting claims from telematics \\ndata. TabNet could predict higher Recall and f1-scores than XGBoost and \\nLogistic Regression on most tasks. For insurers, this is an important \\nscoring metric, as high levels of Recall infer the models capability in \\ndetecting true positive cases of risky driving behavior. In addition, ROC \\nand AUC metrics do not fully represent the sparsity of claims in the \\ndataset, high values of this score are misleading. As a result, the high f1- \\nscore and Matthews Correlation Coefficient from TabNet signify that \\nthe model captures the sparsity in claims data, outperforming or \\nequaling XGBoost. The addition of the final test for robustness also \\ndemonstrates TabNets potential for usage in insurance. The LightGBM \\nand NN models did not achieve any notable improvements in f1-score, or \\nMatthews Correlation Coefficient even when compared against the \\nLogistic Regression model. In addition, the LightGBM and NN required \\nextensive effort to achieve their training score, while TabNet and \\nXGBoost required less training for better performance. Since TabNet is a \\nDL model, access to larger datasets could drastically improve predictive \\nperformance. Model performance may also improve if trained on a real \\ndataset instead of a synthetic dataset, as this data may not fully represent \\nthe chosen target variable. \\n\\nThe final test conducted compared an additional two models against \\nTabNet. These models did not achieve any notable improvements in f1- \\nscore, or Matthews Correlation Coefficient even when compared \\nagainst the Logistic Regression model. In addition, the LightGBM and \\nNN required extensive effort to achieve their training score, while \\nTabNet and XGBoost required less training for better performance. \\n\\n5.2. Model interpretability \\n\\nEach model tested in this paper provided a set of features impor-\\ntances or model coefficients; however, the clarity of the decisions made \\nand the significance of these features were sometimes not as apparent. \\nFor instance, these features may be weighted differently, with some \\nvariation from the initial run. However, ranking these features and \\ndefining commonality between each returned feature for a model is \\nbeneficial, as repeated instances of the same features used may indicate \\na contributor to some risk cases. Once an insurer selects a production \\nmodel, these features will remain constant. However, for a model to be \\nfully interpretable, there needs to be a repeatable and easily definable \\nmethod to return model decisions to provide model decision clarity for \\nregulatory or auditing purposes (Actuarial Standards Board, 2020; \\nCouncil of the European Union, 2016; Institute and Faculty of Actuaries, \\n2015). For example, using p-values or model coefficients, insurers or \\nauditors can easily access model decisions from a Logistic Regression \\nmodel, negating the risk of being in breach of regulation. In contrast, the \\nfeatures importances returned by XGBoost score each feature uniformly \\nbefore choosing the most relevant set of features. The scoring behavior \\nof the XGBoost model is due to the ensemble decision function, where \\ndecision nodes split based on weak classifiers. These weak classifiers \\ncontribute to features importance until a champion set of features \\nbecomes part of the final solution. Additionally, the NN used in the study \\nproved challenging to extract meaningful interior model decisions, a \\nknown disadvantage of using these models (Baecke & Bocca, 2017; \\nPaefgen et al., 2013). The internal decision process is hidden from the \\nuser unless specialist software is used (Gramegna & Giudici, 2020). \\nThus, explaining model decisions and interpreting results becomes a \\ndifficult task. \\n\\nTransitioning away from a GLM is difficult for insurers due to the \\nneed for model clarity and interpretability. Therefore, the black-box \\n\\nTable 4 \\nThe top four feature importances for each model tested per level. Bolded values \\nare traditional or classical risk pricing variables; all other values are telematics \\nvariables. Each model used in this study has favored telematics variables over \\ntraditional or classical variables when making risk predictions. TabNet, in \\nparticular, does not use any traditional variables when making predictions. \\nUnderlined features represent commonality between each model.  \\n\\nFeature Importance \\n\\nLevel TabNet XGBoost Logistic Regression \\n\\nFeature \\n\\n1 Annual.miles.drive \\nPct.drive.wkday \\nRight.turn.intensity11 \\nAnnual.pct.driven \\n\\nRegion \\nAnnual.miles.drive \\nAccel.12miles \\nAccel.11miles \\n\\nCar.age* \\nDuration* \\nLeft.turn.intensity12** \\nAnnual.miles.drive** \\n\\n2 Pct.drive.rush am \\nBrake.14miles \\nRight.turn.intensity08 \\nPct.drive.tue \\n\\nAnnual.miles.drive \\nCredit.score \\nLeft.turn.intensity08 \\nPct.drive.tue \\n\\nAnnual.pct.driven* \\nRight.turn.intensity10* \\nPct.drive.rush pm** \\nPct.drive.rush am** \\n\\n3 Agg_Acc \\nAnnual.pct.driven \\nAnnual.miles.drive \\nPct.drive.rush am \\n\\nCar.age \\nAnnual.miles.drive \\nPct.drive.tue \\nBrake.14miles \\n\\nAnnual.pct.driven* \\nTerritory*  \\n\\nPct.drive.tue** \\nCredit.score** \\n\\n*Denotes coeff values that contributed to drivers identified as not a risk or \\nClaimsYN=0. \\n**Denotes drivers identified as a risk or ClaimsYN=1. \\n\\nK. McDonnell et al.                                                                                                                                                                                                                             \\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119543\\n\\n8\\n\\nstyle of model predictions found in XGB or traditional DL models be-\\ncomes unattractive. However, TabNet provides both features impor-\\ntance and interior decision masks. The returned feature scores from \\nTabNet indicate a clearly chosen feature as significant to model de-\\ncisions, leaving no ambiguity in model choice. Additional features that \\nscore highly are also distinct from low-scoring features. The addition of \\nthe decision mask enables further insight into the model decision pro-\\ncess. The Attentive Transformer does not retain features that do not \\ncontribute to model decisions, and the output from the decision mask \\ncaptures this process. Gaining access to these decisions is simple and \\ndoes not require additional software packages. TabNets ability to easily \\nprovide model interpretability can bridge this gap in using DL in in-\\nsurance as these properties will enable insurers to provide auditors or \\nregulatory bodies with sufficient model information to be regulatory \\ncompliant. \\n\\n5.3. Data trends \\n\\nThe returned features importance for each model assists in discov-\\nering trends in the telematics or policyholder data. An important \\nconsideration for insurers should be the value of investing in bespoke \\ninsurance products and whether these additional features contribute to \\nmodel decisions. The returned features importances for each model \\nvary in their assigned importances to traditional or telematics data. \\n\\nThese decisions from the model help insurers target certain behaviors or \\ncharacteristics and offer specific and competitive bespoke insurance \\nproducts. The chosen model must identify realistic and accessible fea-\\ntures with relative accuracy to achieve this. For instance, Logistic \\nRegression and XGBoost both identified Car.age and Credit.Score as a \\nsignificant contributor to model decisions. These features are likely to \\ninfer a drivers risk; however, traditional risk metrics such as Annual. \\nmiles.drive have historically contributed to risk (Bian, Yang, Zhao, & \\nLiang, 2018; Boucher et al., 2017) and thus should have been rated \\nhigher. \\n\\nTelematics data offers significant insights into driver behavior and, \\ntherefore, should be an indicator of risk. However, out of the three \\nmodels tested, TabNet was the only model that consistently identified \\ntelematics variables as significant contributors to driver risk. Compared \\nto TabNet, the Logistic Regression model sporadically identified fea-\\ntures, indicating poor model performance. The high f1 and recall scores \\nreturned by TabNet also reflect TabNets ability to identify these risk \\nindicators over the other models. Additionally, TabNets ability to \\nidentify these risk indicators accurately will provide insurers with \\ngreater insights into their telematics data. \\n\\n6. Conclusion \\n\\nThis paper provides a comprehensive overview of TabNets \\n\\nFig. 3. Feature masks for TabNet. The highlighted features in each graph display the output from each feature mask at a given step. Each row indicates the levels of \\npre-processing. Additionally, color gradients signify the importance of a feature at that stage of testing, with yellow features indicating a significant contribution and \\npurple the lowest. The x-axis refers to rows of test data, and the y-axis refers to the index of feature values. The final row has only two masks due to the optimal steps \\nchosen as two, as each step outputs a corresponding mask. \\n\\nK. McDonnell et al.                                                                                                                                                                                                                             \\n\\n\\n\\nExpert Systems With Applications 217 (2023) 119543\\n\\n9\\n\\nperformance compared against traditional insurance risk classification \\nmethods in GLM and XGBoost. When compared against these models, \\nTabNet surpasses the performance of XGBoost and Logistic Regression. \\nTabNet is a highly performant DL architecture for insurers, capable of \\nidentifying driver risk from telematics data. This model also provides \\nhighly interpretable results and identifies valuable data trends, another \\nimportant consideration for insurance risk pricing. \\n\\nThe usage of DL models in insurance risk pricing is underutilized due \\nto their low model interpretability and poor generalization on tabular \\ndatasets. Additionally, GLM models and XGBoost require extensive \\nmodel building processes or return poor model interpretability. This \\nnovel approach introduces TabNet for driver risk identification. TabNet \\nprovides high accuracy and model interpretability and can identify risky \\ndrivers from telematics and policyholder data. \\n\\nComparing the performance of each model, TabNet was best suited \\nto capture the sparsity of claims within the dataset, returning the highest \\nf1-scores in two out three rounds, scoring 0.59 & 0.6, respectively. \\nAdditionally, no other model scored higher than TabNet in Recall. The \\nperformance of XGBoost was also comparable to TabNet. XGBoost \\nconsistently returned high precision, accuracy, and AUC values and, in \\nthe first round of testing, returned the highest f1-score. However, Lo-\\ngistic Regression could not generalize on the dataset and could never \\naccurately capture the sparsity in claims. Thus, model performance \\nnever improved despite efforts to optimize the model. Additionally, the \\nfinal set of tests conducted using LightGBM and NN could not accurately \\npredict claims. As a result, neither model could surpass TabNets or \\nXGBoosts scores. \\n\\nThis study identifies model interpretability as TabNets key contri-\\nbution for usage in insurance risk pricing. Each model could identify a \\nsignificant feature that contributed to model decisions; however, \\nXGBoost, in particular, could not provide clarity over the decisions \\nmade. On the other hand, TabNet excelled in this field, returning chosen \\nfeatures of significance with clarity while also providing local model \\ninterpretability. Furthermore, obtaining the decision masks from Tab-\\nNet is a simple process, and each mask displays the decisions made by \\nthe model at that particular step. Finally, the coefficients returned from \\nLogistic Regression provide interpretable results; however, clarity was \\ndifficult to obtain due to poor model performance. This problem per-\\nsisted with the LightGBM and NN models, as both models performed \\n\\npoorly on the claims prediction task. The NN, in particular, demon-\\nstrated a significant challenge in obtaining model decisions, further \\nendorsing TabNets interpretable qualities. \\n\\nAnother important consideration for this study was evaluating each \\nmodels ability to identify telematics and policyholder data trends. \\nIdentifying specific trends in the data is invaluable to insurers, as they \\ncan offer tailored bespoke insurance products for their policyholders. \\nBoth XGBoost and Logistic Regression failed in this aspect, returning \\ninsights that would not benefit the insurer. Conversely, TabNet offered \\nsignificant insights into data trends, identifying traditionally significant \\nfeatures such as annual mileage and telematics features as contributors \\nto risk. \\n\\nTabNet tended to overfit the data despite these aforementioned \\nbenefits and required extensive effort to train and tune the model \\ncorrectly. Additionally, training the model was a time-consuming pro-\\ncess with sometimes minimal reward. XGBoost, in comparison, could \\nachieve comparable performance with minimal effort. \\n\\nCRediT authorship contribution statement \\n\\nKevin McDonnell: Conceptualization, Methodology, Software, \\nFormal analysis, Writing  original draft, Writing  review & editing. \\nFinbarr Murphy: Funding acquisition, Supervision, Writing  review & \\nediting. Barry Sheehan: Supervision, Writing  review & editing. \\nLeandro Masello: Resources, Writing  review & editing. German \\nCastignani: Writing  review & editing. \\n\\nDeclaration of Competing Interest \\n\\nThe authors declare that they have no known competing financial \\ninterests or personal relationships that could have appeared to influence \\nthe work reported in this paper. \\n\\nData availability \\n\\nThe dataset used in this study is a synthetic telematics dataset pro-\\nvided by So et al. (2021) \\n\\nAcknowledgements/Funding \\n\\nThis project was supported by the Science Foundation Ireland (SFI), \\nand by Lero, the SFI Research Center for Software, [grant Blended \\nAutonomous Vehicles, BAV]. The authors would also like to acknowl-\\nedge Greenval Insurance for their support in this research. \\n\\nReferences \\n\\n. Actuarial Standards Board. http://www.actuarialstandardsboard.org/wp-content/uplo \\nads/2020/01/asop056_195-1.pdf. \\n\\nArik, S.O., & Pfister, T. (2021). TabNet: Attentive Interpretable Tabular Learning. \\nProceedings of the AAAI Conference on Artificial Intelligence, 35(8), 66796687. \\n\\nAyuso, M., Guillen, M., & Nielsen, J. P. (2019). Improving automobile insurance \\nratemaking using telematics: Incorporating mileage and driver behaviour data. \\nTransportation, 46(3), 735752. https://doi.org/10.1007/s11116-018-9890-7 \\n\\nBaecke, P., & Bocca, L. (2017). The value of vehicle telematics data in insurance risk \\nselection processes. Decision Support Systems, 98, 6979. https://doi.org/10.1016/j. \\ndss.2017.04.009 \\n\\nBian, Y., Yang, C., Zhao, J. L., & Liang, L. (2018). Good drivers pay less: A study of usage- \\nbased vehicle insurance models. Transportation Research Part A: Policy and Practice, \\n107, 2034. https://doi.org/10.1016/j.tra.2017.10.018 \\n\\nBibal, A., Lognoul, M., de Streel, A., & Frenay, B. (2021). Legal requirements on \\nexplainability in machine learning. Artificial Intelligence and Law, 29(2), 149169. \\nhttps://doi.org/10.1007/s10506-020-09270-4 \\n\\nChen, T., & Guestrin, C. (2016). XGBoost: A Scalable Tree Boosting System. In Proceedings \\nof the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data \\nMining (pp. 785794). https://doi.org/10.1145/2939672.2939785 \\n\\nCouncil of the European Union. (2016). Regulation (EU) 2016/679 of the European \\nParliament and of the Council of 27 April 2016 on the protection of natural persons \\nwith regard to the processing of personal data and on the free movement of such \\ndata, and repealing Directive 95/46/EC (General Data Protection Regulation) (Text \\nwith EEA relevance). https://eur-lex.europa.eu/legal-content/EN/TXT/HTML/? \\nuri=OJ:L:2016:119:FULL&from=EN. \\n\\nTable 5 \\nSummation of Results. Key points summarize each models performance \\nthroughout each round of testing. These include performance metrics, model \\ncomplexity and model interpretability characteristics. For interpretability, ease \\nof access to model decisions indicates good model interpretability.  \\n\\nSummary of Results \\n\\nModel Key Points Interpretability \\n\\nTabNet   Highest F1-Score  \\n Recall highest in 2/3 rounds  \\n Near equal Matthews \\n\\nCorrelation performance \\ncompared to XGB  \\n\\n Scores balanced across all tests  \\n Longest running time  \\n Model building is more \\n\\ncomplex than XGB for similar \\nperformance  \\n\\n Identifies Telematics as \\nsignificant to model decisions in \\nall rounds  \\n\\n Internal model decisions are \\neasily accessible.  \\n\\n Both TabNet and LR have equal \\nlevels of model interpretability \\n\\nXGB   Highest AUC and Precision  \\n Comparable Matthews \\n\\nCorrelation to TabNet  \\n Minimal effort in feature \\n\\nprocessing for good results.  \\n Shortest runtime  \\n\\n Identifies Telematics as \\nsignificant to model decisions in \\nall rounds  \\n\\n Poor interpretability without the \\nusing specialist software \\n\\nLR   Lowest scores in all three \\nrounds  \\n\\n Identifies Telematics variables as \\nmain contributors to risk  \\n\\n Coefficients easily obtained  \\n Both TabNet and GLM have equal \\n\\nlevels of model interpretablility  \\n\\nK. McDonnell et al.                                                                                                                                                                                                                             \\n\\nhttp://www.actuarialstandardsboard.org/wp-content/uploads/2020/01/asop056_195-1.pdf\\nhttp://www.actuarialstandardsboard.org/wp-content/uploads/2020/01/asop056_195-1.pdf\\nhttp://refhub.elsevier.com/S0957-4174(23)00044-1/h0010\\nhttp://refhub.elsevier.com/S0957-4174(23)00044-1/h0010\\nhttps://doi.org/10.1007/s11116-018-9890-7\\nhttps://doi.org/10.1016/j.dss.2017.04.009\\nhttps://doi.org/10.1016/j.dss.2017.04.009\\nhttps://doi.org/10.1016/j.tra.2017.10.018\\nhttps://doi.org/10.1007/s10506-020-09270-4\\nhttps://doi.org/10.1145/2939672.2939785\\nhttps://eur-lex.europa.eu/legal-content/EN/TXT/HTML/?uri=OJ%3aL%3a2016%3a119%3aFULL%26from=EN\\nhttps://eur-lex.europa.eu/legal-content/EN/TXT/HTML/?uri=OJ%3aL%3a2016%3a119%3aFULL%26from=EN\\n\\n\\nExpert Systems With Applications 217 (2023) 119543\\n\\n10\\n\\nGoodfellow, I., Bengio, Y., & Courville, A. (2016). Deep Learning. MIT Press.  \\nGramegna, A., & Giudici, P. (2020). Why to Buy Insurance? An Explainable Artificial \\n\\nIntelligence Approach. Risks, 8(4), 137. https://doi.org/10.3390/risks8040137 \\nGuelman, L. (2012). Gradient boosting trees for auto insurance loss cost modeling and \\n\\nprediction. Expert Systems with Applications, 39(3), 36593667. https://doi.org/ \\n10.1016/j.eswa.2011.09.058 \\n\\nHenckaerts, R., Antonio, K., Clijsters, M., & Verbelen, R. (2018). A data driven binning \\nstrategy for the construction of insurance tariff classes. Scandinavian Actuarial \\nJournal, 2018(8), 681705. https://doi.org/10.1080/03461238.2018.1429300 \\n\\nHenckaerts, R., Cote, M.-P., Antonio, K., & Verbelen, R. (2021). Boosting Insights in \\nInsurance Tariff Plans with Tree-Based Machine Learning Methods. North American \\nActuarial Journal, 25(2), 255285. https://doi.org/10.1080/ \\n10920277.2020.1745656 \\n\\nKlein, N., Denuit, M., Lang, S., & Kneib, T. (2014). Nonlife ratemaking and risk \\nmanagement with Bayesian generalized additive models for location, scale, and \\nshape. Insurance: Mathematics and Economics, 55, 225249. https://doi.org/10.1016/ \\nj.insmatheco.2014.02.001 \\n\\nLeCun, Y., Bengio, Y., & Hinton, G. (2015). Deep learning. Nature, 521(7553), 436444. \\nhttps://doi.org/10.1038/nature14539 \\n\\nMa, Y.-L., Zhu, X., Hu, X., & Chiu, Y.-C. (2018). The use of context-sensitive insurance \\ntelematics data in auto insurance rate making. Transportation Research Part A: Policy \\nand Practice, 113, 243258. https://doi.org/10.1016/j.tra.2018.04.013 \\n\\nMaillart, A. (2021). Toward an explainable machine learning model for claim frequency: \\nA use case in car insurance pricing with telematics data. European Actuarial Journal. \\nhttps://doi.org/10.1007/s13385-021-00270-5 \\n\\nMasello, L., Sheehan, B., Murphy, F., Castignani, G., McDonnell, K., & Ryan, C. (2022). \\nFrom Traditional to Autonomous Vehicles: A Systematic Review of Data Availability. \\nTransportation Research Record, 2676(4), 161193. https://doi.org/10.1177/ \\n03611981211057532 \\n\\nMcCullagh, P., & Nelder, J. A. (2019). In Generalized Linear Models (2nd ed.). Routledge. \\nhttps://doi.org/10.1201/9780203753736.  \\n\\nMcDonnell, K., Murphy, F., Sheehan, B., Masello, L., Castignani, G., & Ryan, C. (2021). \\nRegulatory and Technical Constraints: An Overview of the Technical Possibilities \\nand Regulatory Limitations of Vehicle Telematic Data. Sensors, 21(10), 3517. \\nhttps://doi.org/10.3390/s21103517 \\n\\nMolnar, C. (2020). Interpretable Machine Learning. \\nNoll, A., Salzmann, R., & Wuthrich, M. V. (2018). Case Study: French Motor Third-Party \\n\\nLiability Claims. SSRN Electronic Journal. https://doi.org/10.2139/ssrn.3164764 \\nPaefgen, J., Staake, T., & Thiesse, F. (2013). Evaluation and aggregation of pay-as-you- \\n\\ndrive insurance rate factors: A classification analysis approach. Decision Support \\nSystems, 56, 192201. https://doi.org/10.1016/j.dss.2013.06.001 \\n\\nPedregosa, F., Varoquaux, G., Gramfort, A., Michel, V., Thirion, B., Grisel, O.,  \\nDuchesnay, E. (2011). Scikit-learn: Machine Learning in Python. Journal of Machine \\nLearning Research, 12(85), 28252830. \\n\\nPesantez-Narvaez, J., Guillen, M., & Alcaniz, M. (2019). Predicting Motor Insurance \\nClaims Using Telematics DataXGBoost versus Logistic Regression. Risks, 7(2), 70. \\nhttps://doi.org/10.3390/risks7020070 \\n\\npytorch-tabnet: PyTorch implementation of TabNet (3.1.1). (2021). [Python]. DreamQuark. \\nhttps://github.com/dreamquark-ai/tabnet. \\n\\nQuan, Z., & Valdez, E. A. (2018). Predictive analytics of insurance claims using \\nmultivariate decision trees. Dependence Modeling, 6(1), 377407. https://doi.org/ \\n10.1515/demo-2018-0022 \\n\\nRenshaw, A. E. (1994). Modelling the claims process in the presence of covariates. ASTIN \\nBulletin, 24(2), 265285. Scopus. doi:10.2143/AST.24.2.2005070. \\n\\nShannon, D., Murphy, F., Mullins, M., & Eggert, J. (2018). Applying crash data to injury \\nclaimsAn investigation of determinant factors in severe motor vehicle accidents. \\nAccident; Analysis and Prevention, 113, 244256. https://doi.org/10.1016/j. \\naap.2018.01.037 \\n\\nShavitt, I., & Segal, E. (2018). Regularization Learning Networks: Deep Learning for \\nTabular Datasets. In S. Bengio, H. Wallach, H. Larochelle, K. Grauman, N. Cesa- \\nBianchi, & R. Garnett (Eds.), Advances in Neural Information Processing Systems (Vol. \\n31). Curran Associates, Inc. https://proceedings.neurips.cc/paper/2018/file/500 \\ne75a036dc2d7d2fec5da1b71d36cc-Paper.pdf. \\n\\nSheehan, B., Murphy, F., Ryan, C., Mullins, M., & Liu, H. Y. (2017). Semi-autonomous \\nvehicle motor insurance: A Bayesian Network risk transfer approach. Transportation \\nResearch Part C: Emerging Technologies, 82, 124137. https://doi.org/10.1016/j. \\ntrc.2017.06.015 \\n\\nSiami, M., Naderpour, M., & Lu, J. (2021). A Mobile Telematics Pattern Recognition \\nFramework for Driving Behavior Extraction. IEEE Transactions on Intelligent \\nTransportation Systems, 22(3), 14591472. https://doi.org/10.1109/ \\nTITS.2020.2971214 \\n\\n[dataset] So, B., Boucher, J.-P., & Valdez, E. A. (2021). Synthetic Dataset Generation of \\nDriver Telematics. Risks, 9(4), 58. doi:10.3390/risks9040058. \\n\\nThe Regulation Board, I. and F. of A. (2015, July). APS X2: Review of Actuarial Work. \\nInstitute and Faculty of Actuaries. https://www.actuaries.org.uk/system/files \\n/documents/pdf/20150122-aps-x2-final-version.pdf. \\n\\nVerbelen, R., Antonio, K., & Claeskens, G. (2018). Unravelling the predictive power of \\ntelematics data in car insurance pricing. Journal of the Royal Statistical Society. Series \\nC: Applied Statistics, 67(5), 12751304. Scopus. doi:10.1111/rssc.12283. \\n\\nWang, W., & Xi, J. (2016). A rapid pattern-recognition method for driving styles using \\nclustering-based support vector machines. American Control Conference (ACC), 2016, \\n52705275. https://doi.org/10.1109/ACC.2016.7526495 \\n\\nWu, M., Zhang, S., & Dong, Y. (2016). A Novel Model-Based Driving Behavior \\nRecognition System Using Motion Sensors. Sensors, 16(10), 1746. https://doi.org/ \\n10.3390/s16101746 \\n\\nWthrich, M. V. (2020). Bias regularization in neural network models for general \\ninsurance pricing. European Actuarial Journal, 10(1), 179202. https://doi.org/ \\n10.1007/s13385-019-00215-z \\n\\nXu, L., Skoularidou, M., Cuesta-Infante, A., & Veeramachaneni, K. (2019). Modeling \\nTabular data using Conditional GAN. In H. Wallach, H. Larochelle, A. Beygelzimer, \\nF. dAlche-Buc, E. Fox, & R. Garnett (Eds.), Advances in Neural Information Processing \\nSystems (Vol. 32). Curran Associates, Inc. https://proceedings.neurips.cc/paper/201 \\n9/file/254ed7d2de3b23ab10936522dd547b78-Paper.pdf. \\n\\nK. McDonnell et al.                                                                                                                                                                                                                             \\n\\nhttp://refhub.elsevier.com/S0957-4174(23)00044-1/h0045\\nhttps://doi.org/10.3390/risks8040137\\nhttps://doi.org/10.1016/j.eswa.2011.09.058\\nhttps://doi.org/10.1016/j.eswa.2011.09.058\\nhttps://doi.org/10.1080/03461238.2018.1429300\\nhttps://doi.org/10.1080/10920277.2020.1745656\\nhttps://doi.org/10.1080/10920277.2020.1745656\\nhttps://doi.org/10.1016/j.insmatheco.2014.02.001\\nhttps://doi.org/10.1016/j.insmatheco.2014.02.001\\nhttps://doi.org/10.1038/nature14539\\nhttps://doi.org/10.1016/j.tra.2018.04.013\\nhttps://doi.org/10.1007/s13385-021-00270-5\\nhttps://doi.org/10.1177/03611981211057532\\nhttps://doi.org/10.1177/03611981211057532\\nhttps://doi.org/10.1201/9780203753736\\nhttps://doi.org/10.3390/s21103517\\nhttps://doi.org/10.2139/ssrn.3164764\\nhttps://doi.org/10.1016/j.dss.2013.06.001\\nhttp://refhub.elsevier.com/S0957-4174(23)00044-1/h0120\\nhttp://refhub.elsevier.com/S0957-4174(23)00044-1/h0120\\nhttp://refhub.elsevier.com/S0957-4174(23)00044-1/h0120\\nhttps://doi.org/10.3390/risks7020070\\nhttps://github.com/dreamquark-ai/tabnet\\nhttps://doi.org/10.1515/demo-2018-0022\\nhttps://doi.org/10.1515/demo-2018-0022\\nhttps://doi.org/10.1016/j.aap.2018.01.037\\nhttps://doi.org/10.1016/j.aap.2018.01.037\\nhttps://proceedings.neurips.cc/paper/2018/file/500e75a036dc2d7d2fec5da1b71d36cc-Paper.pdf\\nhttps://proceedings.neurips.cc/paper/2018/file/500e75a036dc2d7d2fec5da1b71d36cc-Paper.pdf\\nhttps://doi.org/10.1016/j.trc.2017.06.015\\nhttps://doi.org/10.1016/j.trc.2017.06.015\\nhttps://doi.org/10.1109/TITS.2020.2971214\\nhttps://doi.org/10.1109/TITS.2020.2971214\\nhttps://www.actuaries.org.uk/system/files/documents/pdf/20150122-aps-x2-final-version.pdf\\nhttps://www.actuaries.org.uk/system/files/documents/pdf/20150122-aps-x2-final-version.pdf\\nhttps://doi.org/10.1109/ACC.2016.7526495\\nhttps://doi.org/10.3390/s16101746\\nhttps://doi.org/10.3390/s16101746\\nhttps://doi.org/10.1007/s13385-019-00215-z\\nhttps://doi.org/10.1007/s13385-019-00215-z\\nhttps://proceedings.neurips.cc/paper/2019/file/254ed7d2de3b23ab10936522dd547b78-Paper.pdf\\nhttps://proceedings.neurips.cc/paper/2019/file/254ed7d2de3b23ab10936522dd547b78-Paper.pdf\\n\\n\\tDeep learning in insurance: Accuracy and model interpretability using TabNet\\n\\t1 Introduction\\n\\t2 Data\\n\\t3 Methodology\\n\\t3.1 TabNet\\n\\t3.2 XGBoost\\n\\t3.3 GLm\\n\\t3.4 Pre-processing level 13\\n\\n\\t4 Results\\n\\t5 Discussion\\n\\t5.1 Model performance\\n\\t5.2 Model interpretability\\n\\t5.3 Data trends\\n\\n\\t6 Conclusion\\n\\tCRediT authorship contribution statement\\n\\tDeclaration of Competing Interest\\n\\tData availability\\n\\tAcknowledgements/Funding\\n\\tReferences\\n\\n\\n', 'status': 200}\n",
      "Dublin Core Metadata:\n",
      "{\n",
      "    \"dc:format\": \"application/pdf; version=1.7\",\n",
      "    \"dc:title\": \"Deep learning in insurance: Accuracy and model interpretability using TabNet\",\n",
      "    \"dc:description\": \"Expert Systems With Applications, 217 (2023) 119543. doi:10.1016/j.eswa.2023.119543\",\n",
      "    \"dc:creator\": [\n",
      "        \"Kevin McDonnell\",\n",
      "        \"Finbarr Murphy\",\n",
      "        \"Barry Sheehan\",\n",
      "        \"Leandro Masello\",\n",
      "        \"German Castignani\"\n",
      "    ],\n",
      "    \"dcterms:created\": \"2023-02-04T09:40:15Z\",\n",
      "    \"dcterms:modified\": \"2023-02-07T17:36:19Z\",\n",
      "    \"dc:language\": \"en\",\n",
      "    \"dc:subject\": [\n",
      "        \"Deep Learning,Telematics,Connected Vehicles,Insurance,General Linear Model,XGBoost,Machine Learning,Explainable AI\",\n",
      "        \"Expert Systems With Applications, 217 (2023) 119543. doi:10.1016/j.eswa.2023.119543\"\n",
      "    ]\n",
      "}\n",
      "Loaded project data successfully.\n",
      "Current project_data: {\n",
      "    \"@context\": {\n",
      "        \"schema\": \"http://schema.org/\",\n",
      "        \"dc\": \"http://purl.org/dc/terms/\"\n",
      "    },\n",
      "    \"@graph\": [\n",
      "        {\n",
      "            \"@type\": \"schema:ResearchProject\",\n",
      "            \"schema:identifier\": \"06535@test\",\n",
      "            \"schema:publicKey\": \"7851c382158dc0349df2136ae8821753b98b65be412387181764005baf9bff20\",\n",
      "            \"schema:description\": {\n",
      "                \"@context\": {\n",
      "                    \"schema\": \"http://schema.org/\",\n",
      "                    \"dc\": \"http://purl.org/dc/terms/\"\n",
      "                },\n",
      "                \"@type\": \"schema:ResearchProject\",\n",
      "                \"schema:name\": \"Investigating the Role of quantum computing in supply chain management\",\n",
      "                \"dc:abstract\": \"This study explores the impact of quantum computing in supply chain management, focusing on biodiversity.\",\n",
      "                \"schema:keywords\": [\n",
      "                    \"quantum computing\",\n",
      "                    \"supply chain management\",\n",
      "                    \"biodiversity\"\n",
      "                ],\n",
      "                \"schema:startDate\": \"2023-07-03\",\n",
      "                \"schema:endDate\": \"2026-07-23\",\n",
      "                \"schema:funding\": {\n",
      "                    \"@type\": \"schema:Organization\",\n",
      "                    \"schema:name\": \"National Science Foundation\"\n",
      "                },\n",
      "                \"schema:location\": {\n",
      "                    \"@type\": \"schema:Place\",\n",
      "                    \"schema:name\": \"Lagos, Nigeria\"\n",
      "                }\n",
      "            },\n",
      "            \"schema:metadataCID\": \"QmbmyecKUbwCDFPt6Uddx411bCvefLiRXPxHs5vnYz4XZm\",\n",
      "            \"schema:linked_user\": \"crazy_nash@test\",\n",
      "            \"schema:files\": [\n",
      "                {\n",
      "                    \"file_index\": 1,\n",
      "                    \"file_cid\": \"QmVk8gxENq6PThSGZTuk7RtbufR2XeN7LtXBj2LVTUoAdN\",\n",
      "                    \"metadata_cid\": \"QmWuj7Rr8PjwGzGW5otvAVTDUywUt8BHh7uvawFqEreMJo\",\n",
      "                    \"metadata\": {}\n",
      "                },\n",
      "                {\n",
      "                    \"file_index\": 2,\n",
      "                    \"file_cid\": \"QmT7ximApXtExAedhzUHGHDwRismRzuKykpH4dgTvGrNZs\",\n",
      "                    \"metadata_cid\": \"QmcqzQsw6F8w5vYV49gQYmzMM1WuQcrXFVASqwThDgyb14\",\n",
      "                    \"metadata\": {\n",
      "                        \"dc:format\": \"application/pdf; version=1.7\",\n",
      "                        \"dc:title\": \"Diabetic retinopathy identification using parallel convolutional neural network based feature extractor and ELM classifier\",\n",
      "                        \"dc:description\": \"Expert Systems With Applications, 217 (2023) 119557. doi:10.1016/j.eswa.2023.119557\",\n",
      "                        \"dc:creator\": [\n",
      "                            \"Md. Nahiduzzaman\",\n",
      "                            \"Md. Robiul Islam\",\n",
      "                            \"Md. Omaer Faruq Goni\",\n",
      "                            \"Md. Shamim Anower\",\n",
      "                            \"Mominul Ahsan\",\n",
      "                            \"Julfikar Haider\",\n",
      "                            \"Marcin Kowalski\"\n",
      "                        ],\n",
      "                        \"dcterms:created\": \"2023-02-04T09:40:15Z\",\n",
      "                        \"dcterms:modified\": \"2023-02-07T17:54:35Z\",\n",
      "                        \"dc:language\": \"en\",\n",
      "                        \"dc:subject\": [\n",
      "                            \"Contrast limited adaptive histogram equalization (CLAHE),Diabetic retinopathy (DR),Parallel convolutional neural network (PCNN),Extreme LEARNING MACHine (ELM)\",\n",
      "                            \"Expert Systems With Applications, 217 (2023) 119557. doi:10.1016/j.eswa.2023.119557\"\n",
      "                        ]\n",
      "                    }\n",
      "                },\n",
      "                {\n",
      "                    \"file_index\": 3,\n",
      "                    \"file_cid\": \"QmZnh5Uuo7moZKMESFHpRjQFbbND5e3nArCzZg8uLARAgg\",\n",
      "                    \"metadata_cid\": \"QmZBwBxATjd85MZK9q6eSaX3tztcYbJzT34obDZmFKNE8K\",\n",
      "                    \"metadata\": {\n",
      "                        \"dcterms:created\": \"2023-02-07T10:24:44Z\",\n",
      "                        \"dcterms:modified\": \"2023-02-07T10:25:02Z\",\n",
      "                        \"dc:format\": \"application/pdf; version=1.7\"\n",
      "                    }\n",
      "                },\n",
      "                {\n",
      "                    \"file_index\": 4,\n",
      "                    \"file_cid\": \"QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW\",\n",
      "                    \"metadata_cid\": \"QmY1iBM4gc3quCmVWbjjmFSoUwxqji9ff3gkX3MyVqypmj\",\n",
      "                    \"metadata\": {\n",
      "                        \"dc:format\": \"application/pdf; version=1.7\",\n",
      "                        \"dc:title\": \"COVID19-MLSF: A multi-task learning-based stock market forecasting framework during the COVID-19 pandemic\",\n",
      "                        \"dc:description\": \"Expert Systems With Applications, 217 (2023) 119549. doi:10.1016/j.eswa.2023.119549\",\n",
      "                        \"dc:creator\": [\n",
      "                            \"Chenxun Yuan\",\n",
      "                            \"Xiang Ma\",\n",
      "                            \"Hua Wang\",\n",
      "                            \"Caiming Zhang\",\n",
      "                            \"Xuemei Li\"\n",
      "                        ],\n",
      "                        \"dcterms:created\": \"2023-02-04T09:40:15Z\",\n",
      "                        \"dcterms:modified\": \"2023-02-07T16:52:03Z\",\n",
      "                        \"dc:language\": \"en-US\",\n",
      "                        \"dc:subject\": [\n",
      "                            \"Stock market forecasting,COVID-19 pandemic,Multi-task learning,Feature fusion,K-nearest neighbor classifier\",\n",
      "                            \"Expert Systems With Applications, 217 (2023) 119549. doi:10.1016/j.eswa.2023.119549\"\n",
      "                        ]\n",
      "                    }\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"@type\": \"schema:ResearchProject\",\n",
      "            \"schema:identifier\": \"96858@test\",\n",
      "            \"schema:publicKey\": \"964dbc74f346b43a17060e1c451b5fd50873d0a2fe69188f32b2f8dbab052cfa\",\n",
      "            \"schema:description\": {\n",
      "                \"@context\": {\n",
      "                    \"schema\": \"http://schema.org/\",\n",
      "                    \"dc\": \"http://purl.org/dc/terms/\"\n",
      "                },\n",
      "                \"@type\": \"schema:ResearchProject\",\n",
      "                \"schema:name\": \"Analyzing the Influence of gene therapy on urban resilience\",\n",
      "                \"dc:abstract\": \"This paper analyzes how gene therapy influences urban resilience, providing insights into how to maximize its climate resilience.\",\n",
      "                \"schema:keywords\": [\n",
      "                    \"gene therapy\",\n",
      "                    \"urban resilience\",\n",
      "                    \"climate resilience\"\n",
      "                ],\n",
      "                \"schema:startDate\": \"2018-04-08\",\n",
      "                \"schema:endDate\": \"2026-06-05\",\n",
      "                \"schema:funding\": {\n",
      "                    \"@type\": \"schema:Organization\",\n",
      "                    \"schema:name\": \"National Science Foundation\"\n",
      "                },\n",
      "                \"schema:location\": {\n",
      "                    \"@type\": \"schema:Place\",\n",
      "                    \"schema:name\": \"Phuket, Thailand\"\n",
      "                }\n",
      "            },\n",
      "            \"schema:metadataCID\": \"QmRgbWW7QFgTWTRQqmjDv7fX6YypV8absEUSXwiw8f1Pn6\"\n",
      "        },\n",
      "        {\n",
      "            \"@type\": \"schema:ResearchProject\",\n",
      "            \"schema:identifier\": \"37887@test\",\n",
      "            \"schema:publicKey\": \"64593fc6dc0eb621cc258ffb3b180a171bcccb225bfea253084600c768776432\",\n",
      "            \"schema:description\": {\n",
      "                \"@context\": {\n",
      "                    \"schema\": \"http://schema.org/\",\n",
      "                    \"dc\": \"http://purl.org/dc/terms/\"\n",
      "                },\n",
      "                \"@type\": \"schema:ResearchProject\",\n",
      "                \"schema:name\": \"Analyzing the Influence of bioinformatics on climate adaptation\",\n",
      "                \"dc:abstract\": \"This paper analyzes how bioinformatics influences climate adaptation, providing insights into how to maximize its scientific discovery.\",\n",
      "                \"schema:keywords\": [\n",
      "                    \"bioinformatics\",\n",
      "                    \"climate adaptation\",\n",
      "                    \"scientific discovery\"\n",
      "                ],\n",
      "                \"schema:startDate\": \"2021-01-20\",\n",
      "                \"schema:endDate\": \"2028-06-16\",\n",
      "                \"schema:funding\": {\n",
      "                    \"@type\": \"schema:Organization\",\n",
      "                    \"schema:name\": \"World Wildlife Fund\"\n",
      "                },\n",
      "                \"schema:location\": {\n",
      "                    \"@type\": \"schema:Place\",\n",
      "                    \"schema:name\": \"Tokyo, Japan\"\n",
      "                }\n",
      "            },\n",
      "            \"schema:metadataCID\": \"QmT1cPcYNcGntxCc2goVmkJuQG9EdVthjvG6SVNs7WCXc8\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "Checking project with ID: '06535@test' against '06535@test'\n",
      "Match found for project ID: 06535@test\n",
      "Updated project 06535@test with new file entry: {'file_index': 5, 'file_cid': 'QmV1vYkuiwKGPA5Tyi4ECNFfWYocyTtQ3E5j7CSvPBX49Q', 'metadata_cid': 'QmY7xwK4beVPQLbeKxEAeStqxY69f7GzRhqTukXXsLMkMh', 'metadata': {'dc:format': 'application/pdf; version=1.7', 'dc:title': 'Deep learning in insurance: Accuracy and model interpretability using TabNet', 'dc:description': 'Expert Systems With Applications, 217 (2023) 119543. doi:10.1016/j.eswa.2023.119543', 'dc:creator': ['Kevin McDonnell', 'Finbarr Murphy', 'Barry Sheehan', 'Leandro Masello', 'German Castignani'], 'dcterms:created': '2023-02-04T09:40:15Z', 'dcterms:modified': '2023-02-07T17:36:19Z', 'dc:language': 'en', 'dc:subject': ['Deep Learning,Telematics,Connected Vehicles,Insurance,General Linear Model,XGBoost,Machine Learning,Explainable AI', 'Expert Systems With Applications, 217 (2023) 119543. doi:10.1016/j.eswa.2023.119543']}}\n",
      "Successfully wrote updated data to datasets/projects.json\n",
      "----------------------------------------\n",
      "{'pdf:PDFVersion': '1.7', 'xmp:CreatorTool': 'Elsevier', 'pdf:docinfo:title': 'Deep learning in insurance: Accuracy and model interpretability using TabNet', 'pdf:hasXFA': 'false', 'access_permission:can_print_degraded': 'true', 'X-TIKA:Parsed-By-Full-Set': ['org.apache.tika.parser.DefaultParser', 'org.apache.tika.parser.pdf.PDFParser'], 'X-TIKA:content_handler': 'ToTextContentHandler', 'pdf:num3DAnnotations': '0', 'dc:format': 'application/pdf; version=1.7', 'pdf:docinfo:custom:robots': 'noindex', 'pdf:docinfo:creator_tool': 'Elsevier', 'access_permission:fill_in_form': 'true', 'pdf:docinfo:custom:CreationDate--Text': '7th February 2023', 'pdf:hasCollection': 'false', 'pdf:encrypted': 'false', 'dc:title': 'Deep learning in insurance: Accuracy and model interpretability using TabNet', 'pdf:containsNonEmbeddedFont': 'false', 'xmp:CreateDate': '2023-02-04T09:40:15Z', 'pdf:docinfo:custom:CrossMarkDomains[1]': 'elsevier.com', 'robots': 'noindex', 'pdf:docinfo:subject': 'Expert Systems With Applications, 217 (2023) 119543. doi:10.1016/j.eswa.2023.119543', 'pdf:hasMarkedContent': 'true', 'xmp:ModifyDate': '2023-02-07T17:36:19Z', 'pdf:docinfo:creator': 'Kevin McDonnell', 'pdf:docinfo:custom:CrossmarkMajorVersionDate': '2010-04-23', 'access_permission:extract_for_accessibility': 'true', 'resourceName': \"b'Deep-learning-in-insurance--Accuracy-and-model-int_2023_Expert-Systems-with-.pdf'\", 'pdf:docinfo:custom:CrossMarkDomains[2]': 'sciencedirect.com', 'X-TIKA:Parsed-By': ['org.apache.tika.parser.DefaultParser', 'org.apache.tika.parser.pdf.PDFParser'], 'ElsevierWebPDFSpecifications': '7.0', 'pdf:docinfo:custom:doi': '10.1016/j.eswa.2023.119543', 'pdf:docinfo:custom:CrossmarkDomainExclusive': 'true', 'X-TIKA:embedded_depth': '0', 'CrossmarkDomainExclusive': 'true', 'pdf:annotationTypes': 'null', 'pdf:docinfo:producer': 'Acrobat Distiller 8.1.0 (Windows)', 'pdf:annotationSubtypes': 'Link', 'CreationDate--Text': '7th February 2023', 'doi': '10.1016/j.eswa.2023.119543', 'pdf:containsDamagedFont': 'false', 'pdf:unmappedUnicodeCharsPerPage': ['0', '0', '0', '0', '0', '0', '0', '0', '0', '0'], 'dc:description': 'Expert Systems With Applications, 217 (2023) 119543. doi:10.1016/j.eswa.2023.119543', 'access_permission:modify_annotations': 'true', 'dc:creator': ['Kevin McDonnell', 'Finbarr Murphy', 'Barry Sheehan', 'Leandro Masello', 'German Castignani'], 'dcterms:created': '2023-02-04T09:40:15Z', 'dcterms:modified': '2023-02-07T17:36:19Z', 'xmpMM:DocumentID': 'uuid:1b499bed-4ce8-4c0c-b682-0d58baae1cbe', 'CrossMarkDomains[1]': 'elsevier.com', 'pdf:overallPercentageUnmappedUnicodeChars': '0.0', 'pdf:docinfo:keywords': 'Deep Learning,Telematics,Connected Vehicles,Insurance,General Linear Model,XGBoost,Machine Learning,Explainable AI', 'pdf:docinfo:modified': '2023-02-07T17:36:19Z', 'Content-Length': '1697865', 'Content-Type': 'application/pdf', 'xmp:MetadataDate': '2023-02-07T17:36:19Z', 'dc:language': 'en', 'pdf:producer': 'Acrobat Distiller 8.1.0 (Windows)', 'dc:subject': ['Deep Learning,Telematics,Connected Vehicles,Insurance,General Linear Model,XGBoost,Machine Learning,Explainable AI', 'Expert Systems With Applications, 217 (2023) 119543. doi:10.1016/j.eswa.2023.119543'], 'pdf:docinfo:custom:ElsevierWebPDFSpecifications': '7.0', 'pdf:totalUnmappedUnicodeChars': '0', 'access_permission:assemble_document': 'true', 'xmpTPg:NPages': '10', 'pdf:hasXMP': 'true', 'pdf:charsPerPage': ['4694', '9144', '7582', '7133', '5283', '4337', '8096', '3645', '8070', '6797'], 'access_permission:extract_content': 'true', 'access_permission:can_print': 'true', 'CrossMarkDomains[2]': 'sciencedirect.com', 'meta:keyword': 'Deep Learning,Telematics,Connected Vehicles,Insurance,General Linear Model,XGBoost,Machine Learning,Explainable AI', 'X-TIKA:parse_time_millis': '91', 'access_permission:can_modify': 'true', 'pdf:docinfo:created': '2023-02-04T09:40:15Z', 'CrossmarkMajorVersionDate': '2010-04-23'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:All documents processed and index committed.\n"
     ]
    }
   ],
   "source": [
    "### New version\n",
    "\n",
    "from whoosh.index import create_in, open_dir, EmptyIndexError  # Import EmptyIndexError\n",
    "from metadata_helper import *\n",
    "import os\n",
    "import logging\n",
    "import mimetypes\n",
    "from tika import parser  # Import Apache Tika\n",
    "\n",
    "print(project_account['account_id'])\n",
    "\n",
    "# Function to extract only Dublin Core related metadata\n",
    "def extract_dublin_core(metadata):\n",
    "    \"\"\"Extracts only Dublin Core related metadata.\"\"\"\n",
    "    return {k: v for k, v in metadata.items() if k.startswith('dc:') or k.startswith('dcterms:')}\n",
    "\n",
    "\n",
    "# Function to parse and index documents from a directory\n",
    "def parse_documents_in_directory(directory_path, schema, linked_project, recreate=False):\n",
    "    \"\"\"Parses documents in a directory and indexes them.\"\"\"\n",
    "    ix = recreate_index(schema) if recreate else create_in(\"indexdir\", schema)\n",
    "    writer = get_writer_with_retry(ix)\n",
    "    index = 1\n",
    "\n",
    "    for filename in os.listdir(directory_path):\n",
    "        logging.info(f\"Processing file: {filename}\")\n",
    "\n",
    "        if not os.path.basename(filename).startswith('.'):\n",
    "            file_path = os.path.join(directory_path, filename)\n",
    "\n",
    "            try:\n",
    "                # Upload the file to IPFS and get its CID\n",
    "                file_cid = upload_file_to_ipfs(file_path)\n",
    "                logging.info(f\"File {filename} uploaded to IPFS with CID: {file_cid}\")\n",
    "\n",
    "                \n",
    "                # Update the project details in the Iroha 1 blockchain\n",
    "                # hash = set_account_detail(address, project_account['account_id'], f\"file_{index}_CID\", file_cid)\n",
    "\n",
    "\n",
    "                # Parse the document using Apache Tika\n",
    "\n",
    "                try:\n",
    "                    parsed_document = parser.from_file(file_path)\n",
    "                    print(parsed_document)\n",
    "                except Exception as e:\n",
    "                        logging.error(f\"Error parsing file with Tika: {e}\")\n",
    "                        continue\n",
    "                \n",
    "                if parsed_document:\n",
    "                    metadata = parsed_document.get('metadata', {})\n",
    "                    full_text = parsed_document.get(\"content\", \"\").strip() or \"No content extracted\"\n",
    "\n",
    "                    # Extract Dublin Core related metadata\n",
    "                    dublin_core_metadata = extract_dublin_core(metadata)\n",
    "                    \n",
    "                    # Normalize and upload JSON metadata to IPFS\n",
    "                    normalized_metadata = {\n",
    "                        'project_id': linked_project,\n",
    "                        'cid': upload_json_to_ipfs(metadata),  # Upload the full metadata\n",
    "                        'name': filename,\n",
    "                        'size': os.path.getsize(file_path),\n",
    "                        'filetype': mimetypes.guess_type(filename)[0] or \"unknown\",\n",
    "                        'title': normalize_metadata_value(metadata.get(\"dc:title\", f\"Document {index}\")),\n",
    "                        'creator': normalize_metadata_value(metadata.get(\"dc:creator\", \"Unknown\")),\n",
    "                        'language': normalize_metadata_value(metadata.get(\"dc:language\", \"en\")),\n",
    "                        'subject': normalize_metadata_value(metadata.get(\"dc:subject\", \"\")),\n",
    "                        'description': normalize_metadata_value(metadata.get(\"dc:description\", \"\")),\n",
    "                        'publisher': normalize_metadata_value(metadata.get(\"dc:publisher\", \"Unknown\")),\n",
    "                        'date': normalize_metadata_value(metadata.get(\"dc:date\", \"\")),\n",
    "                        'abstract': normalize_metadata_value(metadata.get(\"dc:abstract\", \"\")),\n",
    "                        'format': normalize_metadata_value(metadata.get(\"dc:format\", \"\")),\n",
    "                        'created': normalize_metadata_value(metadata.get(\"dcterms:created\", \"\")),\n",
    "                        'modified': normalize_metadata_value(metadata.get(\"dcterms:modified\", \"\"))\n",
    "                    }\n",
    "                    \n",
    "                    logging.info(f\"Indexed {filename} with CID: {normalized_metadata['cid']}\")\n",
    "\n",
    "                    # Add document to the Whoosh index\n",
    "                    add_document(writer, normalized_metadata, full_text)\n",
    "\n",
    "                    # Print extracted Dublin Core metadata\n",
    "                    print(\"Dublin Core Metadata:\")\n",
    "                    print(json.dumps(dublin_core_metadata, indent=4))\n",
    "\n",
    "                    # Update project entry with file data and Dublin Core metadata\n",
    "                    update_project_entry_with_file_data(\n",
    "                        linked_project, file_cid, normalized_metadata['cid'], dublin_core_metadata\n",
    "                    )\n",
    "                    logging.info(\"updated project entry\")\n",
    "                    \n",
    "                    # Upload the metadata to IPFS and get its CID\n",
    "                    print(40*\"-\")\n",
    "                    print(metadata)\n",
    "                    \n",
    "                    metadata_cid = upload_json_to_ipfs(metadata)\n",
    "\n",
    "                    encoded_key = f\"file_{index}\"\n",
    "                    encoded_value = b\"\".join(\n",
    "                        integration_helpers.argument_encoding(v) for v in (file_cid, metadata_cid)\n",
    "                    )\n",
    "                    \n",
    "                    \n",
    "                    import binascii\n",
    "\n",
    "                    hash = set_account_detail(\n",
    "                        address,\n",
    "                        project_account['account_id'],\n",
    "                        encoded_key,\n",
    "                        encoded_value\n",
    "                    )\n",
    "                    logging.info(f\"Hash: {binascii.hexlify(hash)}\")\n",
    "\n",
    "\n",
    "                    # print(metadata_cid)\n",
    "                    # logging.info(f\"File {filename} uploaded to IPFS with CID: {metadata_cid}\")\n",
    "                                        \n",
    "                    # #Sets the project account detail with the file metadata\n",
    "                    # print(40*\"-\")\n",
    "\n",
    "                    # print(project_account['account_id'])\n",
    "                    # print(index)\n",
    "                    # hash = set_account_detail(\n",
    "                    #     address, project_account['account_id'], f\"file_{index}_metadata_CID\", metadata_cid\n",
    "                    #     )\n",
    "\n",
    "                    # # hash = set_account_detail(\n",
    "                    # #     address, project_account['account_id'], f\"file_{index}\", (file_CID, metadata_cid))\n",
    "                        \n",
    "\n",
    "                    # # print(40*\"-\")\n",
    "                    \n",
    "                    # #-\n",
    "                    \n",
    "                else:\n",
    "                    logging.error(f\"Parsing failed for '{filename}'.\")\n",
    "\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Error processing file '{filename}': {e}\")\n",
    "                continue\n",
    "\n",
    "        logging.info(\"-\" * 40)\n",
    "        index += 1\n",
    "\n",
    "    writer.commit()  # Commit changes once all files are processed\n",
    "    logging.info(\"All documents processed and index committed.\")\n",
    "\n",
    "\n",
    "# Function to set up the Whoosh index directory\n",
    "def setup_index(schema):\n",
    "    \"\"\"Sets up the Whoosh index directory and returns the index object.\"\"\"\n",
    "    index_dir = \"indexdir\"\n",
    "    if not os.path.exists(index_dir):\n",
    "        os.mkdir(index_dir)\n",
    "        logging.info(\"Index directory created.\")\n",
    "        ix = create_in(index_dir, schema)\n",
    "    else:\n",
    "        try:\n",
    "            ix = open_dir(index_dir)\n",
    "            logging.info(\"Opened existing index.\")\n",
    "        except EmptyIndexError:\n",
    "            logging.warning(\"Index is empty. Creating a new index.\")\n",
    "            ix = create_in(index_dir, schema)\n",
    "    return ix\n",
    "\n",
    "# ic(linked_project)\n",
    "\n",
    "# Define the schema (including Dublin Core fields)\n",
    "schema = Schema(\n",
    "    project_id=TEXT(stored=True),\n",
    "    cid=ID(stored=True),\n",
    "    name=TEXT(stored=True),\n",
    "    size=NUMERIC(stored=True),\n",
    "    filetype=TEXT(stored=True),\n",
    "    title=TEXT(stored=True),\n",
    "    creator=TEXT(stored=True),\n",
    "    language=TEXT(stored=True),\n",
    "    subject=TEXT(stored=True),\n",
    "    description=TEXT(stored=True),\n",
    "    publisher=TEXT(stored=True),\n",
    "    date=TEXT(stored=True),\n",
    "    abstract=TEXT(stored=True),\n",
    "    format=TEXT(stored=True),\n",
    "    created=TEXT(stored=True),  # Store as string (e.g., ISO format 'YYYY-MM-DD')\n",
    "    modified=TEXT(stored=True),  # Store as string (e.g., ISO format 'YYYY-MM-DD')\n",
    "    full_text=TEXT(stored=False)\n",
    ")\n",
    "\n",
    "# Setup index directory\n",
    "ix = setup_index(schema)\n",
    "\n",
    "# Example document parsing and indexing execution\n",
    "directory_path = \"upload\"\n",
    "\n",
    "linked_project = project_account['account_id']  # Example placeholder, adjust as needed\n",
    "\n",
    "# Parse documents in the specified directory\n",
    "parse_documents_in_directory(directory_path, schema, linked_project, recreate=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "79938646",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:CID: QmWuj7Rr8PjwGzGW5otvAVTDUywUt8BHh7uvawFqEreMJo, Project: 06535@test, Name: integration test.ipynb, Title: document 1, Creator: unknown, Size: 12716 bytes\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['06535@test'],\n",
       " [{'cid': 'QmWuj7Rr8PjwGzGW5otvAVTDUywUt8BHh7uvawFqEreMJo',\n",
       "   'project_id': '06535@test',\n",
       "   'name': 'integration test.ipynb',\n",
       "   'title': 'document 1',\n",
       "   'creator': 'unknown',\n",
       "   'size': 12716}])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example search usage\n",
    "# print(ix)\n",
    "keyword = \"airfoil\"\n",
    "search_index(keyword, ix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74689d5",
   "metadata": {},
   "source": [
    "8 -  Search Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "55a509be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:CID: QmWuj7Rr8PjwGzGW5otvAVTDUywUt8BHh7uvawFqEreMJo, Project: 06535@test, Name: integration test.ipynb, Title: document 1, Creator: unknown, Size: 12716 bytes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FileIndex(FileStorage('indexdir'), 'MAIN')\n",
      "(['06535@test'], [{'cid': 'QmWuj7Rr8PjwGzGW5otvAVTDUywUt8BHh7uvawFqEreMJo', 'project_id': '06535@test', 'name': 'integration test.ipynb', 'title': 'document 1', 'creator': 'unknown', 'size': 12716}])\n"
     ]
    }
   ],
   "source": [
    "print(ix)\n",
    "project_ids = search_index(keyword, ix)\n",
    "print(project_ids)  # prints the list of project ids found in thvc e results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e6348ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keyword = \"example_keyword\"\n",
    "\n",
    "# Initialize objects and variables\n",
    "\n",
    "\n",
    "# project_ids = search_index(keyword, ix)\n",
    "# if project_ids:\n",
    "#     get_project_details(project_ids, net, iroha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f6e752f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage (replace `ix`, `net`, `iroha`, and `keyword` with actual values)\n",
    "# check_cid_in_project_details(keyword, ix, net, iroha)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8dc8733d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:CID: QmWuj7Rr8PjwGzGW5otvAVTDUywUt8BHh7uvawFqEreMJo, Project: 06535@test, Name: integration test.ipynb, Title: document 1, Creator: unknown, Size: 12716 bytes\n",
      "INFO:root:Project Account id = 06535@test, { \"admin@test\" : { \"file_1\" : \"QmVk8gxENq6PThSGZTuk7RtbufR2XeN7LtXBj2LVTUoAdN, QmRxGqNkpdBVeq2GmfbK2ZbW1oZyX14VtiYRZnmSq6nnm7\", \"file_2\" : \"QmT7ximApXtExAedhzUHGHDwRismRzuKykpH4dgTvGrNZs, QmbqyQAkQVELXkkU3jaCTUHDPLHYrMCc7fUckeh83hmRcU\", \"file_3\" : \"QmZnh5Uuo7moZKMESFHpRjQFbbND5e3nArCzZg8uLARAgg, QmXgwRkPFxG2FWQTbVGgKsaEz7thbg4WLBcndsRfKUfeaa\", \"file_4\" : \"QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW, QmbKquQj5bMdMMHaNfacbXkT9NgwWbj157EPpRVi1tPPdx\", \"file_5\" : \"QmV1vYkuiwKGPA5Tyi4ECNFfWYocyTtQ3E5j7CSvPBX49Q, QmY7xwK4beVPQLbeKxEAeStqxY69f7GzRhqTukXXsLMkMh\", \"linked_user\" : \"crazy_nash@test\", \"project_metadata_cid\" : \"QmbmyecKUbwCDFPt6Uddx411bCvefLiRXPxHs5vnYz4XZm\" } }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@prefix ns1: <http://example.org/> .\n",
      "\n",
      "<http://example.org/project/06535@test> a ns1:Project ;\n",
      "    ns1:hasCID \"QmWuj7Rr8PjwGzGW5otvAVTDUywUt8BHh7uvawFqEreMJo\" ;\n",
      "    ns1:hasTitle \"document 1\" .\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from itertools import chain\n",
    "\n",
    "def main(keyword, ix, net, iroha):\n",
    "    # Step 1: Search index with the provided keyword\n",
    "    project_ids, search_results = search_index(keyword, ix)\n",
    "\n",
    "    # Convert project_ids to a set to remove duplicates\n",
    "    unique_project_ids = set(project_ids)\n",
    "\n",
    "    # Step 2: Fetch project details for matched project IDs\n",
    "    project_details = get_project_details(unique_project_ids, net, iroha)\n",
    "\n",
    "    # Step 3: Generate the knowledge graph with CID matching\n",
    "    generate_knowledge_graph(search_results, project_details)\n",
    "\n",
    "# Example usage\n",
    "main(\"autoencoders\", ix, net, iroha)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8e6b78-9d2c-4543-b88c-ba216b3ed596",
   "metadata": {},
   "source": [
    "9 - Query the project account to verify the details update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "66cfac8c-5f92-487a-87fd-067df3e26299",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project Account id = {'account_id': '06535@test'}, { \"admin@test\" : { \"file_1\" : \"QmVk8gxENq6PThSGZTuk7RtbufR2XeN7LtXBj2LVTUoAdN, QmRxGqNkpdBVeq2GmfbK2ZbW1oZyX14VtiYRZnmSq6nnm7\", \"file_2\" : \"QmT7ximApXtExAedhzUHGHDwRismRzuKykpH4dgTvGrNZs, QmbqyQAkQVELXkkU3jaCTUHDPLHYrMCc7fUckeh83hmRcU\", \"file_3\" : \"QmZnh5Uuo7moZKMESFHpRjQFbbND5e3nArCzZg8uLARAgg, QmXgwRkPFxG2FWQTbVGgKsaEz7thbg4WLBcndsRfKUfeaa\", \"file_4\" : \"QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW, QmbKquQj5bMdMMHaNfacbXkT9NgwWbj157EPpRVi1tPPdx\", \"file_5\" : \"QmV1vYkuiwKGPA5Tyi4ECNFfWYocyTtQ3E5j7CSvPBX49Q, QmY7xwK4beVPQLbeKxEAeStqxY69f7GzRhqTukXXsLMkMh\", \"linked_user\" : \"crazy_nash@test\", \"project_metadata_cid\" : \"QmbmyecKUbwCDFPt6Uddx411bCvefLiRXPxHs5vnYz4XZm\" } }\n"
     ]
    }
   ],
   "source": [
    "#Query - GetAccountDetail\n",
    "query = iroha.query('GetAccountDetail', account_id=linked_project)\n",
    "IrohaCrypto.sign_query(query, ADMIN_PRIVATE_KEY)\n",
    "response = net.send_query(query)\n",
    "# print(response)\n",
    "project_data = response.account_detail_response\n",
    "project_details = project_data.detail\n",
    "print(f'Project Account id = {project_account}, {project_details}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc6ee05-f89d-44ce-aab8-e57b2acff3a4",
   "metadata": {},
   "source": [
    "10 - Read CIDs from Iroha and download file metadata and files from IPFS to the project home directory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc6ca74-7343-4109-b774-0582cb9bab9b",
   "metadata": {},
   "source": [
    "11 - Read details from the project account retrieve the CID of every file, download the it file from IPFS and store locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1ae73161-a508-408c-81fb-3bb08b13fcec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing project account: 06535@test\n",
      "Processing file CID: QmVk8gxENq6PThSGZTuk7RtbufR2XeN7LtXBj2LVTUoAdN, QmRxGqNkpdBVeq2GmfbK2ZbW1oZyX14VtiYRZnmSq6nnm7 for key: file_1\n",
      "Processing file CID: QmT7ximApXtExAedhzUHGHDwRismRzuKykpH4dgTvGrNZs, QmbqyQAkQVELXkkU3jaCTUHDPLHYrMCc7fUckeh83hmRcU for key: file_2\n",
      "Processing file CID: QmZnh5Uuo7moZKMESFHpRjQFbbND5e3nArCzZg8uLARAgg, QmXgwRkPFxG2FWQTbVGgKsaEz7thbg4WLBcndsRfKUfeaa for key: file_3\n",
      "Processing file CID: QmUq29KRwpTdvScB5oYzEDobDHyb4N1f9eaZXm4VaMCgiW, QmbKquQj5bMdMMHaNfacbXkT9NgwWbj157EPpRVi1tPPdx for key: file_4\n",
      "Processing file CID: QmV1vYkuiwKGPA5Tyi4ECNFfWYocyTtQ3E5j7CSvPBX49Q, QmY7xwK4beVPQLbeKxEAeStqxY69f7GzRhqTukXXsLMkMh for key: file_5\n",
      "Skipping key: linked_user\n",
      "Skipping key: project_metadata_cid\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from clean_file_name import clean_file_name as clean_name\n",
    "from ipfs_functions import download_file_from_ipfs, download_json_from_ipfs\n",
    "\n",
    "# Convert the JSON string to a Python dictionary\n",
    "project_details_dict = json.loads(project_details)\n",
    "project_account_id = project_account['account_id']\n",
    "\n",
    "print(f\"Processing project account: {project_account_id}\")\n",
    "\n",
    "# Get the value of the dictionary (actual file metadata)\n",
    "files_metadata = project_details_dict['admin@test']\n",
    "# print(files_metadata)\n",
    "\n",
    "# Iterate through files metadata, skip unneeded keys, and process files and metadata CIDs\n",
    "for key, value in files_metadata.items():\n",
    "    if key in ['linked_user', 'project_metadata_cid']:\n",
    "        print(f\"Skipping key: {key}\")\n",
    "        continue\n",
    "\n",
    "    # Distinguish between file CID and metadata CID\n",
    "    if 'metadata_CID' not in key:\n",
    "        file_CID = value\n",
    "        print(f\"Processing file CID: {file_CID} for key: {key}\")\n",
    "    else:\n",
    "        file_metadata_key = '_'.join(key.split('_')[:-2])\n",
    "        file_metadata_CID = value\n",
    "        print(f\"Processing metadata CID: {file_metadata_CID} for key: {file_metadata_key}\")\n",
    "\n",
    "        # Download and process metadata JSON\n",
    "        file_metadata_json = download_json_from_ipfs(file_metadata_CID)\n",
    "        # print(file_metadata_json)\n",
    "\n",
    "        # Ensure 'resourceName' exists in metadata and process the file download\n",
    "        if 'resourceName' in file_metadata_json:\n",
    "            raw_file_name = file_metadata_json['resourceName']\n",
    "            cleaned_file_name = clean_name(raw_file_name)  # Renamed to avoid conflict\n",
    "            print(f\"Cleaned file name: {cleaned_file_name}\")\n",
    "\n",
    "            # Create user-specific download directory if it doesn't exist\n",
    "            download_directory = os.path.join(\"download\", project_account_id)\n",
    "            os.makedirs(download_directory, exist_ok=True)\n",
    "            print(f\"Download directory ready: {download_directory}\")\n",
    "\n",
    "            # Download file using the file CID\n",
    "            file_path = os.path.join(download_directory, cleaned_file_name)\n",
    "            print(f\"Downloading file to: {file_path}\")\n",
    "            download_file_from_ipfs(file_CID, file_path)\n",
    "            print(\"-\" * 40)\n",
    "        else:\n",
    "            print(f\"No 'resourceName' found for metadata CID: {file_metadata_CID}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
